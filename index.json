[{"categories":[],"content":"Tráº£i nghiá»‡m lÃ m Data Engineer táº¡i Bosch","date":"26 Jul 2024","objectID":"/workatbosch/","series":[],"tags":[],"title":"Bosch vÃ  cuá»™c hÃ nh trÃ¬nh má»›i","uri":"/workatbosch/"},{"categories":[],"content":"Lá»i cáº£m Æ¡n â¤ï¸ Lá»i Ä‘áº§u tiÃªn, mÃ¬nh muá»‘n gá»­i lá»i cáº£m Æ¡n Ä‘áº¿n cÃ¡c anh chá»‹ táº¡i Bosch R\u0026D Center Ä‘Ã£ luÃ´n giÃºp Ä‘á»¡, há»— trá»£ OG má»i lÃºc trong suá»‘t quÃ¡ trÃ¬nh OG há»c táº­p vÃ  lÃ m viá»‡c táº¡i Ä‘Ã¢y. OG Ä‘Ã£ biáº¿t vÃ  Ä‘Ã£ cÃ³ nhiá»u tráº£i nghiá»‡m tuyá»‡t vá»i pháº§n lá»›n lÃ  cÃ³ sá»± giÃºp Ä‘á»¡ táº­n tÃ¬nh cá»§a má»i ngÆ°á»i. Tháº­t tá»‘t khi luÃ´n cÃ³ má»i ngÆ°á»i á»Ÿ bÃªn vÃ  Ä‘á»™ng viÃªn OG trong cáº£ chuyáº¿n Ä‘i. Thá»±c sá»± ráº¥t yÃªu quÃ½ táº¥t cáº£ cÃ¡c anh chá»‹ â¤ï¸ ","date":"26 Jul 2024","objectID":"/workatbosch/:0:0","series":[],"tags":[],"title":"Bosch vÃ  cuá»™c hÃ nh trÃ¬nh má»›i","uri":"/workatbosch/#"},{"categories":[],"content":"CÆ¡ há»™i má»›iThÃ nh thá»±c mÃ  nÃ³i mÃ¬nh khÃ´ng nghÄ© lÃ  sáº½ cÃ³ má»™t ngÃ y, mÃ¬nh cÃ³ cÆ¡ há»™i Ä‘Æ°á»£c thá»±c táº­p táº¡i má»™t táº­p Ä‘oÃ n lá»›n nhÆ° Bosch. LÃ  má»™t Ä‘á»©a chá»‰ â€œchÃ¢n Æ°á»›t chÃ¢n rÃ¡oâ€ vÃ o ngÃ nh, cÆ¡ há»™i nÃ y giá»‘ng nhÆ° má»™t kho bÃ¡u giá»¯a Ä‘áº¡i dÆ°Æ¡ng rá»™ng lá»›n váº­y. Ban Ä‘áº§u, mÃ¬nh tháº¥y Ä‘Æ°á»£c nhá»¯ng tiá»m nÄƒng vá» chuyÃªn mÃ´n mÃ¬nh cÃ³ thá»ƒ há»c há»i vÃ  nhá»¯ng má»‘i quan há»‡ má»›i mÃ¬nh cÃ³ thá»ƒ káº¿t ná»‘i. NhÆ°ng rá»“i sau Ä‘Ã³, mÃ¬nh nháº­n ra ráº±ng Bosch cho mÃ¬nh hÆ¡n tháº¿ ráº¥t nhiá»u. KhÃ´ng chá»‰ lÃ  kiáº¿n thá»©c, kinh nghiá»‡m hay tráº£i nghiá»‡m trong chuyÃªn mÃ´n, mÃ  cÃ²n Ä‘Ã³ lÃ  nhá»¯ng ká»· niá»‡m vÃ  ká»¹ nÄƒng trong Ä‘á»i sá»‘ng. Quan trá»ng nháº¥t lÃ  cho mÃ¬nh má»™t cÆ¡ há»™i Ä‘á»ƒ mÃ¬nh gáº·p gá»¡ Ä‘Æ°á»£c nhá»¯ng con ngÆ°á»i vÃ´ cÃ¹ng Æ°u tÃº vÃ  tuyá»‡t vá»i. ","date":"26 Jul 2024","objectID":"/workatbosch/:1:0","series":[],"tags":[],"title":"Bosch vÃ  cuá»™c hÃ nh trÃ¬nh má»›i","uri":"/workatbosch/#cÆ¡-há»™i-má»›i"},{"categories":[],"content":"Ráº¥t nhiá»u cÃ¡i â€œláº§n Ä‘áº§uâ€Äáº¿n vá»›i Bosch, mÃ¬nh Ä‘Æ°á»£c unlock ráº¥t nhiá»u tráº£i nghiá»‡m Ä‘áº§u tiÃªn. ÄÃ³ lÃ  láº§n Ä‘áº§u tiÃªn Ä‘Æ°á»£c Ä‘áº·t chÃ¢n Ä‘áº¿n lÃ m viá»‡c táº¡i má»™t vÄƒn phÃ²ng xÃ¬n xÃ² Ä‘áº§y Ä‘á»§ trang thiáº¿t bá»‹ vÃ  khÃ´ng gian lÃ m viá»‡c rá»™ng rÃ£i. LÃ  láº§n Ä‘áº§u tiÃªn Ä‘Æ°á»£c tráº£i nghiá»‡m â€œcÆ¡m trÆ°a vÄƒn phÃ²ngâ€ vá»›i cÃ¡c anh chá»‹ Ä‘á»“ng nghiá»‡p. Hay lÃ  tráº£i nghiá»‡m cÃ¡i view triá»‡u Ä‘Ã´ cá»§a Dinh Äá»™c Láº­p tá»« trÃªn cao, tha há»“ sá»‘ng áº£o ğŸ˜ Äáº¿n lÃ m táº¡i Ä‘Ã¢y thÃ¬ khÃ´ng thá»ƒ khÃ´ng nháº¯c Ä‘áº¿n má»³ ly cuá»‘i buá»•i, pháº£i nÃ³i lÃ  cá»©u cÃ¡nh cho má»i nhÃ¢n viÃªn vÄƒn phÃ²ng sau má»™t ngÃ y má»‡t má»i Ä‘á»ƒâ€¦láº¥y sá»©c lÃ m tiáº¿p ğŸ˜‚ MÃ¬nh Ä‘Ã£ báº¥t ngá» khi cÃ³ háº³n cáº£ má»™t thá»‘ng kÃª vá» sá»‘ lÆ°á»£ng mÃ¬ ly tiÃªu thá»¥ trong má»™t thÃ¡ng ğŸ˜‹ Táº¥t nhiÃªn lÃ  cÃ³ nhá»¯ng ngÃ y Äƒn nhá»¯ng mÃ³n khÃ¡c nhÆ°ng mÃ  mÃ¬ ly váº«n lÃ  cÃ¡i gÃ¬ Ä‘Ã³ quÃ¡ huyá»n thoáº¡i táº¡i Ä‘Ã¢y mÃ  báº¥t cá»© Engineer nÃ o cÅ©ng Äƒn sau má»—i buá»•i lÃ m. ","date":"26 Jul 2024","objectID":"/workatbosch/:2:0","series":[],"tags":[],"title":"Bosch vÃ  cuá»™c hÃ nh trÃ¬nh má»›i","uri":"/workatbosch/#ráº¥t-nhiá»u-cÃ¡i-láº§n-Ä‘áº§u"},{"categories":[],"content":"LÃ  má»™t Ä‘áº¡i gia Ä‘Ã¬nhThá»±c sá»±, mÃ¬nh ráº¥t thÃ­ch cÃ¡ch mÃ  má»i ngÆ°á»i, cÃ¡c anh chá»‹ táº¡i Bosch R\u0026D gáº¯n bÃ³ vá»›i nhau. Ngay tá»« nhá»¯ng ngÃ y Ä‘áº§u tiÃªn láº­p báº­p Ä‘i lÃ m, mÃ¬nh cá»© nghÄ© sáº½ máº¥t ráº¥t nhiá»u thá»i gian Ä‘á»ƒ lÃ m quen. Tuy nhiÃªn cÃ¡c anh chá»‹, Ä‘á»“ng nghiá»‡p Ä‘á»u cá»Ÿi má»Ÿ vÃ  chÃ o Ä‘Ã³n mÃ¬nh nhÆ° thá»ƒ má»™t thÃ nh viÃªn má»›i cá»§a Ä‘áº¡i gia Ä‘Ã¬nh, vÃ  Ä‘iá»u Ä‘Ã³ giÃºp cho báº£n thÃ¢n OG cáº£m tháº¥y tá»± tin hÆ¡n Ä‘á»ƒ hÃ²a nháº­p vá»›i mÃ´i trÆ°á»ng má»›i. NgoÃ i ra cÅ©ng cÃ³ nhá»¯ng buá»•i Ä‘i team building hay háº¹n nhau Ä‘i chÆ¡i siÃªu vui. Cuá»‘i cÃ¹ng vá»›i OG, Ä‘Ã¢y chÃ­nh lÃ  gia Ä‘Ã¬nh thá»© 2 cá»§a mÃ¬nh â¤ï¸ DÃ¹ cuá»™c hÃ nh trÃ¬nh nÃ o cÅ©ng Ä‘áº¿n há»“i káº¿t, cuá»™c vui nÃ o cÅ©ng Ä‘áº¿n lÃºc tÃ n. NhÆ°ng nhá»¯ng kÃ½ á»©c vá» ká»³ tráº£i nghiá»‡m tuyá»‡t vá»i á»Ÿ Bosch R\u0026D sáº½ mÃ£i lÃ  cá»™t má»‘c Ä‘Ã¡ng nhá»› trong sá»± nghiá»‡p cá»§a OG - luv all of you â¤ï¸ â€“Mewwâ€“ ","date":"26 Jul 2024","objectID":"/workatbosch/:3:0","series":[],"tags":[],"title":"Bosch vÃ  cuá»™c hÃ nh trÃ¬nh má»›i","uri":"/workatbosch/#lÃ -má»™t-Ä‘áº¡i-gia-Ä‘Ã¬nh"},{"categories":[],"content":"NhÃ¬n láº¡i cháº·ng Ä‘Æ°á»ng dÃ i nÄƒm 2023 cá»§a báº£n thÃ¢n mÃ¬nh","date":"31 Dec 2023","objectID":"/recap2023/","series":[],"tags":["lifestory"],"title":"NhÃ¬n láº¡i 2023","uri":"/recap2023/"},{"categories":[],"content":"NÄƒm 2023 vá»«a qua tháº­t sá»± lÃ  má»™t cá»™t má»‘c Ä‘Ã¡ng nhá»› Ä‘á»‘i vá»›i báº£n thÃ¢n OG. ÄÃ³ lÃ  má»™t cháº·ng Ä‘Æ°á»ng ráº¥t dÃ i thÄƒng tráº§m buá»“n vui láº«n lá»™n. VÃ o nhá»¯ng giÃ¢y phÃºt cuá»‘i cÃ¹ng, OG sáº½ dÃ¹ng bÃ i viáº¿t nÃ y Ä‘á»ƒ nhÃ¬n láº¡i cuá»™c hÃ nh trÃ¬nh Ä‘Ã£ qua Ä‘á»ƒ rá»“i sau cuá»‘i chÃ­nh lÃ  hÆ°á»›ng Ä‘áº¿n má»™t tÆ°Æ¡ng lai vá»›i nhiá»u káº¿ hoáº¡ch má»›i phÃ­a trÆ°á»›c á»Ÿ nÄƒm má»›i 2024 â¤ï¸ ","date":"31 Dec 2023","objectID":"/recap2023/:0:0","series":[],"tags":["lifestory"],"title":"NhÃ¬n láº¡i 2023","uri":"/recap2023/#"},{"categories":[],"content":"LÃ  má»™t nÄƒm Ä‘áº§y niá»m vuiNáº¿u Ä‘Æ°á»£c tÃ³m gá»n 2 tá»« Ä‘á»ƒ mÃ´ táº£ nÄƒm vá»«a qua, thÃ¬ OG sáº½ chá»n 2 tá»« â€œMÃ£n nguyá»‡nâ€. VÃ¬ Ä‘iá»u lá»›n lao mÃ  nÄƒm qua OG Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c chÃ­nh lÃ  Ä‘Ã£ Ä‘Æ°á»£c cÆ°á»i tháº­t nhiá»u, Ä‘Ã£ Ä‘Æ°á»£c sá»‘ng tháº­t háº¿t mÃ¬nh vÃ  tráº£i nghiá»‡m nhiá»u Ä‘iá»u má»›i láº¡. NhÆ° tháº¿ vá»›i mÃ¬nh Ä‘Ã£ lÃ  â€œMÃ£n nguyá»‡nâ€ rá»“i ğŸ˜„ Khi nhÃ¬n láº¡i quÃ¡ khá»©, Ä‘iá»u gá»£i lÃªn Ä‘áº§u tiÃªn cháº¯c háº³n lÃ  nhá»¯ng Ä‘iá»u khiáº¿n ta vui váº», háº¡nh phÃºc. Äáº¿n Ä‘Ã¢y, OG muá»‘n nÃ³i lá»i cáº£m Æ¡n Ä‘áº¿n nhá»¯ng ngÆ°á»i báº¡n há»c, nhá»¯ng ngÆ°á»i mÃ  OG Ä‘Ã£ gáº·p, nhá»¯ng â€œanh emâ€ Ä‘Ã£ luÃ´n sÃ¡t cÃ¡nh vá»›i OG trong cáº£ chuyáº¿n hÃ nh trÃ¬nh dÃ i vá»«a qua. Há» khÃ´ng chá»‰ lÃ  nhá»¯ng ngÆ°á»i báº¡n Ä‘á»“ng hÃ nh, mÃ  cÃ²n lÃ  nhá»¯ng ngÆ°á»i giÃºp â€œnÃªm náº¿mâ€ cho cuá»™c sá»‘ng OG thiá»‡t máº·n mÃ  vÃ  thÃº vá»‹ ğŸ˜‚ Xin vÃ´ cÃ¹ng cáº£m Æ¡n cÃ¡c báº¡n. ","date":"31 Dec 2023","objectID":"/recap2023/:1:0","series":[],"tags":["lifestory"],"title":"NhÃ¬n láº¡i 2023","uri":"/recap2023/#lÃ -má»™t-nÄƒm-Ä‘áº§y-niá»m-vui"},{"categories":[],"content":"Cuá»™c Ä‘á»i lÃ  nhá»¯ng chuyáº¿n Ä‘iÄáº§u tiÃªn nÃ³i vá» chuyá»‡n Ä‘i chÆ¡i trÆ°á»›c, nÄƒm vá»«a qua tháº­t sá»± lÃ  má»™t nÄƒm Ä‘áº·c biá»‡t, vÃ¬ OG Ä‘Æ°á»£c Ä‘i du lá»‹ch nhiá»u nÆ¡i vÃ  tráº£i nghiá»‡m nhiá»u cáº£m giÃ¡c má»›i láº¡. Info Tháº­t sá»± thÃ¬ mÃ¬nh ráº¥t thÃ­ch Ä‘i du lá»‹ch vÃ  khÃ¡m phÃ¡ tháº¿ giá»›i xung quanh Ä‘á»ƒ sau nÃ y khi nhÃ¬n láº¡i thÃ¬ mÃ¬nh cÃ³ thá»ƒ cho con chÃ¡u â€œWow há»“i Ä‘Ã³ Ã´ng bodoi dá»¯â€ ğŸ˜‚ Má»Ÿ Ä‘áº§u cho nÄƒm 2023, mÃ¬nh vÃ  nhá»¯ng ngÆ°á»i báº¡n Ä‘Ã£ cÃ¹ng dáº¯t nhau Ä‘i hÆ°á»Ÿng cÃ¡i láº¡nh ÄÃ  Láº¡t vÃ  sau Ä‘Ã³ lÃ  ngáº¯m biá»ƒn Nha Trang quÃ¡ xÃ¡ Ä‘Ã£ ÄÃ  Láº¡t lÃºc Ä‘Ã³ láº¡nh teo\" ÄÃ  Láº¡t lÃºc Ä‘Ã³ láº¡nh teo Nhá» nhá»¯ng chuyáº¿n Ä‘i nhÆ° váº­y, mÃ¬nh Ä‘Ã£ lÃ m quen nhiá»u nhá»¯ng ngÆ°á»i báº¡n má»›i. Sau Ä‘Ã³ (háº³n ná»­a nÄƒm sau ğŸ˜‚) mÃ¬nh láº¡i cÃ³ dá»‹p quay láº¡i Nha Trang Ä‘á»ƒ xáº£ hÆ¡i trong ká»³ hÃ¨. -- Chuáº©n bá»‹ ra biá»ƒn báº¯t á»‘cnha trang \" Chuáº©n bá»‹ ra biá»ƒn báº¯t á»‘c Tham quan nhÃ  thá» Ä‘Ã¡ má»‡t luÃ´nnha trang \" Tham quan nhÃ  thá» Ä‘Ã¡ má»‡t luÃ´n ÄÃ£ cÃ³ nhá»¯ng láº§n Ä‘i tháº­t xa, vÃ  táº¥t cáº£ nhá»¯ng chuyáº¿n Ä‘i Ä‘Ã³, Ä‘á»u Ä‘á»ng láº¡i trong OG nhá»¯ng Ä‘iá»u Ä‘Ã¡ng quÃ½ nhÆ° lÃ  má»™t pháº§n cá»§a nÄƒm 2023 quÃ¡ Ä‘Ã¡ng nhá»›. ","date":"31 Dec 2023","objectID":"/recap2023/:2:0","series":[],"tags":["lifestory"],"title":"NhÃ¬n láº¡i 2023","uri":"/recap2023/#cuá»™c-Ä‘á»i-lÃ -nhá»¯ng-chuyáº¿n-Ä‘i"},{"categories":[],"content":"LÃ  nÄƒm cá»§a sá»± ná»— lá»±cMÃ¬nh Ä‘i chÆ¡i nhiá»u, thÃ¬ Ä‘á»•i láº¡i mÃ¬nh há»c cÅ©ng nhiá»u. NÄƒm vá»«a qua chÃ­nh lÃ  nÄƒm mÃ  mÃ¬nh cÃ³ ráº¥t nhiá»u cÆ¡ há»™i Ä‘Æ°á»£c há»c há»i, dáº¥n thÃ¢n tráº£i nghiá»‡m nhiá»u thá»©. Tháº­t sá»±, OG muá»‘n cáº£m Æ¡n báº£n thÃ¢n mÃ¬nh vÃ¬ Ä‘Ã£ khÃ´ng bao giá» bá» cuá»™c vÃ  luÃ´n dáº¥n thÃ¢n lÃ m nhá»¯ng Ä‘iá»u má»›i máº» vÃ  há»c táº­p khÃ´ng ngá»«ng. BÆ°á»›c tiáº¿n Ä‘áº§u tiÃªn mÃ¬nh muá»‘n ká»ƒ Ä‘Ã³ chÃ­nh lÃ  láº§n Ä‘áº§u tiÃªn báº£n thÃ¢n mÃ¬nh tá»± tay hoÃ n thiá»‡n Ä‘Æ°á»£c má»™t dá»± Ã¡n Data Engineer end-to-end. CÃ³ thá»ƒ nÃ³ khÃ´ng to tÃ¡t nhÆ°ng vá»›i báº£n thÃ¢n OG, Ä‘Ã³ láº¡i chÃ­nh lÃ  Ä‘á»™ng lá»±c vÃ  lÃ  viÃªn gáº¡ch thÃ nh quáº£ Ä‘áº§u tiÃªn cho hÃ nh trÃ¬nh há»c táº­p dÃ i phÃ­a trÆ°á»›c. OG muá»‘n gá»­i lá»i cáº£m Æ¡n sÃ¢u sáº¯c Ä‘áº¿n cÃ¡c tháº§y cá»§a khÃ³a há»c FDE cá»§a AIDE vÃ  cÃ¡c báº¡n Ä‘Ã£ há»— trá»£ vÃ  gÃ³p Ã½ cho mÃ¬nh Ä‘á»ƒ hoÃ n thiá»‡n dá»± Ã¡n Ä‘áº§u tiÃªn â¤ï¸ Báº¡n cÃ³ thá»ƒ ghÃ© qua xem thá»­ dá»± Ã¡n Ä‘Ã³ cá»§a mÃ¬nh: Football ETL Analysis VÃ  nÄƒm qua cÅ©ng lÃ  nÄƒm mÃ  OG tham gia má»™t cuá»™c thi vá» dá»¯ liá»‡u lÃ  Datathon VietNam. Tuy khÃ´ng may máº¯n Ä‘áº¡t Ä‘Æ°á»£c thÃ nh tÃ­ch tá»‘t, nhÆ°ng láº¡i lÃ  minh chá»©ng cho sá»± dÅ©ng cáº£m cá»§a báº£n thÃ¢n vÃ¬ Ä‘Ã£ bÆ°á»›c khá»i vÃ¹ng an toÃ n vÃ  thá»­ thÃ¡ch chÃ­nh mÃ¬nh. VÃ  hÆ¡n tháº¿ ná»¯a báº£n thÃ¢n mÃ¬nh cÅ©ng cÃ³ cÆ¡ há»™i lÃ m viá»‡c vá»›i nhá»¯ng â€œlÃ n giÃ³ má»›iâ€ vÃ´ cÃ¹ng Äƒn Ã½ vÃ  gÃ³p nháº·t Ä‘Æ°á»£c nhiá»u kinh nghiá»‡m tá»« há» vÃ  tá»« cuá»™c thi. Má»™t thÃ nh quáº£ nho nhá» khÃ´ng thá»ƒ khÃ´ng ká»ƒ Ä‘áº¿n trong nÄƒm qua chÃ­nh lÃ  sá»± ra Ä‘á»i cá»§a trang web nÃ y :))) bravo Táº¥t nhiÃªn lÃ  á»Ÿ trÆ°á»ng mÃ¬nh cÅ©ng Ä‘Ã£ luÃ´n cá»‘ gáº¯ng Ä‘á»ƒ khÃ´ng bá»‹ â€œchÃ¬m nghá»‰mâ€ vÃ  cÅ©ng tháº­t tuyá»‡t vá»i vÃ¬ luÃ´n cÃ³ nhá»¯ng Ä‘á»“ng chÃ­ luÃ´n giÃºp Ä‘á»¡ OG háº¿t mÃ¬nh trong trÆ°á»ng lá»›p. ","date":"31 Dec 2023","objectID":"/recap2023/:3:0","series":[],"tags":["lifestory"],"title":"NhÃ¬n láº¡i 2023","uri":"/recap2023/#lÃ -nÄƒm-cá»§a-sá»±-ná»—-lá»±c"},{"categories":[],"content":"Nhá»¯ng khoáº£ng tráº§mTrong suá»‘t má»™t cháº·ng Ä‘Æ°á»ng dÃ i, khÃ´ng pháº£i lÃºc nÃ o cÅ©ng luÃ´n lÃ  nhá»¯ng Ä‘iá»u vui váº». Báº£n thÃ¢n mÃ¬nh Ä‘Ã£ tá»«ng ráº¥t stress, Ã¡p lá»±c vá» cuá»™c sá»‘ng. ÄÃ´i lÃºc mÃ¬nh tháº¥y mÃ¬nh tháº­t â€œvÃ´ triâ€â€¦ Tháº­t Ä‘áº¥y, má»™t cáº£m giÃ¡c khÃ´ng há» dá»… chá»‹u gÃ¬ nhÃ¬n tháº¥y sá»± tiáº¿n bá»™ cá»§a má»i ngÆ°á»i xung quanh cÃ²n mÃ¬nh thÃ¬ váº«n loay hoay vá»›i nhá»¯ng dá»± Ä‘á»‹nh, káº¿ hoáº¡ch váº«n cÃ²n dang dá»Ÿ. VÃ  Ä‘Ã´i khi nhÃ¬n tháº¥y báº£n thÃ¢n ná»— lá»±c mÃ  cháº³ng cÃ³ káº¿t quáº£ gÃ¬, Ä‘iá»u Ä‘Ã³ ráº¥t nhiá»u, Ä‘Ã£ ráº¥t nhiá»u láº§n lÃ m mÃ¬nh náº£n chÃ­ vÃ  tá»± trÃ¡ch. NhÆ°ng sau cuá»‘i, sau má»i cáº£m giÃ¡c tiÃªu cá»±c, cáº£m Æ¡n báº£n thÃ¢n vÃ¬ Ä‘Ã£ chÆ°a bao giá» Ä‘áº§u hÃ ng vÃ  luÃ´n tiáº¿n vá» phÃ­a trÆ°á»›c. Äiá»u quan trá»ng lÃ  ta chá»‰ cáº§n giá»i hÆ¡n báº£n thÃ¢n cá»§a ngÃ y hÃ´m qua. NhÆ° tháº¿ Ä‘Ã£ thÃ nh cÃ´ng rá»“i. ","date":"31 Dec 2023","objectID":"/recap2023/:4:0","series":[],"tags":["lifestory"],"title":"NhÃ¬n láº¡i 2023","uri":"/recap2023/#nhá»¯ng-khoáº£ng-tráº§m"},{"categories":[],"content":"Má»™t chÆ°Æ¡ng má»›iÄi qua má»™t nÄƒm 2023 nhiá»u sá»± kiá»‡n nhÆ° váº­y Ä‘Ã£ giÃºp báº£n thÃ¢n mÃ¬nh trÆ°á»Ÿng thÃ nh hÆ¡n ráº¥t nhiá»u. KhÃ©p láº¡i má»™t chÆ°Æ¡ng cÅ© vá»›i nhiá»u bÃ i há»c quÃ½ giÃ¡ vÃ  nhá»¯ng ká»· niá»‡m Ä‘Ã¡ng nhá»› Ä‘á»ƒ lÃ m bÆ°á»›c Ä‘Ã  cho chÆ°Æ¡ng má»›i 2024. OG chÃºc cÃ¡c báº¡n Ä‘á»c má»™t nÄƒm má»›i bÃ¬nh an vÃ  cÃ³ nhiá»u thÃ nh cÃ´ng Ä‘á»™t phÃ¡ vá»›i nhá»¯ng dá»± Ä‘á»‹nh cá»§a mÃ¬nh trong nÄƒm 2024 ğŸ‹ Háº¹n gáº·p láº¡i cÃ¡c báº¡n vÃ o â€œNÄ‚M SAUâ€ ğŸ˜‚ -Mew New Year- ","date":"31 Dec 2023","objectID":"/recap2023/:5:0","series":[],"tags":["lifestory"],"title":"NhÃ¬n láº¡i 2023","uri":"/recap2023/#má»™t-chÆ°Æ¡ng-má»›i"},{"categories":["projects"],"content":"A End to End ELT data pipeline to Analyze Spotify Data and build recommendation system","date":"10 Dec 2023","objectID":"/spotify_analysis/","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/"},{"categories":["projects"],"content":"Shout out cho nhá»¯ng member tÃ¢m huyáº¿t Project nÃ y cÃ³ thá»ƒ hoÃ n thiá»‡n cÅ©ng lÃ  sá»± Ä‘Ã³ng gÃ³p cá»§a cÃ¡c thÃ nh viÃªn trong team: Ngá»c Tuáº¥n (Data Engineer), Duy SÆ¡n (Data Scientist), VÄ© ThiÃªn (Data Analyst) PhongHuynh0394 Spotify Analysis with PySpark English Version Available Hello ! Hello ! Láº¡i lÃ  OG Ä‘Ã¢y. Láº§n nÃ y mÃ¬nh sáº½ cÃ¹ng nhau xÃ¢y dá»±ng End-to-End ELT data pipeline vÃ  má»™t Recommender System dá»±a trÃªn dá»¯ liá»‡u phÃ¢n tÃ­ch tá»« Spotify API nhÃ©. KhÃ´ng dÃ i dÃ²ng ná»¯a, báº¯t Ä‘áº§u thÃ´i nÃ o. ","date":"10 Dec 2023","objectID":"/spotify_analysis/:0:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#"},{"categories":["projects"],"content":"IntroductionProject láº§n nÃ y lÃ  xÃ¢y dá»±ng há»‡ thá»‘ng phÃ¢n tÃ­ch nháº¡c tá»« Spotify nhÆ° diagram sau Trong diagram bao gá»“m nhá»¯ng thÃ nh pháº§n sau: Infrastructure: Ta sáº½ sá»­ dá»¥ng Docker Ä‘á»ƒ set up cho háº§u háº¿t cÃ¡c frameworks sá»­ dá»¥ng trong há»‡ thá»‘ng vÃ  Terraform (Optional) Ä‘á»ƒ set up cho MongoDB. Pipeline 1: ÄÃ¢y lÃ  pipeline sáº½ thá»±c hiá»‡n incremental load vÃ o MongoDB má»—i kÃ©o data tá»« Spotify API vá». Pipeline 2: Data Pipeline nÃ y thá»±c hiá»‡n viá»‡c chÃ­nh lÃ  ELT (Extract, Load, Transform) Ä‘á»ƒ xá»­ lÃ½ vÃ  chuáº©n hÃ³a dá»¯ liá»‡u JSON tá»« MongoDB. Viá»‡c xá»­ lÃ½ cáº¥u trÃºc dá»¯ liá»‡u phá»©c táº¡p vÃ  lá»“ng nhau cá»§a JSON chá»§ yáº¿u sáº½ Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng pySpark (Python API cá»§a Apache Spark) ngay trÃªn HDFS (Hadoop Distributed File System) Analytic Layer: Äá»ƒ cÃ³ thá»ƒ sá»­ dá»¥ng phÃ¢n tÃ­ch Ä‘Æ°á»£c, ta sáº½ apply má»™t lá»›p phÃ¢n tÃ­ch lÃªn trÃªn Hadoop. á» project nÃ y ta sáº½ sá»­ dá»¥ng Dremio Ä‘á»ƒ cho viá»‡c Ä‘Ã³. Machine learning and Dashboard: á» pháº§n nÃ y chá»§ yáº¿u lÃ  viá»‡c training mÃ´ hÃ¬nh machine learning model cho há»‡ thá»‘ng gá»£i Ã½ Ã¢m nháº¡c spoitfy. NgoÃ i ra cÅ©ng cÃ³ thá»ƒ PowerBI Ä‘á»ƒ táº¡o cÃ¡c Dashboard Ä‘á»ƒ phÃ¢n tÃ­ch tá»« dá»¯ liá»‡u á»Ÿ Dremio. Application: Cuá»‘i cÃ¹ng ta sáº½ dÃ¹ng Streamlit Ä‘á»ƒ viáº¿t má»™t web Ä‘Æ¡n giáº£n Ä‘á»ƒ lÃ m há»‡ thá»‘ng gá»£i Ã½ vÃ  tÃ¬m kiáº¿m nháº¡c. NgoÃ i ra ngÆ°á»i dÃ¹ng cÅ©ng cÃ³ thá»ƒ tÆ°Æ¡ng tÃ¡c vá»›i BI Dashboard á»Ÿ layer nÃ y ","date":"10 Dec 2023","objectID":"/spotify_analysis/:1:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#introduction"},{"categories":["projects"],"content":"Data SchemaNguá»“n data cá»§a chÃºng ta Ä‘áº¿n tá»« Spotify API. NgoÃ i ra ta cÅ©ng sáº½ cÃ o thÃªm má»™t danh sÃ¡ch nghá»‡ sÄ© trÃªn Spotify tá»« trang Sportify Artists. Data sau khi Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ cuá»‘i cÃ¹ng sáº½ cÃ³ schema nhÆ° sau: ","date":"10 Dec 2023","objectID":"/spotify_analysis/:2:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#data-schema"},{"categories":["projects"],"content":"InfrastructureTa sáº½ sá»­ dá»¥ng chá»§ yáº¿u lÃ  Docker Ä‘á»ƒ cáº¥u hÃ¬nh cho háº§u háº¿t cÃ¡c framework trong há»‡ thá»‘ng thÃ´ng qua docker-compose.yml file. Chá»‰ riÃªng cÃ³ MongoDB Atlas thÃ¬ cÃ³ thá»ƒ set up báº±ng nhiá»u cÃ¡ch khÃ¡c nhau. ","date":"10 Dec 2023","objectID":"/spotify_analysis/:3:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#infrastructure"},{"categories":["projects"],"content":"Apache HadoopÄáº§u tiÃªn ta sáº½ set up Apache Hadoop báº±ng Docker Compose. NhÆ° Ä‘Ã£ biáº¿t Hadoop lÃ  má»™t framework Ä‘Æ°á»£c viáº¿t báº±ng Java Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi Google vÃ o nÄƒm 2006 vÃ  á»©ng dá»¥ng cÃ´ng nghá»‡ há»‡ thá»‘ng phÃ¢n tÃ¡n Ä‘á»ƒ lÆ°u trá»¯ vÃ  xá»­ lÃ½ Big Data. Hadoop Ä‘Æ°á»£c xÃ¢y dá»±ng Ä‘á»±a trÃªn ba thÃ nh pháº§n chÃ­nh: HDFS (Hadoop Distributed File System): lÃ  há»‡ thá»‘ng file phÃ¢n tÃ¡n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ lÆ°u trá»¯ dá»¯ liá»‡u YARN (Yet Another Resouce Negotiator): lÃ  má»™t framework quáº£n lÃ½ vÃ  phÃ¢n bá»• tÃ i nguyÃªn Ä‘á»ƒ váº­n hÃ nh cÃ¡c á»©ng dá»¥ng trÃªn Hadoop MapReduce: lÃ  má»™t framework láº­p trÃ¬nh xá»­ lÃ½ vÃ  tÃ­nh toÃ¡n dá»¯ liá»‡u song song trong mÃ´i trÆ°á»ng há»‡ thá»‘ng phÃ¢n tÃ¡n. HDFS vÃ  YARN trong Hadoop Trong project nÃ y, ta sáº½ lÆ°á»£t bá»›t pháº§n setup MapReduce trong Hadoop Cluster vÃ  thay vÃ o Ä‘Ã³ chá»‰ lÃ  HDFS vÃ  YARN thÃ´i (vÃ¬ pháº§n xá»­ lÃ½ tÃ­nh toÃ¡n ta sáº½ thay tháº¿ báº±ng Apache Spark). NgoÃ i ra vÃ¬ lÃ  project PoC (Proof of Concept), ta sáº½ Ä‘Æ¡n giáº£n hÃ³a Hadoop cluster vá»›i 1 Master Node, 1 Worker Node mÃ  thÃ´i. volumes:hadoop_datanode:hadoop_namenode:services:namenode:container_name:namenodeimage:apache/hadoop:3hostname:namenodecommand:bash -c \"if [ ! -f /tmp/hadoop-root/dfs/name/.formatted ]; then hdfs namenode -format \u0026\u0026 touch /tmp/hadoop-root/dfs/name/.formatted; fi \u0026\u0026 hdfs namenode\"ports:- 9870:9870- 8020:8020- 9000:9000user:rootenv_file:- .envvolumes:- hadoop_namenode:/tmp/hadoop-root/dfs/namenetworks:- docker-netdatanode:image:apache/hadoop:3container_name:datanodehostname:datanode command:[\"hdfs\",\"datanode\"]ports:- 9864:9864- 9866:9866expose:- 50010env_file:- .envuser:rootvolumes:- hadoop_datanode:/tmp/hadoop-root/dfs/datanetworks:- docker-netresourcemanager:image:apache/hadoop:3hostname:resourcemanagercommand:[\"yarn\",\"resourcemanager\"]ports:- 8088:8088env_file:- .envvolumes:- ./test.sh:/opt/test.shnetworks:- docker-netnodemanager:image:apache/hadoop:3command:[\"yarn\",\"nodemanager\"]env_file:- .envports:- 8188:8188networks:- docker-net Ta sáº½ chá»§ yáº¿u sá»­ dá»¥ng HDFS Ä‘á»ƒ lÃ m Datalake cho project nÃ y. NgoÃ i ra cÃ³ thá»ƒ truy cáº­p vÃ o cÃ¡c services cá»§a Hadoop thÃ´ng qua: Namenode: localhost:9870 Datanode: localhost:9864 Resouces Manager (YARN): localhost:8088 ","date":"10 Dec 2023","objectID":"/spotify_analysis/:3:1","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#apache-hadoop"},{"categories":["projects"],"content":"PrefectPrefect lÃ  má»™t orchestration tool khÃ¡ dá»… dÃ¹ng vÃ  dá»… báº¯t Ä‘áº§u. Vá»›i giao diá»‡n báº¯t máº¯t vÃ  tÃ­nh dá»… tiáº¿p cáº­n, framework nÃ y giÃºp cho viá»‡c lÃªn lá»‹ch, sáº¯p xáº¿p vÃ  cháº¡y cÃ¡c task hay tháº­m chÃ­ lÃ  cháº¡y song song (concurrent task). Ta sáº½ set up má»™t prefect server vÃ  prefect API báº±ng docker nhÆ° sau: prefect-server:build:context:./prefectimage:prefecthostname:prefect-servercontainer_name:prefect-servervolumes:- prefect:/root/.prefectcommand:prefect server startenvironment:- PREFECT_UI_URL=http://127.0.0.1:4200/api- PREFECT_API_URL=http://127.0.0.1:4200/api- PREFECT_SERVER_API_HOST=0.0.0.0ports:- 4200:4200networks:- docker-netprefect:image:prefect:latestcontainer_name:prefectrestart:alwaysvolumes:- \"./prefect/flows:/opt/prefect/flows\"- \"/etc/timezone:/etc/timezone:ro\"- \"/etc/localtime:/etc/localtime:ro\"env_file:- .envnetworks:- docker-netdepends_on:- prefect-server Táº¡i sao láº¡i set up Prefect Server vÃ  Prefect riÃªng vá»›i nhau ? CÃ³ nhiá»u lÃ½ do Ä‘á»ƒ chá»n set up riÃªng Prefect Server vÃ  Prefect riÃªng biá»‡t, nhÆ°ng thÆ°á»ng lÃ½ do quan trá»ng nháº¥t lÃ  ta muá»‘n tÃ¹y chá»‰nh mÃ´i trÆ°á»ng cháº¡y flow mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n server. Prefect Server sáº½ Ä‘Ã³ng vai trÃ² Backend xá»­ lÃ½ cÃ¡c tÃ­n hiá»‡u tá»« cÃ¡c container khÃ¡c thÃ´ng qua prefect API. Äiá»u nÃ y giÃºp tÄƒng tÃ­nh á»•n Ä‘á»‹nh cho há»‡ thá»‘ng vÃ  dá»… Ä‘á»ƒ báº£o trÃ¬, debug. VÃ  trong lÃºc setup, ta sáº½ khÃ´ng sá»­ dá»¥ng built-in image PrefectHQ mÃ  thay vÃ o Ä‘Ã³ sáº½ tá»± build má»™t custom image Ä‘á»ƒ cÃ³ thá»ƒ dá»… tÃ¹y biáº¿n. NgoÃ i cÃ¡c module cho python trong requirements.txt ta sáº½ cáº§n pháº£i config thÃªm Java 11 Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i pyspark ARG IMAGE_VARIANT=slim-busterARG OPENJDK_VERSION=11 ARG PYTHON_VERSION=3.11.0FROMpython:${PYTHON_VERSION}-${IMAGE_VARIANT} AS py3FROMopenjdk:${OPENJDK_VERSION}-${IMAGE_VARIANT}COPY --from=py3 / /WORKDIR/opt/prefectCOPY requirements.txt .RUN pip install -r requirements.txt --trusted-host pypi.python.org --no-cache-dirCOPY flows /opt/prefect/flows# Run our flow script when the container startsCMD [\"python\", \"flows/main_flow.py\"] Ta cÃ³ thá»ƒ truy cáº­p UI Prefect thÃ´ng qua localhost:4042 Ä‘á»ƒ trigger pipeline. ","date":"10 Dec 2023","objectID":"/spotify_analysis/:3:2","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#prefect"},{"categories":["projects"],"content":"DremioBÃ¢y giá» ta Ä‘Ã£ cÃ³ má»™t datalake lÃ  hadoop HDFS, tuy nhiÃªn Object Storange nhÆ° HDFS khÃ´ng cung cáº¥p kháº£ nÄƒng phÃ¢n tÃ­ch hay truy váº¥n, do Ä‘Ã³ ta sáº½ cáº§n xÃ¢y dá»±ng má»™t Analytic Layer trÃªn HDFS. á» vá»‹ trÃ­ nÃ y cÃ³ khÃ¡ nhiá»u lá»±a chá»n nhÆ° Trino, Hive,â€¦ Tuy nhiÃªn á»Ÿ project nÃ y ta sáº½ dÃ¹ng má»™t Lakehouse platform lÃ  Dremio. Dremio lÃ  má»™t mÃ£ nguá»“n má»Ÿ data-as-a-service há»— trá»£ phÃ¢n tÃ­ch vÃ  dá»… dÃ ng káº¿t ná»‘i vá»›i Ä‘a dáº¡ng nguá»“n data khÃ¡c nhau vÃ  táº¥t nhiÃªn trong Ä‘Ã³ cÃ³ Hadoop. Dremio cung cáº¥p kháº£ truy váº¥n máº¡nh máº½ vá»›i SQL engine vÃ  má»™t giao diá»‡n thÃ¢n thiá»‡n Dremio Cluster Ta sáº½ config má»™t dremio cluster vá»›i dremio-oss image. Image nÃ y bao gá»“m: Embedded Zookeeper Master Coordinator Execuor dremio:image:dremio/dremio-osshostname:dremiocontainer_name:dremiorestart:alwaysuser:rootvolumes:- dremio_data:/var/lib/dremio- dremio_data:/localFiles- dremio_data:/opt/dremioports:- \"9047:9047\"# Web UI (HTTP)- \"31010:31010\"# ODBC/JDBC client- \"32010:32010\"# Apache Arrow Flight clientsnetworks:- docker-net Sau khi deploy thÃ nh cÃ´ng, ta cÃ³ thá»ƒ Ä‘Äƒng nháº­p vÃ o dremio á»Ÿ localhost:9047 vá»›i username=dremio vÃ  password=dremio123 ","date":"10 Dec 2023","objectID":"/spotify_analysis/:3:3","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#dremio"},{"categories":["projects"],"content":"MongoDB with TerraformWarning á» bÆ°á»›c set up nÃ y cáº§n pháº£i Ä‘Äƒng kÃ½ tÃ i khoáº£n MongoDB Atlas vÃ  cÃ i Ä‘áº·t Terraform Vá» Terraform: HashiCorp Terraform lÃ  má»™t cÃ´ng cá»¥ â€œinsfrastructure as codeâ€ giÃºp ta setup vÃ  config nhá»¯ng tÃ i nguyÃªn cáº£ on-prem hay cloud chá»‰ vá»›i viá»‡c viáº¿t configuration file. MongoDB Atlas: cÃ³ thá»ƒ khÃ´ng cáº§n config trong docker compose vÃ  hoÃ n toÃ n cÃ³ thá»ƒ set up thá»§ cÃ´ng á»Ÿ ÄÃ¢y. Tuy nhiÃªn trong pháº§n nÃ y thÃ¬ ta sáº½ lÃ m Ä‘iá»u Ä‘Ã³ tá»± Ä‘á»™ng báº±ng Terraform. Äáº§u tiÃªn ta cÃ n pháº£i cÃ³ tÃ i khoáº£n MongoDB Atlas, sau Ä‘Ã³ bÆ°á»›c Ä‘áº§u tiÃªn lÃ  sáº½ set up vÃ i variables trong file variable.tf. File nÃ y sáº½ lÆ°u Ä‘a sá»‘ cÃ¡c biáº¿n mÃ´i trÆ°á»ng, API key, token,â€¦. Note Chi tiáº¿t cÃ¡ch set up file variable.tf cÃ³ thá»ƒ Ä‘á»c á»Ÿ ÄÃ¢y Vá»›i terraform, ta sáº½ chá»§ yáº¿u cháº¡y file main.tf vÃ¬ file nÃ y sáº½ lÆ°u má»i config vá» cluster muá»‘n deploy. Ta sáº½ sá»­ dá»¥ng MongoDB Atlas Provider vÃ  gá»i láº¡i cÃ¡c variables (Ä‘Æ°á»£c set trong file file variable.tf trÆ°á»›c Ä‘Ã³) terraform { required_providers { mongodbatlas = { source = \"mongodb/mongodbatlas\", version = \"1.8.0\" } } } provider \"mongodbatlas\" { public_key = var.public_key private_key = var.private_ke } Tip Chi tiáº¿t cÃ¡c resources cÃ³ thá»ƒ tham kháº£o táº¡i Ä‘Ã¢y mongodbatlas Provider terraform docs NgoÃ i ra ta cÅ©ng sáº½ táº¡o má»™t vÃ i resources khÃ¡c Ä‘á»ƒ hoÃ n thiá»‡n pháº§n setting up: mongdodbatlas_project: Config project khá»i táº¡o resource \"mongodbatlas_project\" \"spotify_project\" { name = \"spotify_project\" org_id = var.org_id is_collect_database_specifics_statistics_enabled = true is_data_explorer_enabled = true is_performance_advisor_enabled = true is_realtime_performance_panel_enabled = true is_schema_advisor_enabled = true } mongodbatlas_cluster: setup cluster cho atlas, ta sáº½ host trÃªn gcp (cÃ³ thá»ƒ chá»n azure hay aws Ä‘á»u Ä‘Æ°á»£c) resource \"mongodbatlas_cluster\" \"spotify\" { name = var.cluster_name project_id = mongodbatlas_project.spotify_project.id backing_provider_name = \"GCP\" provider_name = \"TENANT\" provider_instance_size_name = var.cluster_size provider_region_name = var.region } Cháº¡y lá»‡nh deploy cluster Sau khi Ä‘Ã£ chuáº©n bá»‹ hoÃ n táº¥t cÃ¡c configuration, viá»‡c cÃ²n láº¡i lÃ  cháº¡y cÃ¡c lá»‡nh tf cli Ä‘á»ƒ set up plan terraform init # set up provider for atlas terraform plan Sau Ä‘Ã³, nháº­p yes Ä‘á»ƒ tiáº¿p tá»¥c quÃ¡ trÃ¬nh set up. cuá»‘i dÃ¹ng Ä‘á»ƒ deploy cluster thÃ¬ ta sáº½ chá»‰ cáº§n nháº­p terraform apply. sau Ä‘Ã³ ta sáº½ nháº­n Ä‘Æ°á»£c káº¿t quáº£ giá»‘ng tháº¿ nÃ y Apply complete! Resources: 4 added, 0 changed, 0 destroyed. Outputs: password = \"123\" srv_address = \"mongodb+srv://spotify-cluster.kdglyul.mongodb.net\" user = \"root\" HÃ£y chÃº Ã½ cÃ¡c thÃ´ng tin á»Ÿ ba dÃ²ng cuá»‘i lÃ  password, srv_address vÃ  user. ta sáº½ cáº§n nhá»¯ng thÃ´ng tin nÃ y cho file .env Ä‘á»ƒ set up connection vá»›i Atlas sau nÃ y. ÄÃ³ sáº½ lÃ  cÃ¡c biáº¿n MONGODB_PASS, MONGODB_SRV vÃ  MONGODB_USER Tip Äá»ƒ xÃ³a má»i thá»© trÃªn mongodb atlas ká»ƒ cáº£ cluster thÃ¬ chá»‰ cáº§n cháº¡y lá»‡nh terraform destroy. hÃ£y cáº©n tháº­n vÃ¬ lá»‡nh nÃ y cÃ³ thá»ƒ xÃ³a háº¿t cluster vÃ  cáº£ data ","date":"10 Dec 2023","objectID":"/spotify_analysis/:3:4","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#mongodb-with-terraform"},{"categories":["projects"],"content":"Pipeline 1Data pipeline nÃ y thá»±c hiá»‡n viá»‡c chÃ­nh lÃ  pooling api Ä‘á»ƒ crawl data tá»« spotify api vÃ  incremental load data vÃ o mongodb atlas. Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» vá» rate limit, ta sáº½ config cho flow nÃ y Ä‘Æ°á»£c tá»± Ä‘á»™ng trigger má»—i 2 phÃºt 5 giÃ¢y Ä‘á»ƒ crawl má»™t batch gá»“m láº§n lÆ°á»£t thÃ´ng tin 5 artists tá»« file danh sÃ¡ch artists.txt Incremental load KhÃ¡c vá»›i full load khi ta load data vÃ  overwrite táº¥t cáº£ trong database , incremental load hay Ä‘Æ°á»£c gá»i lÃ  delta load thá»±c hiá»‡n viá»‡c chá»‰ load pháº§n data update hoáº·c data má»›i mÃ  khÃ´ng load láº¡i táº¥t cáº£ cÃ¡c historical data trÆ°á»›c Ä‘Ã³. pipeline nÃ y sáº½ luÃ´n cÃ o vÃ  ingest thÃ´ng tin nghá»‡ sÄ© má»›i nháº¥t trong file artists.txt Ä‘á»ƒ gá»i spotify api qua má»—i batch vÃ  dÃ¹ng má»™t file log.txt Ä‘á»ƒ Ä‘Ã¡nh dáº¥u vá»‹ trÃ­ index vÃ  sá»‘ lÆ°á»£ng nghá»‡ sÄ© Ä‘Ã£ cÃ o thÃ nh cÃ´ng ","date":"10 Dec 2023","objectID":"/spotify_analysis/:4:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#pipeline-1"},{"categories":["projects"],"content":"Pipeline 2ÄÃ¢y lÃ  pháº§n chÃ­nh cá»§a project nÃ y vÃ  háº§u háº¿t cÃ¡c tÃ¡c vá»¥ xá»­ lÃ½ sáº½ thá»±c hiá»‡n trong pipeline nÃ y. Pipeline nÃ y chÃ­nh lÃ  má»™t ELT (Extract - Load - Transform) data pipeline vá»›i nguá»“n raw lÃ  cÃ¡c collections tá»« MongoDB, sau Ä‘Ã³ sáº½ Ä‘Æ°á»£c xá»­ lÃ½ báº±ng spark vÃ  lÆ°u trong hdfs. Ta Ä‘á»“ng thá»i sáº½ xÃ¢y dá»±ng má»™t Medallion architecture ngay trong hdfs Ä‘á»ƒ phÃ¢n vÃ¹ng cho cÃ¡c loáº¡i data. Medallion architecture kiáº¿n trÃºc nÃ y Ä‘Æ°á»£c Databricks giá»›i thiá»‡u lÃ  má»™t â€œdata design patternâ€ dÃ¹ng Ä‘á»ƒ tá»• chá»©c data trong lakehouse vá»›i má»¥c tiÃªu lÃ  Ä‘á»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng data qua tá»«ng layer cá»§a kiáº¿n trÃºc nÃ y (bronze -\u003e silver -\u003e gold) ","date":"10 Dec 2023","objectID":"/spotify_analysis/:5:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#pipeline-2"},{"categories":["projects"],"content":"PySparkApache Spark Ä‘Æ°á»£c set up á»Ÿ Ä‘Ã¢u ? CÃ³ láº½ báº¡n sáº½ tháº¯c máº¯c táº¡i sao khÃ´ng tháº¥y Apache Spark Ä‘Æ°á»£c set up. cÃ³ 2 lÃ½ do: TÃ i nguyÃªn háº¡n cháº¿: Ä‘á»‘i vá»›i project hiá»‡n táº¡i khi Ä‘Ã£ cÃ³ quÃ¡ nhiá»u services Ä‘Æ°á»£c cháº¡y cÃ¹ng lÃºc bá»Ÿi docker containers, set up thÃªm spark cluster cÃ³ thá»ƒ sáº½ quÃ¡ táº£i vÃ  khÃ´ng Ä‘á»§ tÃ i nguyÃªn Ä‘á»ƒ deploy táº¥t cáº£. Data nhá»: thÃ nh thá»±c thÃ¬ sá»‘ lÆ°á»£ng data pháº£i process khÃ´ng thá»±c sá»± quÃ¡ lá»›n (khoáº£ng hÆ¡n 200k quan sÃ¡t) thÃ¬ viá»‡c sá»­ dá»¥ng spark cÃ³ thá»ƒ sáº½ lÃ£ng phÃ­ tÃ i nguyÃªn. tuy nhiÃªn vÃ¬ má»¥c Ä‘Ã­ch há»c táº­p vÃ  thá»±c hiá»‡n project poc, ta sáº½ sá»­ dá»¥ng spark vá»›i local mode thay vÃ¬ set up standardlone mode vá»›i cluster Apache Spark cÃ³ nhiá»u cháº¿ Ä‘á»™ cháº¡y mÃ  ta cÃ³ thá»ƒ tÃ¹y vÃ o quy mÃ´ project mÃ  sá»­ dá»¥ng: local[*]: lÃ  cháº¿ Ä‘á»™ local, cháº¿ Ä‘á»™ nÃ y cho phÃ©p cháº¡y mÃ  khÃ´ng cáº§n pháº£i setup spark cluster spark://{master-node-name}:7077: cháº¿ Ä‘á»™ standalone vÃ  ta sáº½ káº¿t ná»‘i vá»›i má»™t spark cluster yarn-client: cháº¿ Ä‘á»™ yarn-client yarn-cluster: cháº¿ Ä‘á»™ yarn-cluster mesos://host:5050: mesos cluster VÃ  á»Ÿ project nÃ y ta sáº½ sá»­ dá»¥ng local mode Ä‘á»ƒ tá»‘i Æ°u tÃ i nguyÃªn cÅ©ng nhÆ° phÃ¹ há»£p vá»›i kÃ­ch thÆ°á»›c dataset. Ä‘á»ƒ tiá»‡n lá»£i cho viá»‡c táº¡o SparkSession, ta sáº½ viáº¿t má»™t sparkIO báº±ng contextlib from pyspark.sql import SparkSession from pyspark import SparkConf from contextlib import contextmanager @contextmanager def SparkIO(conf: SparkConf = SparkConf()): app_name = conf.get(\"spark.app.name\") master = conf.get(\"spark.master\") print(f'Create SparkSession app {app_name}with {master}mode') spark = SparkSession.builder.config(conf=conf).getOrCreate() try: yield spark except Exception: raise Exception finally: print(f'Stop SparkSession app {app_name}') spark.stop() Ä‘iá»u nÃ y giÃºp Ä‘Æ¡n giáº£n hÃ³a viá»‡c táº¡o sparksession vÃ  táº¯t spark trá»Ÿ nÃªn Ä‘Æ¡n giáº£n vÃ  trÃ¡nh thiáº¿u sÃ³t Tip Ta cÅ©ng cÃ³ thá»ƒ lÃ m tÆ°Æ¡ng tá»± cho viá»‡c káº¿t ná»‘i vá»›i mongodb báº±ng cÃ¡ch viáº¿t má»™t mongodb_io from pymongo import MongoClient from pymongo.errors import ConnectionFailure from contextlib import contextmanager import os @contextmanager def MongodbIO(): user = os.getenv(\"MONGODB_USER\") password = os.getenv(\"MONGODB_PASSWORD\") cluster = os.getenv(\"MONGODB_SRV\") cluster = cluster.split(\"//\")[-1] uri = f\"mongodb+srv://{user}:{password}@{cluster}/?retryWrites=true\u0026w=majority\" try: client = MongoClient(uri) print(f\"MongoDB Connected\") yield client except ConnectionFailure: print(f\"Failed to connect with MongoDB\") raise ConnectionFailure finally: print(\"Close connection to MongoDB\") client.close() ","date":"10 Dec 2023","objectID":"/spotify_analysis/:5:1","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#pyspark"},{"categories":["projects"],"content":"Data Processingta sáº½ xÃ¢y dá»±ng hdfs theo kiáº¿n trÃºc meddalion báº±ng cÃ¡ch chia data quality thÃ nh cÃ¡ch vÃ¹ng (hay directory): Bronze layer: dÃ¹ng Ä‘á»ƒ chá»‰ lÆ°u raw data Silver layer: lÆ°u data Ä‘Ã£ xá»­ lÃ½ má»™t pháº§n (xá»­ lÃ½ kiá»ƒu dá»¯ liá»‡u, xá»­ lÃ½ kiá»ƒu array vÃ  cÃ¡c cáº¥u trÃºc lá»“ng phá»©c táº¡p) tá»« Bronze Layer Gold layer: lÆ°u data Ä‘Ã£ Ä‘Æ°á»£c lÃ m sáº¡ch sau khi chuáº©n hÃ³a dá»¯ liá»‡u vÃ  lÃ m sáº¡ch cÃ¡c báº£ng má»›i tá»« Silver Layer ","date":"10 Dec 2023","objectID":"/spotify_analysis/:5:2","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#data-processing"},{"categories":["projects"],"content":"Analytic layerNhÆ° Ä‘Ã£ setup tá»« trÆ°á»›c, ta sáº½ sá»­ dá»¥ng dremio nhÆ° má»™t analytic layer Ä‘á»ƒ cÃ³ thá»ƒ phÃ¢n tÃ­ch trÃªn data sáº¡ch á»Ÿ gold layer trong HDFS. Viá»‡c Ä‘Æ¡n giáº£n lÃ  ta chá»‰ cáº§n káº¿t ná»‘i dremio Ä‘áº¿n HDFS qua dremio UI á»Ÿ localhost:9047 vÃ  sau Ä‘Ã³ format file .parquet á»Ÿ thÆ° má»¥c gold_layer vÃ  ta cÃ³ thá»ƒ viáº¿t cÃ¡c cÃ¢u lá»‡nh sql query Ä‘á»ƒ báº¯t Ä‘áº§u phÃ¢n tÃ­ch Ä‘Æ°á»£c rá»“i ","date":"10 Dec 2023","objectID":"/spotify_analysis/:6:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#analytic-layer"},{"categories":["projects"],"content":"Machine learning and DashboardÄáº¿n Ä‘Ã¢y cÃ³ thá»ƒ coi nhÆ° lÃ  káº¿t thÃºc pháº§n viá»‡c cá»§a má»™t data engineer, ta sáº½ báº¯t Ä‘áº§u cÃ¡c tasks cá»§a má»™t data scientist vÃ  data analyst trong viá»‡c xÃ¢y dá»±ng mÃ´ hÃ¬nh mÃ¡y há»c vÃ  xÃ¢y dá»±ng report. ","date":"10 Dec 2023","objectID":"/spotify_analysis/:7:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#machine-learning-and-dashboard"},{"categories":["projects"],"content":"K-Nearest Neighbors (KNN)Ta sáº½ xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh cÃ³ thá»ƒ gá»£i Ã½ nháº¡c dá»±a trÃªn Ä‘á»™ giá»‘ng nhau giá»¯a cÃ¡c features cá»§a nhá»¯ng báº£n nháº¡c nhÆ°: Ä‘á»™ lá»›n, giai Ä‘iá»‡u, thá»ƒ loáº¡i, tempo, má»©c Ä‘á»™ sÃ´i Ä‘á»™ng,â€¦ Äá»ƒ lÃ m Ä‘Æ°á»£c viá»‡c Ä‘Ã³ ta sáº½ sá»­ dá»¥ng má»™t mÃ´ hÃ¬nh cÃ³ thá»ƒ Ä‘Æ°a ra Ä‘Æ°á»£c top k cÃ¡c record khÃ¡c nhau tá»« danh sÃ¡ch hÃ ng trÄƒm nghÃ¬n bÃ i hÃ¡t. ÄÃ³ lÃ  KNN KNN lÃ  má»™t mÃ´ hÃ¬nh há»c mÃ¡y Ä‘Æ¡n giáº£n giÃºp ta tÃ¬m Ä‘Æ°á»£c top nhá»¯ng Ä‘iá»ƒm data gáº§n nháº¥t vá»›i vá»‹ trÃ­ data point Ä‘áº§u vÃ o dá»±a trÃªn khoáº£ng cÃ¡ch cá»§a chÃºng trong khÃ´ng gian vector. Similarity Metric láº§n nÃ y ta sá»­ dá»¥ng sáº½ lÃ  Ä‘á»™ tÆ°Æ¡ng tá»± consine hay consine similarity $$ S_C(A,B) = cos(\\theta) = \\frac{A \\cdot B}{\\Vert A\\Vert \\Vert B \\Vert} = \\frac{\\sum^n_{i=1}A_iB_i}{\\sqrt{\\sum^n_{i=1}A^2} \\cdot \\sqrt{\\sum^n_{i=1}B^2} } $$ Ta sáº½ xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh gá»£i Ã½ top k cÃ¡c bÃ i hÃ¡t giá»‘ng nháº¥t vá»›i bÃ i hÃ¡t lá»±a chá»n nhÆ° sau: class SongRecommendationSystem: def __init__(self, client, options): self.client = client self.options = options self.knn_model = NearestNeighbors(metric='cosine') def fit(self, table_name): matrix_table = self._get_table(table_name).values self.knn_model.fit(matrix_table) def _get_table(self, table_name): sql = f\"select * from {table_name}\" return self.client.query(sql, self.options) def recommend_songs(self, track_name: str, table_name='home.searchs', num_recommendations=5): song_library = self._get_table(table_name).reset_index(drop=True) if track_name not in song_library['track_name'].values: print(f'Track \"{track_name}\" not found in the dataset.') return None features_matrix = self._get_table('home.model') track_index = song_library.index[song_library['track_name'] == track_name].tolist()[0] _, indices = self.knn_model.kneighbors([features_matrix.iloc[track_index]], n_neighbors=num_recommendations + 1) return song_library.loc[indices[0][1:], :] Khi thá»­ tÃ¬m cÃ¡c bÃ i hÃ¡t giá»‘ng vá»›i â€œSomething Just Like Thisâ€ (cÃ³ váº» cÅ©ng chÆ°a tá»‘t láº¯m ğŸ˜‚) ","date":"10 Dec 2023","objectID":"/spotify_analysis/:7:1","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#k-nearest-neighbors-knn"},{"categories":["projects"],"content":"PowerBI DashboardKhi cÃ³ ráº¥t nhiá»u data sáº¡ch, Ä‘iá»u tiáº¿p theo ta cÃ³ thá»ƒ nghÄ© Ä‘áº¿n chÃ­nh lÃ  lÃ m sao tháº¥y Ä‘Æ°á»£c nhiá»u insight giÃ¡ trá»‹ nháº¥t tá»« data Ä‘Ã³. ÄÃ¢y lÃ  lÃºc ta cÃ³ thá»ƒ dÃ¹ng PowerBI Ä‘á»ƒ xÃ¢y dá»±ng Dashboard tá»« Dremio ","date":"10 Dec 2023","objectID":"/spotify_analysis/:7:2","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#powerbi-dashboard"},{"categories":["projects"],"content":"ApplicationCuá»‘i cÃ¹ng, ta cÃ³ thá»ƒ xÃ¢y dá»±ng má»™t á»©ng dá»¥ng Ä‘Æ¡n giáº£n Ä‘á»ƒ á»©ng dá»¥ng mÃ´ hÃ¬nh machine learning cÅ©ng nhÆ° nhÆ° tÃ­ch há»£p Dashboard vÃ o trong á»©ng dá»¥ng nÃ y nhÆ° má»™t portal toÃ n diá»‡n. Ta sáº½ sá»­ dá»¥ng Streamlit Ä‘á»ƒ xÃ¢y dá»±ng má»™t web app Ä‘Æ¡n giáº£n ","date":"10 Dec 2023","objectID":"/spotify_analysis/:8:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#application"},{"categories":["projects"],"content":"Final ThoughtsProject chá»‰ mang tÃ­nh cháº¥t há»c táº­p, do Ä‘Ã³ Ä‘á»™ lá»›n cá»§a data hay má»™t sá»‘ kiáº¿n trÃºc set up cÃ³ thá»ƒ chÆ°a hoÃ n chá»‰nh. Tuy nhiÃªn Ä‘Ã¢y váº«n lÃ  má»™t cá»™t má»‘c Ä‘Ã¡ng nhá»› trong hÃ nh trÃ¬nh há»c táº­p cá»§a OG. Hy vá»ng nÃ³ sáº½ giÃºp Ã­ch cho cÃ¡c báº¡n tham kháº£o ğŸ˜„ -Meww- ","date":"10 Dec 2023","objectID":"/spotify_analysis/:9:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#final-thoughts"},{"categories":["projects"],"content":"Related Stock Analysis Basic analyzing vn30 stock using pca and k-means Read more... Football ETL Analysis A Data Engineer project building pipeline to analyze football data Read more... ","date":"10 Dec 2023","objectID":"/spotify_analysis/:0:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis/#related"},{"categories":null,"content":"A End to End ELT data pipeline to Analyze Spotify Data and build recommendation system","date":"10 Dec 2023","objectID":"/spotify_analysis_en/","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/"},{"categories":null,"content":"Shout out for our dedicated members This project is contributed by: Ngá»c Tuáº¥n (Data Engineer), Duy SÆ¡n (Data Scientist), VÄ© ThiÃªn (Data Analyst) PhongHuynh0394 Spotify Analysis with PySpark Vietnamese Version Available Hello! Hello! Itâ€™s OG again. This time weâ€™ll be building an End-to-End ELT data pipeline and a Recommender System based on analytics from the Spotify API. Without further ado, letâ€™s get started. ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:0:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#"},{"categories":null,"content":"IntroductionThis project involves building a music analytics system from Spotify, as shown in the diagram below: The diagram includes the following components: Infrastructure: We will use Docker to set up most of the frameworks used in the system and optionally use Terraform to set up MongoDB. Pipeline 1: This pipeline performs incremental loading into MongoDB each time data is pulled from the Spotify API. Pipeline 2: This data pipeline performs ELT (Extract, Load, Transform) to process and normalize JSON data from MongoDB. Most of the work dealing with the complex, nested JSON structure will be handled by PySpark (Python API for Apache Spark) on HDFS (Hadoop Distributed File System). Analytic Layer: To analyze the data, we will apply an analytics layer on top of Hadoop. In this project, we will use Dremio for that. Machine learning and Dashboard: This part involves training a machine learning model for the Spotify music recommendation system. Additionally, we can use PowerBI to create dashboards to analyze data from Dremio. Application: Finally, we will use Streamlit to build a simple web application for the music recommendation and search system. Users can also interact with the BI Dashboard at this layer. ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:1:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#introduction"},{"categories":null,"content":"Data SchemaOur data source comes from the Spotify API. We will also scrape a list of Spotify artists from Sportify Artists. The final processed data will have the following schema: ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:2:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#data-schema"},{"categories":null,"content":"InfrastructureWe will primarily use Docker to configure most of the frameworks in the system via a docker-compose.yml file. MongoDB Atlas, however, can be set up in multiple ways. ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:3:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#infrastructure"},{"categories":null,"content":"Apache HadoopFirst, we will set up Apache Hadoop using Docker Compose. As we know, Hadoop is a Java-based framework introduced by Google in 2006 that leverages distributed system technology to store and process Big Data. Hadoop is built on three main components: HDFS (Hadoop Distributed File System): A distributed file system used for data storage. YARN (Yet Another Resource Negotiator): A resource management framework for running applications on Hadoop. MapReduce: A parallel data processing framework in a distributed system environment. HDFS and YARN in Hadoop In this project, we will simplify the setup by omitting the MapReduce component in the Hadoop Cluster and only using HDFS and YARN (since we will use Apache Spark for processing). Additionally, as this is a PoC (Proof of Concept) project, we will simplify the Hadoop cluster to just one Master Node and one Worker Node. volumes:hadoop_datanode:hadoop_namenode:services:namenode:container_name:namenodeimage:apache/hadoop:3hostname:namenodecommand:bash -c \"if [ ! -f /tmp/hadoop-root/dfs/name/.formatted ]; then hdfs namenode -format \u0026\u0026 touch /tmp/hadoop-root/dfs/name/.formatted; fi \u0026\u0026 hdfs namenode\"ports:- 9870:9870- 8020:8020- 9000:9000user:rootenv_file:- .envvolumes:- hadoop_namenode:/tmp/hadoop-root/dfs/namenetworks:- docker-netdatanode:image:apache/hadoop:3container_name:datanodehostname:datanode command:[\"hdfs\",\"datanode\"]ports:- 9864:9864- 9866:9866expose:- 50010env_file:- .envuser:rootvolumes:- hadoop_datanode:/tmp/hadoop-root/dfs/datanetworks:- docker-netresourcemanager:image:apache/hadoop:3hostname:resourcemanagercommand:[\"yarn\",\"resourcemanager\"]ports:- 8088:8088env_file:- .envvolumes:- ./test.sh:/opt/test.shnetworks:- docker-netnodemanager:image:apache/hadoop:3command:[\"yarn\",\"nodemanager\"]env_file:- .envports:- 8188:8188networks:- docker-net We will primarily use HDFS as the Data Lake for this project. Additionally, you can access Hadoop services through: Namenode: localhost:9870 Datanode: localhost:9864 Resource Manager (YARN): localhost:8088 ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:3:1","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#apache-hadoop"},{"categories":null,"content":"PrefectPrefect is an easy-to-use orchestration tool with an attractive interface that simplifies task scheduling, organization, and parallel (concurrent) task execution. We will set up a Prefect server and API using Docker: prefect-server:build:context:./prefectimage:prefecthostname:prefect-servercontainer_name:prefect-servervolumes:- prefect:/root/.prefectcommand:prefect server startenvironment:- PREFECT_UI_URL=http://127.0.0.1:4200/api- PREFECT_API_URL=http://127.0.0.1:4200/api- PREFECT_SERVER_API_HOST=0.0.0.0ports:- 4200:4200networks:- docker-netprefect:image:prefect:latestcontainer_name:prefectrestart:alwaysvolumes:- \"./prefect/flows:/opt/prefect/flows\"- \"/etc/timezone:/etc/timezone:ro\"- \"/etc/localtime:/etc/localtime:ro\"env_file:- .envnetworks:- docker-netdepends_on:- prefect-server Why separate Prefect Server and Prefect? There are several reasons for separating Prefect Server from Prefect, but the most important is to allow customization of the flow environment without affecting the server. The Prefect Server acts as the backend, processing signals from other containers via the Prefect API. This improves system stability and makes it easier to maintain and debug. Instead of using the built-in image from PrefectHQ, we will build a custom image to allow easier customization. In addition to the Python modules in requirements.txt, we will configure Java 11 for PySpark compatibility: ARG IMAGE_VARIANT=slim-busterARG OPENJDK_VERSION=11 ARG PYTHON_VERSION=3.11.0FROMpython:${PYTHON_VERSION}-${IMAGE_VARIANT} AS py3FROMopenjdk:${OPENJDK_VERSION}-${IMAGE_VARIANT}COPY --from=py3 / /WORKDIR/opt/prefectCOPY requirements.txt .RUN pip install -r requirements.txt --trusted-host pypi.python.org --no-cache-dirCOPY flows /opt/prefect/flows# Run our flow script when the container startsCMD [\"python\", \"flows/main_flow.py\"] We can access the Prefect UI at localhost:4042 to trigger the pipeline. ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:3:2","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#prefect"},{"categories":null,"content":"DremioNow that we have a data lake in Hadoop HDFS, we need an Analytic Layer to analyze or query the data, as HDFS does not provide these capabilities. We have various options such as Trino or Hive, but in this project, we will use Dremio, a Lakehouse platform. Dremio is an open-source data-as-a-service platform that supports analytics and can easily connect with various data sources, including Hadoop. Dremio provides powerful query capabilities with its SQL engine and a user-friendly interface: Dremio Cluster We will configure a Dremio cluster using the dremio-oss image, which includes: Embedded Zookeeper Master Coordinator Executor dremio:image:dremio/dremio-osshostname:dremiocontainer_name:dremiorestart:alwaysuser:rootvolumes:- dremio_data:/var/lib/dremio- dremio_data:/localFiles- dremio_data:/opt/dremioports:- \"9047:9047\"# Web UI (HTTP)- \"31010:31010\"# ODBC/JDBC client- \"32010:32010\"# Apache Arrow Flight clientsnetworks:- docker-net After successfully deployed, we can access Dremio UI at localhost:9047 with username=dremio and password=dremio123 ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:3:3","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#dremio"},{"categories":null,"content":"MongoDB with TerraformWarning In this setup step, you need to register for a MongoDB Atlas account and install Terraform. About Terraform: HashiCorp Terraform is an â€œinfrastructure as codeâ€ tool that allows us to set up and configure resources, whether on-prem or in the cloud, simply by writing configuration files. MongoDB Atlas: You can manually configure MongoDB without Docker Compose via this link. However, in this section, we will automate the setup using Terraform. First, you need a MongoDB Atlas account. The next step is to set up some variables in the variable.tf file. This file will store most of the environment variables, API keys, tokens, etc. Note You can find details on how to set up the variable.tf file here With Terraform, weâ€™ll primarily run the main.tf file because it contains all the configuration to deploy the cluster. Weâ€™ll use the MongoDB Atlas Provider and refer to the variables defined in variable.tf as follows: terraform { required_providers { mongodbatlas = { source = \"mongodb/mongodbatlas\", version = \"1.8.0\" } } } provider \"mongodbatlas\" { public_key = var.public_key private_key = var.private_ke } Tip You can refer to detailed resources for the MongoDB Atlas provider here. Next, weâ€™ll create a few resources to complete the setup: mongodbatlas_project: This resource sets up the project. resource \"mongodbatlas_project\" \"spotify_project\" { name = \"spotify_project\" org_id = var.org_id is_collect_database_specifics_statistics_enabled = true is_data_explorer_enabled = true is_performance_advisor_enabled = true is_realtime_performance_panel_enabled = true is_schema_advisor_enabled = true } mongodbatlas_cluster: This resource sets up the MongoDB Atlas cluster. We will host it on GCP, but you can also choose Azure or AWS. resource \"mongodbatlas_cluster\" \"spotify\" { name = var.cluster_name project_id = mongodbatlas_project.spotify_project.id backing_provider_name = \"GCP\" provider_name = \"TENANT\" provider_instance_size_name = var.cluster_size provider_region_name = var.region } Deploy the Cluster Once the configuration is ready, you can run Terraform CLI commands to set up the plan: terraform init # set up provider for atlas terraform plan Then, type yes to proceed with the setup. To deploy the cluster, just enter terraform apply. The result will look like this: Apply complete! Resources: 4 added, 0 changed, 0 destroyed. Outputs: password = \"123\" srv_address = \"mongodb+srv://spotify-cluster.kdglyul.mongodb.net\" user = \"root\" Pay attention to the information in the last three lines: password, srv_address, and user. These details will be needed for the .env file to set up the connection with MongoDB Atlas later. These will be the MONGODB_PASS, MONGODB_SRV and MONGODB_USER. Tip To delete everything from MongoDB Atlas, including the cluster, you only need to run terraform destroy. Be cautious, as this command will remove the entire cluster and all data. ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:3:4","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#mongodb-with-terraform"},{"categories":null,"content":"Pipeline 1This data pipeline performs API pooling to crawl data from the Spotify API and incrementally loads it into MongoDB Atlas. To handle the rate limit issue, we configure this flow to automatically trigger every 2 minutes and 5 seconds, crawling a batch of information for 5 artists from the artists.txt file. Incremental Load Unlike full load, which overwrites all data in the database, incremental load (or delta load) only loads updated or new data without reloading all historical data. This pipeline will always fetch and ingest the latest artist information from the artists.txt file by calling the Spotify API in batches and using a log.txt file to track the index and number of artists successfully crawled. ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:4:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#pipeline-1"},{"categories":null,"content":"Pipeline 2This is the main part of the project where most of the processing takes place. It follows an ELT (Extract - Load - Transform) pipeline model with raw data from MongoDB collections, which is then processed with Spark and stored in HDFS. We will also build a Medallion Architecture within HDFS to partition the data. Medallion Architecture This architecture, introduced by Databricks, is a â€œdata design patternâ€ used to organize data in a Lakehouse to improve data quality through its layers (Bronze -\u003e Silver -\u003e Gold). ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:5:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#pipeline-2"},{"categories":null,"content":"PySparkWhere is Apache Spark set up? You might wonder why Apache Spark is not set up. There are two reasons: Limited resources: With many services running simultaneously via Docker containers, setting up an additional Spark Cluster might exceed resource limits. Small dataset: The dataset size is relatively small (around 200K observations), so using Spark could be overkill. However, for learning purposes, we will use Spark in local mode rather than setting up a standalone cluster. Apache Spark offers several running modes depending on project scale: local[*]: Local mode, no need for a Spark Cluster setup. spark://{master-node-name}:7077: Standalone mode, connecting to a Spark Cluster yarn-client: Yarn-client mode yarn-cluster: Yarn-cluster mode mesos://host:5050: Mesos cluster For this project, we will use local mode to optimize resources. To simplify creating and stopping SparkSessions, we write a SparkIO using contextlib from pyspark.sql import SparkSession from pyspark import SparkConf from contextlib import contextmanager @contextmanager def SparkIO(conf: SparkConf = SparkConf()): app_name = conf.get(\"spark.app.name\") master = conf.get(\"spark.master\") print(f'Create SparkSession app {app_name}with {master}mode') spark = SparkSession.builder.config(conf=conf).getOrCreate() try: yield spark except Exception: raise Exception finally: print(f'Stop SparkSession app {app_name}') spark.stop() This approach simplifies the creation and termination of SparkSessions, ensuring we donâ€™t miss any steps. Tip We can do something similar for MongoDB connections by writing a MongoDB_io from pymongo import MongoClient from pymongo.errors import ConnectionFailure from contextlib import contextmanager import os @contextmanager def MongodbIO(): user = os.getenv(\"MONGODB_USER\") password = os.getenv(\"MONGODB_PASSWORD\") cluster = os.getenv(\"MONGODB_SRV\") cluster = cluster.split(\"//\")[-1] uri = f\"mongodb+srv://{user}:{password}@{cluster}/?retryWrites=true\u0026w=majority\" try: client = MongoClient(uri) print(f\"MongoDB Connected\") yield client except ConnectionFailure: print(f\"Failed to connect with MongoDB\") raise ConnectionFailure finally: print(\"Close connection to MongoDB\") client.close() ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:5:1","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#pyspark"},{"categories":null,"content":"Data ProcessingWe will organize HDFS using the Medallion architecture, dividing data quality into different zones (or directories): Bronze Layer: Stores raw data. Silver Layer: Stores partially processed data (handling data types, arrays, and complex nested structures) from the Bronze Layer. Gold Layer: Stores cleaned data after standardizing and cleaning the tables from the Silver Layer. ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:5:2","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#data-processing"},{"categories":null,"content":"Analytic LayerAs previously set up, we will use Dremio as an analytic layer to analyze the clean data stored in the Gold Layer within HDFS. The process is straightforward: connect Dremio to HDFS through the Dremio UI at localhost:9047. Then, format the .parquet files in the golde_layer directory, and youâ€™ll be able to write SQL queries to start analyzing the data. ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:6:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#analytic-layer"},{"categories":null,"content":"Machine Learning and DashboardAt this point, the responsibilities of a Data Engineer are largely complete. We will now move on to the tasks of a Data Scientist and Data Analyst, focusing on building machine learning models and generating reports. ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:7:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#machine-learning-and-dashboard"},{"categories":null,"content":"K-Nearest Neighbors (KNN)We will develop a model to recommend music based on the similarity of features between songs, such as loudness, melody, genre, tempo, energy level, and more. To achieve this, we will use a model that can return the top K most similar records from a list of hundreds of thousands of songs. This model is KNN KNN is a simple machine learning model that helps us find the closest data points to the input data point based on their distance in vector space. The similarity metric we will use is cosine similarity: $$ S_C(A,B) = cos(\\theta) = \\frac{A \\cdot B}{\\Vert A\\Vert \\Vert B \\Vert} = \\frac{\\sum^n_{i=1}A_iB_i}{\\sqrt{\\sum^n_{i=1}A^2} \\cdot \\sqrt{\\sum^n_{i=1}B^2} } $$ We will build a model to recommend the top K songs most similar to a selected song as follows: class SongRecommendationSystem: def __init__(self, client, options): self.client = client self.options = options self.knn_model = NearestNeighbors(metric='cosine') def fit(self, table_name): matrix_table = self._get_table(table_name).values self.knn_model.fit(matrix_table) def _get_table(self, table_name): sql = f\"select * from {table_name}\" return self.client.query(sql, self.options) def recommend_songs(self, track_name: str, table_name='home.searchs', num_recommendations=5): song_library = self._get_table(table_name).reset_index(drop=True) if track_name not in song_library['track_name'].values: print(f'Track \"{track_name}\" not found in the dataset.') return None features_matrix = self._get_table('home.model') track_index = song_library.index[song_library['track_name'] == track_name].tolist()[0] _, indices = self.knn_model.kneighbors([features_matrix.iloc[track_index]], n_neighbors=num_recommendations + 1) return song_library.loc[indices[0][1:], :] When testing the system to find songs similar to â€œSomething Just Like Thisâ€ (itâ€™s not perfect yet! ğŸ˜…): ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:8:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#k-nearest-neighbors-knn"},{"categories":null,"content":"PowerBI DashboardWith a large amount of clean data, the next logical step is to derive valuable insights from that data. This is where PowerBI comes into play, allowing us to create a dashboard using data from Dremio. ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:8:1","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#powerbi-dashboard"},{"categories":null,"content":"ApplicationFinally, we can build a simple application to implement the machine learning model and integrate the dashboard into this application, creating a comprehensive portal. We will use Streamlit to build a simple web app. ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:9:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#application"},{"categories":null,"content":"Final ThoughtsThis project is primarily for learning purposes, so the dataset size and some architectural setups may not be fully complete. However, this marks an important milestone in OGâ€™s learning journey. Hopefully, it will be helpful as a reference for others! ğŸ˜„ -Meww- ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:10:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#final-thoughts"},{"categories":null,"content":"Related Stock Analysis Basic analyzing VN30 stock using PCA and K-Means Read more... Football ETL Analysis A Data Engineer project building pipeline to analyze football data Read more... ","date":"10 Dec 2023","objectID":"/spotify_analysis_en/:0:0","series":[],"tags":["streamlit","API","ELT","Data Engineer","Machine Learning","Distributed System","Hadoop","Spark","Docker","Terraform","Visualization","PowerBI"],"title":"Spotify Analysis","uri":"/spotify_analysis_en/#related"},{"categories":[],"content":"Khi biáº¿t Ä‘áº¿n Linux, tÃ´i Ä‘Ã£ yÃªu em lÃºc nÃ o khÃ´ng hay","date":"27 Sep 2023","objectID":"/linux/","series":["Data lÃº"],"tags":[],"title":"Linux - tiáº¿ng sÃ©t Ã¡i tÃ¬nh","uri":"/linux/"},{"categories":[],"content":"Xin chÃ o xin chÃ o lÃ  OG Ä‘Ã¢yy ! á» bÃ i trÆ°á»›c OG Ä‘Ã£ ká»ƒ cho cÃ¡c báº¡n nghe vá» cÃ¡c khÃ¡i niá»‡m cÆ¡ báº£n trong ngÃ nh Data rá»“i. Tháº¿ thÃ¬ á»Ÿ sá»‘ nÃ y mÃ¬nh sáº½ nÃ³i nhiá»u hÆ¡n vá» viÃªn gáº¡ch Ä‘áº§u tiÃªn khi mÃ¬nh Ä‘áº¿n vá»›i Data Engineer. ÄÃ³ chÃ­nh lÃ  viá»‡c mÃ¬nh biáº¿t Ä‘áº¿n há»‡ Ä‘iá»u hÃ nh Linux, ká»ƒ tá»« Ä‘Ã³ cuá»™c Ä‘á»i mÃ¬nh Ä‘á»•i thay. Lets goo! ","date":"27 Sep 2023","objectID":"/linux/:0:0","series":["Data lÃº"],"tags":[],"title":"Linux - tiáº¿ng sÃ©t Ã¡i tÃ¬nh","uri":"/linux/#"},{"categories":[],"content":"QuÃ¡ khá»© bi Ä‘Ã¡tTrÆ°á»›c khi Ä‘áº¿n vá»›i ngÆ°á»i anh báº¡n cÃ¡nh cá»¥t cÆ° tÃª kia, mÃ¬nh Ä‘Ã£ tá»«ng lÃ m viá»‡c vá»›i chiáº¿c laptop cÃ¹i báº¯p (intel pentium) win 8.1. Khi Ä‘Ã³ OG vá»«a bÆ°á»›c chÃ¢n vÃ o giáº£ng Ä‘Æ°á»ng Ä‘áº¡i há»c, vÃ  cá»© nghÄ© ráº±ng tháº¿ nÃ y Ä‘Ã£ Ä‘á»§ xÃ i, cÃ³ thá»ƒ hÆ¡i cháº­m cháº¡p nhÆ°ng cÃ³ láº½ sáº½ sá»‘ng á»•n. Ã”i tháº­t ngÃ¢y thÆ¡ ğŸ˜¢ ngay ná»­a há»c kÃ¬ Ä‘áº§u tiÃªn cá»§a nÄƒm há»c má»›i, cÃ¡i laptop Ä‘Ã³ Ä‘Ã£ dá»‘c tá»«ng nhá»‹p thá»Ÿ vÃ  cháº¡y chÆ°Æ¡ng trÃ¬nh báº±ng cáº£ tÃ­nh máº¡ng. ÄÃ³ lÃ  tráº£i nghiá»‡m há»c táº­p khÃ´ng máº¥y dá»… chá»‹u khi pháº£i Ä‘á»‘i máº·t vá»›i con lap Ã¬ áº¡ch nhÆ° váº­y trong suá»‘t má»™t khoáº£ng thá»i gian dÃ i. VÃ  má»™t combo há»§y diá»‡t Ä‘i kÃ¨m vá»›i sá»± Ã¬ áº¡ch Ä‘Ã³: há»‡ Ä‘iá»u hÃ nh WINDOW, Ä‘áº·c biá»‡t lÃ  phiÃªn báº£n 8 vÃ  8.1 . OG trÆ°á»›c Ä‘Ã¢y lÃ  má»™t fan cá»§a window, pháº£i thÃº thá»±c lÃ  váº­y. Giao diá»‡n dá»… dÃ¹ng, thÃ¢n thiá»‡n. NhÆ°ng cÃ³ 1 váº¥n Ä‘á», nÃ³ quÃ¡ náº·ng vÃ  cháº­m cháº¡p (Ã­t nháº¥t lÃ  Ä‘á»‘i vá»›i laptop cá»§a OG). CÃ²n cáº£ vá» lá»—i vÃ  cÃ¡c báº£n update mÃ  chá»‰ khi dÃ¹ng window, OG má»›i cáº£m nháº­n Ä‘Æ°á»£c sá»± Ä‘au khá»•. Tháº¿ lÃ  cÃ³ 1 ngÃ y ná», má»™t ngÆ°á»i báº¡n Ä‘Ã£ chá»‰ mÃ¬nh chuyá»ƒn sang Linux vÃ  cuá»™c sá»‘ng láº­p trÃ¬nh cá»§a mÃ¬nh bÆ°á»›c sang má»™t trang má»›i toanh. ","date":"27 Sep 2023","objectID":"/linux/:1:0","series":["Data lÃº"],"tags":[],"title":"Linux - tiáº¿ng sÃ©t Ã¡i tÃ¬nh","uri":"/linux/#quÃ¡-khá»©-bi-Ä‘Ã¡t"},{"categories":[],"content":"Linux - Tiáº¿ng sÃ©t Ã¡i tÃ¬nhTrÆ°á»›c khi Ä‘Æ°á»£c giá»›i thiá»‡u vá» Linux, OG hoÃ n toÃ n khÃ´ng biáº¿t gÃ¬ vá» nÃ³ trÆ°á»›c Ä‘Ã³. Tá»« Terminal, Distro,â€¦ HoÃ n toÃ n lÃ  tá» giáº¥y tráº¯ng tinh. Tuy nhiÃªn OG váº«n chá»n há»‡ Ä‘iá»u hÃ nh nÃ y vÃ¬ nÃ³ NHANH, ráº¥t nhanh lÃ  Ä‘áº±ng khÃ¡c. Ngay khoáº£nh kháº¯c Ä‘Ã³, OG Ä‘Ã£ khÃ´ng biáº¿t mÃ¬nh Ä‘Ã£ mÃª Ä‘áº¯m hÄ‘h nÃ y máº¥t rá»“i ğŸ˜˜ VÃ  sau má»™t thá»i gian há»c táº­p vÃ  lÃ m viá»‡c vá»›i anh báº¡n ğŸ§ cÆ° tÃª thÃ¬ OG Ä‘Ã£ khÃ´ng cÃ²n muá»‘n quay láº¡i cá»­a sá»• (window) láº§n nÃ o ná»¯a. Váº­y Linux cÃ³ gÃ¬ hay hÃ£y Ä‘á»c tiáº¿p nhÃ© ","date":"27 Sep 2023","objectID":"/linux/:2:0","series":["Data lÃº"],"tags":[],"title":"Linux - tiáº¿ng sÃ©t Ã¡i tÃ¬nh","uri":"/linux/#linux---tiáº¿ng-sÃ©t-Ã¡i-tÃ¬nh"},{"categories":[],"content":"Há»‡ Ä‘iá»u hÃ nh cháº¥t chÆ¡i ngÆ°á»i dÆ¡iLinux lÃ  má»™t há»‡ Ä‘iá»u hÃ nh Ä‘Æ°á»£c phÃ¡t triá»ƒn tá»« nÄƒm 1991 bá»Ÿi Linus Torvalds dá»±a trÃªn há»‡ Ä‘iá»u hÃ nh Unix. ChÃº cÃ¡nh cá»¥t nÃ y Ä‘Æ°á»£c viáº¿t báº±ng C vÃ  Ä‘áº£m nháº­n nhiá»‡m vá»¥ nháº­n cÃ¡c request tá»« chÆ°Æ¡ng trÃ¬nh trÃªn mÃ¡y tÃ­nh vÃ  chuyá»ƒn chÃºng Ä‘áº¿n pháº§n cá»©ng. Äiá»u Ä‘áº·c biá»‡t nháº¥t cÃ³ láº½ lÃ  nÃ³ Ä‘Æ°á»£c phÃ¡t hÃ nh miá»…n phÃ­ (open source). NghÄ©a lÃ  báº¡n cÃ³ thá»ƒ dá»… dÃ ng cÃ i Linux má»™t cÃ¡ch quang minh chÃ­nh Ä‘áº¡i mÃ  khÃ´ng cáº§n pháº£i crack hay â€œÄi cá»­a sauâ€ vá»›i nhiá»u rá»§i ro lá»—i nhÆ° khi sá»­ dá»¥ng hÄ‘h khÃ¡c. Tháº­m chÃ­ báº¡n cÃ³ thá»ƒ chá»‰nh sá»­a, Ä‘Ã³ng gÃ³p xÃ¢y dá»±ng thÃªm cho há»‡ Ä‘iá»u hÃ nh nÃ y náº¿u muá»‘n. KhÃ´ng nhá»¯ng váº­y, cá»™ng Ä‘á»“ng há»— trá»£ cá»§a há»‡ Ä‘iá»u hÃ nh nÃ y cÅ©ng rá»™ng lá»›n vÃ  vÃ´ cÃ¹ng â€œbÃ¡ Ä‘áº¡oâ€ vá» nhiá»u khÃ­a cáº¡nh ğŸ˜‚ Báº¡n sáº½ cÃ³ thá»ƒ gáº§n nhÆ° ngay láº­p tá»©c Ä‘Æ°á»£c giáº£i Ä‘Ã¡p háº§u háº¿t cÃ¡c tháº¯c máº¯c hay trá»¥c tráº·c khi sá»­ dá»¥ng linux. Cá»™ng Ä‘á»“ng nÃ y Ä‘a sá»‘ lÃ  cÃ¡c láº­p trÃ¬nh viÃªn, nhÃ  phÃ¡t triá»ƒn,â€¦ VÃ¬ chÃº cÃ¡nh cá»¥t nÃ y há»‡ Ä‘iá»u hÃ nh Æ°u thÃ­ch vÃ  thÃ­ch há»£p Ä‘á»ƒ phÃ¡t triá»ƒn sáº£n pháº©m hoáº·c xÃ¢y dá»±ng há»‡ thá»‘ng nhá» lÃ  á»©ng dá»¥ng mÃ£ nguá»“n má»Ÿ vÃ  tÃ­nh báº£o máº­t cao. Khi chuyá»ƒn sang dÃ¹ng Linux, báº¡n cÅ©ng khÃ´ng cáº§n pháº£i quÃ¡ lo láº¯ng vá» viá»‡c thay Ä‘á»•i mÃ´i trÆ°á»ng vÃ  thÃ­ch nghi vá»›i há»‡ Ä‘iá»u hÃ nh nÃ y. VÃ¬ cÆ¡ báº£n Linux váº«n giá»‘ng vá»›i nhá»¯ng há»‡ Ä‘iá»u hÃ nh trÆ°á»›c Ä‘Ã¢y báº¡n dÃ¹ng thÃ´i. Báº¡n váº«n cÃ³ thá»ƒ thao tÃ¡c vá»›i giao diá»‡n há»‡ Ä‘iá»u hÃ nh, váº«n sá»­ dá»¥ng Ä‘Æ°á»£c cÃ¡c pháº§n má»m nhÆ° xá»­ lÃ½ vÄƒn báº£n, edit video hay áº£nh,â€¦ NghÄ©a lÃ  cÃ¡c thao tÃ¡c sá»­ dá»¥ng thÃ´ng thÆ°á»ng, Linux váº«n Ä‘Ã¡p á»©ng tá»‘t vÃ  cÃ²n ráº¥t nhanh. ","date":"27 Sep 2023","objectID":"/linux/:2:1","series":["Data lÃº"],"tags":[],"title":"Linux - tiáº¿ng sÃ©t Ã¡i tÃ¬nh","uri":"/linux/#há»‡-Ä‘iá»u-hÃ nh-cháº¥t-chÆ¡i-ngÆ°á»i-dÆ¡i"},{"categories":[],"content":"ShellHáº³n lÃ  cÃ³ thá»ƒ Ä‘Ã¢u Ä‘Ã³, báº¡n tháº¥y má»™t anh chÃ ng ngáº§u lÃ²i nÃ o Ä‘Ã³ báº¥m vÃ i dÃ²ng lá»‡nh, Bá»¥p enter. Rá»“i tá»± nhiÃªn má»™t Ä‘á»‘ng chá»¯ xuáº¥t hiá»‡n dá»“n dáº­p trÃªn cÃ¡i ná»n terminal tÃ­m. á»’ cÃ³ thá»ƒ anh ta Ä‘ang sá»­ dá»¥ng shell Ä‘áº¥y. Hoáº·c lÃ  má»™t láº­p trÃ¬nh viÃªn, báº¡n Ä‘Ã£ quÃ¡ chÃ¡n vá»›i giao diá»‡n Command Prompt vÃ  PowerShell ? HÃ£y chuyá»ƒn sang Linux vÃ  báº¡n sáº½ bÆ°á»›c vÃ o tháº¿ giá»›i huyá»n diá»‡u khi sá»­ dá»¥ng terminal. Shell lÃ  má»™t chÆ°Æ¡ng trÃ¬nh phÃ¡t triá»ƒn dÃ nh cho cÃ¡c mÃ¡y tÃ­nh cháº¡y trÃªn há»‡ Ä‘iá»u hÃ nh Unix vÃ  Linux. Pháº§n má»m nÃ y cÅ©ng cáº¥p giao diá»‡n ngÆ°á»i dÃ¹ng nháº­p vÃ  giao tiáº¿p vá»›i mÃ¡y tÃ­nh dÆ°á»›i dáº¡ng vÄƒn báº£n. VÃ  trÃªn cÃ¡c mÃ¡y tÃ­nh Ubuntu thÃ¬ Shell cÅ©ng cÃ³ thá»ƒ gá»i lÃ  Terminal. Äá»‘i vá»›i ngÆ°á»i dÃ¹ng Linux, viá»‡c thao tÃ¡c vá»›i terminal lÃ  Ä‘iá»u gáº§n nhÆ° hiá»ƒn nhiÃªn. Äáº·c biá»‡t thÃ­ch há»£p cho cÃ¡c â€œcÃ³t Ä‘Æ¡â€ hay nhÃ  phÃ¡t triá»ƒn. Viá»‡c cháº¡y lá»‡nh trÃªn Terminal ngoÃ i viá»‡c trÃ´ng cÃ³ váº» â€œnguy hiá»ƒmâ€ hÆ¡n, tráº£i nghiá»‡m sá»­ dá»¥ng shell cÅ©ng Ä‘Æ°á»£c cho lÃ  thoáº£i mÃ¡i hÆ¡n trÃªn window ráº¥t nhiá»u. KhÃ´ng nhá»¯ng váº­y, vá»›i má»™t cá»™ng Ä‘á»“ng cá»±c lá»›n, viá»‡c lÃ m quen vá»›i shell dÆ°á»ng nhÆ° Ä‘Ã£ trá»Ÿ nÃªn dá»… dÃ ng hÆ¡n bao giá» háº¿t. Viá»‡c sá»­ dá»¥ng shell nhÆ° tháº¿ nÃ o cÃ³ láº½ OG sáº½ Ä‘á»ƒ dÃ nh láº¡i vÃ o 1 bÃ i khÃ¡c nhÃ© hihi ","date":"27 Sep 2023","objectID":"/linux/:2:2","series":["Data lÃº"],"tags":[],"title":"Linux - tiáº¿ng sÃ©t Ã¡i tÃ¬nh","uri":"/linux/#shell"},{"categories":[],"content":"Äa dáº¡ng phiÃªn báº£nVÃ¬ lÃ  sáº£n pháº©m mÃ£ nguá»“n má»Ÿ, Linux cÃ³ ráº¥t nhiá»u phiÃªn báº£n khÃ¡c nhau. CÃ¡c Linux Distro lÃ  pháº§n Ä‘Ã£ gÃ³p pháº§n vÃ o sá»± thÃº vá»‹ nÃ³i chung cá»§a há»‡ Ä‘iá»u hÃ nh nÃ y vÃ  giÃºp cho chÃºng ta cÃ³ Ä‘a dáº¡ng sá»± chá»n lá»±a cho phiÃªn báº£n mÃ¬nh yÃªu thÃ­ch. Hiá»‡n cÃ³ khoáº£ng 600 báº£n Distro vÃ  hÆ¡n ná»­a trong sá»‘ Ä‘Ã³ Ä‘Æ°á»£c liÃªn tá»¥c phÃ¡t triá»ƒn vÃ  cáº£i thiá»‡n. CÃ³ Ä‘a dáº¡ng cÃ¡c distro vÃ  phÃ¹ há»£p vá»›i Ä‘a dáº¡ng cÃ¡c ná»n táº£ng khÃ¡c nhau tá»« desktop, laptop, di Ä‘á»™ng,â€¦ VÃ  cÅ©ng nháº¯m tá»›i phá»¥c vá»¥ cho Ä‘a dáº¡ng cÃ¡c Ä‘á»‘i tÆ°á»£ng khÃ¡c nhau. HÃ£y cÃ¹ng xem qua má»™t sá»‘ distro phá»• biáº¿n nháº¥t nÃ o Ubuntu: Ä‘Ã¢y lÃ  phiÃªn báº£n Ä‘Ã´ng Ä‘áº£o ngÆ°á»i dÃ¹ng sá»§ dá»¥ng nháº¥t. ÄÃ¢y chÃ­nh lÃ  má»™t nhÃ¡nh cá»§a Debian Linux. Ubuntu cÃ³ giao diá»‡n dá»… nhÃ¬n vÃ  dá»… tiáº¿p cáº­n, do Ä‘Ã³ ngÆ°á»i dÃ¹ng má»›i khÃ´ng khÃ³ Ä‘á»ƒ lÃ m quen vÃ  sá»­ dá»¥ng. HÆ¡n ná»¯a lÃ  cá»™ng Ä‘á»“ng sá»­ dá»¥ng lá»›n nÃªn báº¡n sáº½ dá»… dÃ ng tÃ¬m Ä‘Æ°á»£c giáº£i Ä‘Ã¡p cho cÃ¡c tháº¯c máº¯c mÃ¬nh trong khi sá»­ dá»¥ng. VÃ  OG cÅ©ng Ä‘ang sá»­ dá»¥ng Distro nÃ y ğŸ˜„ Linux Mint: LÃ  má»™t trong nhá»¯ng distro tá»‘t nháº¥t dÃ nh do ngÆ°á»i dÃ¹ng Linux má»›i. Giao diá»‡n Desktop cá»§a Mint ráº¥t lÃ  Window, táº¡o cáº£m giÃ¡c vÃ´ cÃ¹ng quen thuá»™c vÃ  dá»… thÃ­ch nghi Ä‘á»‘i vá»›i ngÆ°á»i dÃ¹ng má»›i chuyá»ƒn hoáº·c Æ°u thÃ­ch Window. ÄÃ¢y cÅ©ng lÃ  má»™t trong nhá»¯ng Ä‘iá»ƒm Ä‘áº·c sáº¯c cá»§a distro nÃ y. NgoÃ i ra Linux Mint dá»±a trÃªn Ubuntu, do Ä‘Ã³ cÅ©ng cÃ³ thá»ƒ cháº¡y á»©ng dá»¥ng dÃ nh cho Ubuntu. Fedora: TrÆ°á»›c Ä‘Ã¢y gá»i lÃ  Fedora core, Ä‘Æ°á»£c phÃ¡t triá»ƒn dá»±a trÃªn cá»™ng Ä‘á»“ng theo Fedora Project vÃ  Ä‘Æ°á»£c báº£o trá»£ bá»Ÿi Red Hat (CÃ´ng ty con cá»§a IBM). ÄÃ¢y lÃ  má»™t trong nhá»¯ng báº£n phÃ¢n phá»‘i cÃ³ tá»‘c Ä‘á»™ nhanh vÃ  á»•n Ä‘á»‹nh nháº¥t. ÄÆ°á»£c Æ°u chuá»™ng bá»Ÿi cÃ¡c nhÃ  phÃ¡t triá»ƒn. CentOS: Má»™t trong nhá»¯ng phÃ¢n phá»‘i Linux dÃ nh cho mÃ´i trÆ°á»ng server, CentOS dá»±a trÃªn mÃ£ nguá»“n má»Ÿ cá»§a Red Hat Enterprise Linux (RHEL) vÃ  miá»…n phÃ­. CentOS cÃ³ Ä‘á»™ á»•n Ä‘á»‹nh cao vÃ  Ä‘Æ°á»£c nhiá»u cÃ´ng ty Æ°u chuá»™ng. Arch Linux: Báº£n phÃ¢n phá»‘i nÃ y lÃ  má»™t â€œRolling Releaseâ€, Ä‘áº¡i loáº¡i nhÆ° lÃ  nÃ³ sáº½ luÃ´n Ä‘Æ°á»£c cung cáº¥p báº£n cáº­p nháº­t pháº§n má»m sá»›m nháº¥t cÃ³ thá»ƒ vÃ  cáº£i thiá»‡n tá»‘t nháº¥t. Äiá»u Ä‘áº·c biá»‡t cá»§a distro nÃ y lÃ  kháº£ nÄƒng cÃ¡ nhÃ¢n hÃ³a ráº¥t cao, báº¡n tháº­m chÃ­ sáº½ khÃ´ng nháº­n Ä‘Æ°á»£c giao diá»‡n Ä‘á»“ há»a khi má»›i báº¯t Ä‘áº§u. Äá»•i láº¡i báº¡n sáº½ cÃ³ thá»ƒ thiáº¿t káº¿, xÃ¢y dá»±ng theo sá»Ÿ thÃ­ch cá»§a chÃ­nh mÃ¬nh. VÃ  cÃ²n ráº¥t ráº¥t nhiá»u phÃ¢n phá»‘i khÃ¡c thÃº vá»‹ ná»¯a mÃ  ká»ƒ ra cháº¯c pháº£i thÃ nh sÃ¡ch máº¥t ğŸ˜‚ ","date":"27 Sep 2023","objectID":"/linux/:2:3","series":["Data lÃº"],"tags":[],"title":"Linux - tiáº¿ng sÃ©t Ã¡i tÃ¬nh","uri":"/linux/#Ä‘a-dáº¡ng-phiÃªn-báº£n"},{"categories":[],"content":"Linux vs WindowHiá»‡n nay cÃ³ 3 há»‡ Ä‘iá»u hÃ nh phá»• biáº¿n lÃ  Window, Linux, MacOS. Äá»‘i vá»›i Mac thÃ¬ OG chÆ°a tráº£i nghiá»‡m (vÃ¬ mÃ¬nh nghÃ¨o ğŸ˜¢). Do Ä‘Ã³ chÃºng ta sáº½ so sÃ¡nh tráº£i nghiá»‡m giá»¯a 2 há»‡ Ä‘iá»u hÃ nh nÃ y theo cáº£m nháº­n cá»§a OG sau má»™t thá»i gian sá»­ dá»¥ng Linux vÃ  cáº£ Window nhÃ© Äá»‘i tÆ°á»£ng sá»­ dá»¥ng: Äá»‘i vá»›i Window, Ä‘Ã£ quÃ¡ phá»• biáº¿n rá»“i, do Ä‘Ã³ Ä‘á»‘i tÆ°á»£ng hÆ°á»›ng Ä‘áº¿n cÅ©ng ráº¥t rá»™ng rÃ£i giÃ  tráº» lá»›n bÃ© Ä‘á»u cÃ³ thá»ƒ sá»­ dá»¥ng dá»… dÃ ng sá»­ dá»¥ng. NgÆ°á»£c láº¡i, nhá»¯ng ngÆ°á»i sá»­ dá»¥ng Linux thÆ°á»ng lÃ  cÃ¡c láº­p trÃ¬nh viÃªn vÃ  cÃ¡c nhÃ  phÃ¡t triá»ƒn. Há» lÃ  ngÆ°á»i hiá»ƒu vá» há»‡ thá»‘ng vÃ  cÃ³ thá»ƒ kiá»ƒm soÃ¡t há»‡ thá»‘ng. Bash Shell: Äáº§u tiÃªn, Ä‘á»‘i vá»›i viá»‡c láº­p trÃ¬nh cáº§n pháº£i thao tÃ¡c nhiá»u vá»›i há»‡ thá»‘ng thÃ¬ viá»‡c sá»­ dá»¥ng cmd hay PowerShell gáº§n nhÆ° lÃ  1 tráº£i nghiá»‡m â€œÄ‘á»“ Ä‘Ã¡â€ Ä‘á»‘i vá»›i OG. Window 10 cÃ³ há»— trá»£ cmd vÃ  PowerShell nhÆ°ng cáº£ 2 loáº¡i nÃ y Ä‘á»u cÃ³ giao diá»‡n cÅ© kÄ© vÃ  cÃº phÃ¡p dÃ i dÃ²ng, khÃ³ nhá»›. Trong khi Ä‘Ã³, sá»­ dá»¥ng Bash Shell á»Ÿ Linux Ä‘Æ°a láº¡i tráº£i nghiá»‡m mÆ°á»£t mÃ  hÆ¡n vá»›i cÃ¢u lá»‡nh dá»… nhá»›, mÃ u sáº¯c cÅ©ng Ä‘a dáº¡ng hÆ¡n vÃ  táº¥t nhiÃªn lÃ  cÅ©ng dá»… dÃ¹ng hÆ¡n ráº¥t nhiá»u. Xá»­ lÃ½, can thiá»‡p mÃ£ nguá»“n: Trong khi sá»­ dá»¥ng Window, viá»‡c truy cáº­p mÃ£ nguá»“n gáº§n nhÆ° lÃ  báº¥t kháº£ thi. ThÃ¬ Ä‘á»‘i vá»›i ngÆ°á»i dÃ¹ng Linux láº¡i ngÆ°á»£c láº¡i, báº¡n hoÃ n toÃ n cÃ³ kháº£ nÄƒng truy cáº­p hay chá»‰nh sá»­a mÃ£ nguá»“n Ä‘áº¿n táº­n nhÃ¢n. Viá»‡c cáº¥u hÃ¬nh há»‡ thá»‘ng theo sá»Ÿ thÃ­ch cÃ¡ nhÃ¢n hoÃ n toÃ n lÃ  Ä‘iá»u kháº£ thi vÃ  táº¡o tÃ­nh linh hoáº¡t khi sá»­ dá»¥ng. Xá»­ lÃ½ vÄƒn báº£n, hÃ¬nh áº£nh: Vá» phÆ°Æ¡ng diá»‡n nÃ y, pháº£i nÃ³i lÃ  khÃ´ng thá»ƒ qua Ä‘Æ°á»£c Microsoft Office 365 cá»§a Window, táº¥t nhiÃªn Linux cÅ©ng cÃ³ LibreOffice, tuy nhiÃªn pháº§n má»m nÃ y váº«n cÃ²n khÃ¡ háº¡n cháº¿ vÃ  kÃ©m. NgoÃ i ra viá»‡c sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ chá»‰nh sá»­a hÃ¬nh áº£nh, video nhÆ° Adobe Photoshops hay Adobe Premiere trÃªn linux cÅ©ng lÃ  khÃ´ng thá»ƒ. Gaming: ThÃ nh tháº­t mÃ  nÃ³i, náº¿u báº¡n sá»­ dá»¥ng linux, thÃ¬ hÃ£y táº­p bá» dáº§n thÃ³i quen chÆ¡i game Ä‘i ğŸ˜‚ vÃ¬ háº§u háº¿t cÃ¡c game há»— trá»£ tá»‘t nháº¥t trÃªn há»‡ Ä‘iá»u hÃ nh Window Äá»™ báº£o máº­t: Táº¥t nhiÃªn, khÃ´ng thá»ƒ phá»§ nháº­n Window lÃ  má»™t há»‡ Ä‘iá»u hÃ nh cá»±c ká»³ báº£o máº­t. NhÆ°ng nÃ³ luÃ´n lÃ  má»¥c tiÃªu cá»§a cÃ¡c cuá»™c táº¥n cÃ´ng vÃ¬ Ä‘á»™ phá»• biáº¿n quÃ¡ lá»›n cá»§a nÃ³. Trong khi ngÆ°á»i dÃ¹ng Linux háº§u háº¿t lÃ  cÃ¡c láº­p trÃ¬nh viÃªn vÃ  táº¥t nhiÃªn lÃ  cáº£ Hacker. Okay nÃ³i quÃ¡ trá»i nÃ³i thÃ¬ tÃ³m gá»n qua báº£ng sau Ä‘Ã¢y: TiÃªu chÃ­ Window Linux Äá»‘i tÆ°á»£ng NgÆ°á»i dÃ¹ng phá»• thÃ´ng vá»›i nhu cáº§u cÆ¡ báº£n: lÆ°á»›t web, cÃ´ng viá»‡c vÄƒn phÃ²ng,â€¦ Láº­p trÃ¬nh viÃªn, nhÃ  phÃ¡t triá»ƒn, hacker,â€¦ Giao diá»‡n Command Line ThÃ´ sÆ¡, khÃ³ dÃ¹ng vá»›i Command Prompt, PowerShell Máº¡nh máº½ vá»›i nhiá»u loáº¡i shells (Bash, Zsh,â€¦) Kháº£ nÄƒng tÃ¹y chá»‰nh mÃ£ nguá»“n KhÃ´ng thá»ƒ HoÃ n toÃ n cÃ³ thá»ƒ, giÃºp cÃ¡ nhÃ¢n hÃ³a vÃ  táº¡o tÃ­nh linh hoáº¡t Xá»­ lÃ½ vÄƒn báº£n, phim áº£nh Ráº¥t tá»‘t vá»›i bá»™ Office 365, Adobe Photoshops,â€¦ CÃ³ thá»ƒ sá»­ dá»¥ng LibreOffice chá»‰nh sá»­a cÆ¡ báº£n nhÆ°ng chá»©c nÄƒng Ã­t Game Há»— trá»£ tá»‘t KhÃ¡ khÃ³ khÄƒn Äá»™ báº£o máº­t Tá»‘t, nhÆ°ng dá»… bá»‹ nháº¯m tá»›i Tá»‘t vÃ  cÃ³ tÃ­nh báº£o máº­t cao Viá»‡c há»c láº­p trÃ¬nh hay quáº£n lÃ½ há»‡ thÃ´ng, cÃ³ láº½ Linux sáº½ lÃ  lá»±a chá»n hoÃ n háº£o hÆ¡n (hoáº·c náº¿u cÃ³ Ä‘iá»u kiá»‡n, hÃ£y mua Mac ğŸ˜„ tháº­t Ä‘áº¥y !). CÃ²n náº¿u báº¡n lÃ  ngÆ°á»i dÃ¹ng phá»• thÃ´ng, khÃ´ng cÃ³ nhu cáº§u pháº£i biáº¿t vá» láº­p trÃ¬nh, quáº£n lÃ½ háº¡ táº§ng,â€¦ thÃ¬ cá»© cá»­a sá»• mÃ  dÃ¹ng thÃ´i hihi ","date":"27 Sep 2023","objectID":"/linux/:2:4","series":["Data lÃº"],"tags":[],"title":"Linux - tiáº¿ng sÃ©t Ã¡i tÃ¬nh","uri":"/linux/#linux-vs-window"},{"categories":[],"content":"Muá»‘n thÃ¬ tÃ¬m cÃ¡chNáº¿u báº¡n lÃ  má»™t ngÆ°á»i dÃ¹ng Mac, chÃºc má»«ng báº¡n Ä‘Ã£ quay vÃ o Ã´ an toÃ n ğŸ˜„ sÆ°á»›ng nháº¥t báº¡n rá»“i hi. CÃ²n náº¿u sá»­ dá»¥ng Window mÃ  báº¥t giÃ¡c cÃ³ má»™t tÃ¬nh yÃªu vá»›i Linux thÃ¬ pháº£i lÃ m sao Ä‘Ã¢y ? KhÃ´ng láº½ pháº£i bá» Win cÃ i láº¡i Linux sao ? CÃ¢u tráº£ lá»i lÃ  KhÃ´ng. Hiá»‡n nay cÃ³ 3 cÃ¡ch chÃ­nh Ä‘á»ƒ báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng Linux mÃ  khÃ´ng cáº§n pháº£i tá»« bá» chiáº¿c cá»­a sá»• cá»§a mÃ¬nh: DÃ¹ng mÃ¡y áº£o: Viá»‡c Ä‘áº§u tiÃªn mÃ  háº§u háº¿t má»i ngÆ°á»i nghÄ© tá»›i khi dÃ¹ng má»™t há»‡ Ä‘iá»u hÃ nh khÃ¡c vá»›i há»‡ Ä‘iá»u hÃ nh chÃ­nh cá»§a mÃ¡y chÃ­nh lÃ  dÃ¹ng má»™t con mÃ¡y áº£o. Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng VirtualBox hoáº·c VMware PLayer má»™t cÃ¡ch miá»…n phÃ­ Ä‘á»ƒ cÃ i Ä‘áº·t. NhÆ°ng vá»›i OG, sá»­ dá»¥ng mÃ¡y áº£o cháº£ khÃ¡c nÃ o má»™t cá»±c hÃ¬nh, vÃ¬ nÃ³ cháº­m kinh khá»§ng khiáº¿p. VÃ¬ loáº¡i mÃ¡y áº£o nÃ y cháº¡y trÃªn há»‡ Ä‘iá»u hÃ nh mÃ¡y vÃ  sá»­ dá»¥ng cÃ´ng nghá»‡ áº£o hÃ³a cá»§a CPU Ä‘á»ƒ táº¡o ra cÃ¡c mÃ¡y áº£o khÃ¡c. CÆ¡ báº£n lÃ  pháº£i thÃ´ng qua má»™t OS trung gian (Window), do Ä‘Ã³ tá»‘c Ä‘á»™ cá»§a nÃ³ thá»±c sá»± nhÆ° rÃ¹a. DÃ¹ng dual boot: CÆ¡ báº£n cÃ¡ch nÃ y lÃ  cÃ i Ä‘áº·t cho mÃ¡y tÃ­nh báº¡n cháº¡y Ä‘Æ°á»£c cáº£ 2 há»‡ Ä‘iá»u hÃ nh cÃ¹ng má»™t lÃºc, cÃ¡ch nÃ y Ä‘Æ°á»£c khÃ¡ nhiá»u ngÆ°á»i sá»­ dá»¥ng vÃ  táº¥t nhiÃªn lÃ  nhanh hÆ¡n viá»‡c sá»­ dá»¥ng mÃ¡y áº£o. DÃ¹ng WSL: hay cÃ²n Ä‘Æ°á»£c gá»i lÃ  Window Subsystem for Linux, vá» báº£n cháº¥t mÃ  nÃ³i thÃ¬ Ä‘Ã¢y cÅ©ng lÃ  má»™t loáº¡i mÃ¡y áº£o. Tuy nhiÃªn nÃ³ lÃ  loáº¡i mÃ¡y áº£o cháº¡y trÃªn má»™t ná»n táº£ng áº£o hÃ³a cá»§a CPU lÃ  Hyper-V, vÃ  khÃ´ng há» thÃ´ng qua há»‡ Ä‘iá»u hÃ nh trung gian nÃ o. CÃ³ thá»ƒ hiá»ƒu lÃ  cÃ´ng nghá»‡ Hyper-V lÃ  cÃ´ng nghá»‡ áº£o hÃ³a cá»§a CPU cung cáº¥p cÃ¡c táº§ng áº£o hÃ³a, ká»ƒ cáº£ cho chÃ­nh Window cá»§a báº¡n. Viá»‡c sá»­ dá»¥ng mÃ¡y áº£o loáº¡i nÃ y thá»±c sá»± nhanh hÆ¡n ráº¥t nhiá»u vÃ  cÅ©ng khÃ´ng cáº§n pháº£i restart mÃ¡y Ä‘á»ƒ chuyá»ƒn sang OS khÃ¡c nhÆ° cÃ¡ch dual boot mÃ  Ä‘Æ¡n giáº£n chá»‰ lÃ  táº¯t wsl trÃªn PowerShell Ä‘i lÃ  xong. QuÃ¡ Ä‘Ã£ pháº£i khÃ´ng nÃ o. Äá»‘i vá»›i OG thÃ¬ mÃ¬nh Ä‘ang dÃ¹ng cÃ¡ch 3 Ä‘á»ƒ cÃ³ thá»ƒ sá»­ dá»¥ng Linux trÃªn Window má»™t cÃ¡ch hoÃ n toÃ n miá»…n phÃ­ vÃ  tráº£i nghiá»‡m vÃ´ cÃ¹ng á»•n Ä‘á»‹nh. Microsoft Ä‘Ã£ táº¡o ra WSL Ä‘á»ƒ giÃºp giáº£i tá»a cÆ¡n khÃ¡t Linux cá»§a ngÆ°á»i dÃ¹ng Window vÃ  giÃºp cho cuá»™c sá»‘ng cÃ¡c láº­p trÃ¬nh viÃªn thÃªm ngá»t ngÃ o dá»… sá»‘ng hÆ¡n ğŸ˜‚ Hoáº·c báº¡n cÃ³ thá»ƒ ghÃ© thÄƒm page Ubunchuu trÆ°á»ng Ãº Ä‘á»ƒ tÃ¬m hiá»ƒu táº¥t táº§n táº­t má»i thá»© vá» Linux vÃ  Ubuntu nhÃ©. ÄÃ¢y lÃ  kÃªnh do má»™t nhÃ³m cÃ¡c sinh viÃªn Ä‘am mÃª vá»›i linux cá»§a HCMUS thÃ nh láº­p nháº±m táº¡o cá»™ng Ä‘á»“ng linux giÃºp Ä‘á»¡ láº«n nhau. VÃ  táº¥t nhiÃªn lÃ  hÆ°á»›ng Ä‘áº¿n cÃ¡c báº¡n ngÆ°á»i má»›i, newbie vá»›i Ubuntu rá»“i. ","date":"27 Sep 2023","objectID":"/linux/:3:0","series":["Data lÃº"],"tags":[],"title":"Linux - tiáº¿ng sÃ©t Ã¡i tÃ¬nh","uri":"/linux/#muá»‘n-thÃ¬-tÃ¬m-cÃ¡ch"},{"categories":[],"content":"CÃºng cÃ¹iVÃ  Ä‘Ã³ lÃ  táº¥t cáº£ cáº£m nháº­n cá»§a OG vá» viá»‡c sá»­ dá»¥ng Linux, cÅ©ng nhÆ° lÃ  giá»›i thiá»‡u má»™t chÃºt vá» chÃº cÃ¡nh cá»¥t ğŸ§ cÆ° tÃª nÃ y. Táº¥t cáº£ chá»‰ lÃ  cáº£m nháº­n cÃ¡ nhÃ¢n cá»§a OG trong quÃ¡ trÃ¬nh sá»­ dá»¥ng Linux, hy vá»ng ráº±ng sáº½ giÃºp báº¡n cáº£m tháº¥y thÃº vá»‹. -Mew- ","date":"27 Sep 2023","objectID":"/linux/:4:0","series":["Data lÃº"],"tags":[],"title":"Linux - tiáº¿ng sÃ©t Ã¡i tÃ¬nh","uri":"/linux/#cÃºng-cÃ¹i"},{"categories":[],"content":"Data lÃº #1 Tháº±ng nhÃ³c thÃ­ch code vÃ  data NgÃ nh Data cÃ³ gÃ¬ hot mÃ  mÃ¬nh láº¡i dÃ­nh Read more... #2 Linux - Tiáº¿ng sÃ©t Ã¡i tÃ¬nh Khi biáº¿t Ä‘áº¿n Linux, tÃ´i Ä‘Ã£ yÃªu em lÃºc nÃ o khÃ´ng hay Read more... ","date":"24 Sep 2023","objectID":"/blogs/:0:0","series":[""],"tags":[],"title":"Blogs","uri":"/blogs/#data-lÃº"},{"categories":[],"content":"CÃ¢u chuyá»‡n Ä‘á»i sá»‘ng NhÃ¬n láº¡i 2023 Quáº£ lÃ  má»™t nÄƒm gian nan nhÆ°ng tháº­t má»«ng vÃ¬ mÃ¬nh Ä‘Ã£ khÃ´ng Ä‘áº§u hÃ ng Read more... Bosch vÃ  cuá»™c hÃ nh trÃ¬nh má»›i ÄÃ¢y lÃ  cÃ¢u chuyá»‡n vá» cuá»™c hÃ nh trÃ¬nh lÃ m má»™t Data Engineer cá»§a mÃ¬nh táº¡i Bosch R\u0026D Center Read more... ","date":"24 Sep 2023","objectID":"/blogs/:0:0","series":[""],"tags":[],"title":"Blogs","uri":"/blogs/#cÃ¢u-chuyá»‡n-Ä‘á»i-sá»‘ng"},{"categories":["projects"],"content":"Warning ÄÃ¢y lÃ  kiáº¿n thá»©c tÃ­ch gÃ³p tá»« nhiá»u nguá»“n vÃ  tÃ¬m hiá»ƒu cá»§a nhÃ³m OG, táº¥t nhiÃªn khÃ´ng thá»ƒ trÃ¡nh khá»i sai sÃ³t. Hy vá»ng bÃ i viáº¿t láº§n nÃ y thÃº vá»‹ vÃ  giÃºp báº¡n Ä‘á»c thÆ° giÃ£n, tham kháº£o. PhongHuynh0394 Stock-Analysis HÃ© lÃ´ hÃ© lÃ´ lÃ  OG Ä‘Ã¢yy, á»Ÿ pháº§n 1, ta Ä‘Ã£ giáº£m chiá»u dá»¯ liá»‡u báº±ng PCA rá»“i, tiáº¿p Ä‘áº¿n pháº§n nÃ y, chÃºng ta sáº½ dÃ¹ng K-means Ä‘á»ƒ phÃ¢n cá»¥m rá»“i tÃ¬m ra Ä‘iá»ƒm chung cá»§a dá»¯ liá»‡u nhÃ©, cuá»‘i cÃ¹ng lÃ  phÃ¢n tÃ­ch cÃ¡c â€œsá»± kiá»‡nâ€ Ä‘Ã£ diá»…n ra trong tá»«ng cá»¥m. LÃ©t gÃ´ ! Má»™t láº§n ná»¯a xin cáº£m Æ¡n tháº§y Nguyá»…n HoÃ ng Äá»©c vÃ  tháº§y NgÃ´ Minh Máº«n Ä‘Ã£ há»— trá»£ Ä‘á»ƒ Ä‘á»“ Ã¡n Ä‘Æ°á»£c hoÃ n thiá»‡n. Äá»“ng thá»i cáº£m Æ¡n cÃ¡c thÃ nh viÃªn nhÃ³m 7 Ä‘Ã£ cÃ¹ng lÃ m viá»‡c háº¿t mÃ¬nh. ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:0:0","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#"},{"categories":["projects"],"content":"K-Means ClusteringNháº¯c láº¡i chÃºt xÃ­u, á»Ÿ Pháº§n 1 chÃºng ta Ä‘Ã£ dÃ¹ng PCA lÃ m giáº£m chiá»u dá»¯ liá»‡u nhÆ°ng xÃ©t vá» máº·t Ã½ nghÄ©a, dá»¯ liá»‡u sau PCA chÆ°a thá»ƒ phÃ¢n tÃ­ch Ä‘Æ°á»£c mÃ  ta sáº½ chá»‰ dÃ¹ng nÃ³ Ä‘á»ƒ Ã¡p vÃ o má»™t ká»¹ thuáº­t tiáº¿p theo. Ká»¹ thuáº­t nÃ y sáº½ â€œgá»™p nhÃ³mâ€ dá»¯ liá»‡u vÃ  tráº£ lá»i cÃ¢u há»i â€œlÃ m thá»ƒ nÃ o Ä‘á»ƒ phÃ¢n dá»¯ liá»‡u thÃ nh cÃ¡c cá»¥m (cluster) khÃ¡c nhau, sao cho dá»¯ liá»‡u trong cÃ¹ng má»™t cá»¥m cÃ³ tÃ­nh cháº¥t giá»‘ng nhau?â€ Báº£n cháº¥t cá»§a viá»‡c phÃ¢n nhÃ³m nÃ y dá»±a trÃªn nhá»¯ng biáº¿n Ä‘á»™ng, sá»± kiá»‡n nÃ o Ä‘Ã³ trÃªn thá»‹ trÆ°á»ng mÃ  chÃºng ta chÆ°a biáº¿t nhÆ°ng nÃ³ chi phá»‘i trá»±c tiáº¿p hay giÃ¡n tiáº¿p, nhiá»u hay Ã­t Ä‘áº¿n vá»›i cÃ¡c cá»• phiáº¿u cÃ³ liÃªn quan. ChÃ­nh vÃ¬ lÃ½ do Ä‘Ã³, chÃºng ta tiáº¿n hÃ nh sá»­ dá»¥ng thuáº­t toÃ¡n K-Means Clustering Ä‘á»ƒ phÃ¢n cá»¥m dá»¯ liá»‡u phá»¥c vá»¥ má»¥c tiÃªu Ä‘á» ra. Trong bÃ i nÃ y chÃºng ta sáº½ thá»±c hiá»‡n thuáº­t K-means step by step, nÃ o báº¯t Ä‘áº§u thoaii ğŸ˜„ ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:1:0","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#k-means-clustering"},{"categories":["projects"],"content":"K-Means step by stepStep 1: Lá»±a chá»n sá»‘ clusters $K$ # initialize labels N, d = X_pca.shape pre_labels = np.zeros((N, 1)) # Hyper-parameters K_CLUSTERS = 3 # \u003c\u003c N Step 2: Chá»n K Ä‘iá»ƒm ngáº«u nhiÃªn tá»« dá»¯ liá»‡u lÃ m trá»ng tÃ¢m import random # random K-samples to be centroids k_indices = random.sample(range(0, N), K_CLUSTERS) centroids = X_pca[k_indices] # shape: (K, d) Step 3: GÃ¡n táº¥t cáº£ cÃ¡c Ä‘iá»ƒm cho tÃ¢m cá»¥m gáº§n nháº¥t HÃ m assign_cluster() giÃºp ta phÃ¢n má»—i Ä‘iá»ƒm dá»¯ liá»‡u vÃ o cluster cÃ³ center gáº§n nÃ³ nháº¥t vá»›i K Ä‘iá»ƒm báº¥t ká»³ Ä‘Æ°á»£c chá»n lÃ m cÃ¡c center ban Ä‘áº§u def assign_cluster(distances: np.ndarray) -\u003e np.ndarray: # distances: (N, K) return np.argmin(distances, axis=1) # return min value from distances array Cá»¥ thá»ƒ: Máº£ng distances chá»©a khoáº£ng cÃ¡ch tá»« Ä‘iá»ƒm $i$ Ä‘áº¿n cá»¥m $k$, Ä‘Ã¢y lÃ  khoáº£ng cÃ¡ch Euclid vá»›i cÃ´ng thá»©c distance$(x,y)=||x-y||$ HÃ m np.argmin() tráº£ vá» giÃ¡ trá»‹ cá»§a biáº¿n sá»‘ Ä‘á»ƒ hÃ m sá»‘ Ä‘Ã³ Ä‘áº¡t giÃ¡ trá»‹ nhá» nháº¥t. NÃ³i cÃ¡ch khÃ¡c, nÃ³ giÃºp chÃºng ta tÃ¬m ra Ä‘Æ°á»£c vá»‹ trÃ­ mÃ  Ä‘iá»ƒm dá»¯ liá»‡u pháº£i thuá»™c vá» dá»±a trÃªn quy táº¯c gáº§n cá»¥m nÃ o nháº¥t thÃ¬ chá»n cá»¥m Ä‘Ã³. VÃ­ dá»¥: # Example for np.argmin() # k = 0 1 2 D = np.array([[1, 0, 3], # min = 0 and it locate in 1 -\u003e x_1 y_1 = 1 [-1, 2, 1]]) # min =-1 and it locate in 0 -\u003e x_2 y_2 = 0 np.argmin(D, axis=1) # --\u003e array([1,0]) Step 4: TÃ­nh toÃ¡n láº¡i cÃ¡c trá»ng tÃ¢m cá»§a cÃ¡c cá»¥m má»›i Ä‘Æ°á»£c hÃ¬nh thÃ nh HÃ m update_centroids() dÃ¹ng cáº­p nháº­t láº¡i tÃ¢m cá»¥m vÃ  tráº£ vá» 1 bá»™ cÃ¡c tÃ¢m cá»¥m má»›i báº±ng cÃ¡ch láº¥y trung bÃ¬nh cá»™ng cá»§a táº¥t cÃ¡c cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n vÃ o cluster Ä‘Ã³. def update_centroids(X, labels): new_centroids = np.array([X[labels == k].mean(axis=0) for k in range(K_CLUSTERS)]) return new_centroids # (3, 13) Cuá»‘i cÃ¹ng: láº·p láº¡i step 3 vÃ  step 4 Question Khi nÃ o thÃ¬ bÃ i toÃ¡n há»™i tá»¥ váº­y OG ? Khi nÃ o thÃ¬ chÃºng ta má»›i dá»«ng láº¡i thuáº­t toÃ¡n ? â€“\u003e CÃ¢u tráº£ lá»i lÃ  khi viá»‡c phÃ¢n cá»¥m khÃ´ng cÃ²n sá»± thay Ä‘á»•i nÃ o ná»¯a hoáº·c giÃ¡ trá»‹ hÃ m máº¥t mÃ¡t khÃ´ng thay Ä‘á»•i nhiá»u sau má»—i láº§n update tÃ¢m cá»¥m. ChÃºng ta sáº½ viáº¿t má»™t hÃ m kiá»ƒm tra tÃ­nh há»™i tá»¥ cá»§a bÃ i toÃ¡n lÃ  has_convert(). HÃ m nÃ y kiá»ƒm tra cá»¥m trÆ°á»›c vÃ  sau cÃ³ giá»‘ng nhau khÃ´ng. # Check convergence def has_convert(pre_labels: np.ndarray, cur_labels: np.ndarray) -\u003e bool: return (pre_labels == cur_labels).all() HÃ m get_total_wcv() lÃ  má»™t hÃ m máº¥t mÃ¡t, tÃ­nh tá»•ng cÃ¡c phÆ°Æ¡ng sai bÃªn trong cá»§a 1 cluster Náº¿u ta coi $m_k$ lÃ  center (representation) cá»§a má»—i cluster vÃ  Æ°á»›c lÆ°á»£ng táº¥t cáº£ cÃ¡c Ä‘iá»ƒm Ä‘Æ°á»£c phÃ¢n vÃ o cluster nÃ y bá»Ÿi $m_k$, thÃ¬ má»™t Ä‘iá»ƒm dá»¯ liá»‡u $x_i$ Ä‘Æ°á»£c phÃ¢n vÃ o cluster $k$ sáº½ bá»‹ sai sá»‘ lÃ  $(x_i-m_k)$. ChÃºng ta mong muá»‘n sai sá»‘ nÃ y cÃ³ trá»‹ tuyá»‡t Ä‘á»‘i bÃ© nháº¥t nÃªn ta sáº½ tÃ¬m cÃ¡ch Ä‘á»ƒ Ä‘áº¡i lÆ°á»£ng sau Ä‘Ã¢y Ä‘áº¡t min: $||x_i - m_k||^2_2$ def get_total_wcv(X, labels, centroids): # Total within cluster variance WCVs = [ np.sum(np.linalg.norm(X[labels == k] - centroids[k], axis=1) ** 2) \\ for k in range(K_CLUSTERS) ] return np.sum(WCVs) NhÃ¬n chung vá» Ä‘iá»u kiá»‡n há»™i tá»¥ cÃ³ thá»ƒ tháº¥y má»‘i liÃªn há»‡ giá»¯a cÃ¡c Ä‘iá»u kiá»‡n lÃ  gáº§n tÆ°Æ¡ng Ä‘á»“ng nhÆ° nhau. Khi cÃ³ Ã­t Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Æ°á»£c gÃ¡n sang cluster khÃ¡c cÃ³ thá»ƒ khiáº¿n Ä‘iá»ƒm trung tÃ¢m khÃ´ng thay Ä‘á»•i nhiá»u vÃ  tá»« Ä‘Ã³ hÃ m máº¥t mÃ¡t cÅ©ng sáº½ Ã­t bá»‹ áº£nh hÆ°á»Ÿng. ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:1:1","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#k-means-step-by-step"},{"categories":["projects"],"content":"The K-means algorithm is written in object-oriented formTa sáº½ káº¿t há»£p táº¥t cáº£ cÃ¡c bÆ°á»›c thuáº­t toÃ¡n vÃ o má»™t Ä‘á»‘i tÆ°á»£ng KMeansClustering import numpy as np import pandas as pd import random import matplotlib.pyplot as plt from scipy.spatial import distance class KMeansClustering: \"\"\" An instance of K-Means Clustering algorithm \"\"\" def __init__(self, n_clusters=29): \"\"\" n_clusters: number of clusters _centroids: center/ centroid of clusters inertia_: sum of squared distances of samples to their closest cluster center labels_: labels of input samples X: input data \"\"\" self.n_clusters = n_clusters def fit(self, X: np.ndarray) -\u003e None: \"\"\" K-means execution \"\"\" N, p = X.shape self.X = X # random K-samples to be centroids k_indices = random.sample(range(0, N), self.n_clusters) self._centroids = self.X[k_indices] # initialize labels pre_labels = np.zeros((N, 1)) # training it = 0 while True: # compute distances from X_i to distances = self._calc_dists(self.X, self._centroids) # assign new labels self.labels_ = self._assign_cluster(distances) # assign new labels # check convergence if self._has_convert(pre_labels, self.labels_): break # update centroids self._update_centroids(self.X, self.labels_) pre_labels = self.labels_ it += 1 # compute total Within Cluster Variance (WCV) self.inertia_ = self._calc_total_WCV(self.X, self.labels_, self._centroids) def _calc_dists(self, X, centroids): return distance.cdist(X, centroids, \"euclidean\") def _assign_cluster(self, distances): return np.argmin(distances, axis=1) def _update_centroids(self, X, labels): self._centroids = np.array( [X[labels == k].mean(axis=0) for k in range(self.n_clusters)] ) def _calc_total_WCV(self, X, labels, centroids): WCVs = [ np.sum(np.linalg.norm(X[labels == k] - centroids[k], axis=1) ** 2) for k in range(self.n_clusters) ] return np.sum(WCVs) def _has_convert(self, pre_labels, cur_labels): return (pre_labels == cur_labels).all() def _predict(self, X_test): dist_test = self._calc_dists(X_test, self._centroids) test_labels = self._assign_cluster(dist_test) return test_labels def predict(self, X_test): return self._predict(X_test) TrÆ°á»›c khi tháº­t sá»± Ã¡p dá»¥ng thuáº­t toÃ¡n nÃ y cho dataset cá»§a chÃºng ta, cÃ³ má»™t cÃ¢u há»i Ä‘áº·t ra lÃ : Thuáº­t toÃ¡n nÃ y thá»±c hiá»‡n vá»›i Ä‘áº§u vÃ o lÃ  sá»‘ $K$ tá»©c lÃ  sá»‘ lÆ°á»£ng cluster, tháº¿ thÃ¬ $K$ báº±ng bao nhiÃªu lÃ  tá»‘t nháº¥t? ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:1:2","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#the-k-means-algorithm-is-written-in-object-oriented-form"},{"categories":["projects"],"content":"Finding the optimal â€˜Kâ€™ in a K-Means clusteringCÃ³ má»™t phÆ°Æ¡ng phÃ¡p tÃªn lÃ  Elbow aka cÃ¡i khuá»·a tay ğŸ˜„ PhÆ°Æ¡ng phÃ¡p Elbow lÃ  má»™t cÃ¡ch giÃºp ta lá»±a chá»n Ä‘Æ°á»£c sá»‘ lÆ°á»£ng cÃ¡c cá»¥m phÃ¹ há»£p dá»±a vÃ o Ä‘á»“ thá»‹ trá»±c quan hoÃ¡ báº±ng cÃ¡ch nhÃ¬n vÃ o sá»± suy giáº£m cá»§a hÃ m biáº¿n dáº¡ng vÃ  lá»±a chá»n ra Ä‘iá»ƒm khuá»·u tay (elbow point). Äá»‘i vá»›i má»—i giÃ¡ trá»‹ cá»§a $K$, ta tÃ­nh toÃ¡n WCSS (Tá»•ng bÃ¬nh phÆ°Æ¡ng trong cá»¥m). WCSS lÃ  tá»•ng bÃ¬nh phÆ°Æ¡ng khoáº£ng cÃ¡ch giá»¯a má»—i Ä‘iá»ƒm vÃ  tÃ¢m trong má»™t cá»¥m. def elbow_method(X, k_clusters = list(range(1,9))): total_wcss = [] for k in k_clusters: # Train with k cluster kmeans_model = KMeansClustering(n_clusters=k) kmeans_model.fit(X) # calculate WCSS total_wcss.append(kmeans_model.inertia_) plt.figure() plt.plot(k_clusters, total_wcss, marker='o', color='r') plt.ylabel('WCSS') plt.xlabel('Number of clusters K') plt.grid() plt.show() elbow_method(X_pca) Khi ta váº½ Ä‘á»“ thá»‹ WCSS vá»›i giÃ¡ trá»‹ K, Ä‘á»“ thá»‹ trÃ´ng giá»‘ng nhÆ° má»™t khuá»·u tay. Khi sá»‘ cá»¥m tÄƒng lÃªn, giÃ¡ trá»‹ WCSS sáº½ báº¯t Ä‘áº§u giáº£m. GiÃ¡ trá»‹ WCSS lá»›n nháº¥t khi $K=1$ elbow_method ChÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng biá»ƒu Ä‘á»“ sáº½ thay Ä‘á»•i nhanh chÃ³ng táº¡i $K=2$ vÃ  do Ä‘Ã³ táº¡o ra hÃ¬nh dáº¡ng khuá»·u tay. Tá»« thá»i Ä‘iá»ƒm nÃ y, Ä‘á»“ thá»‹ di chuyá»ƒn gáº§n nhÆ° song song vá»›i trá»¥c $X$ GiÃ¡ trá»‹ $K$ tÆ°Æ¡ng á»©ng vá»›i Ä‘iá»ƒm nÃ y lÃ  giÃ¡ trá»‹ tá»‘i Æ°u cá»§a $K$ hoáº·c cá»¥m tá»‘i Æ°u. ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:1:3","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#finding-the-optimal-k-in-a-k-means-clustering"},{"categories":["projects"],"content":"Evaluation Metrics of K-Means ClusteringSilhouette Score: cho chÃºng ta biáº¿t nhá»¯ng Ä‘iá»ƒm dá»¯ liá»‡u hay nhá»¯ng quan sÃ¡t nÃ o náº±m gá»n bÃªn trong cá»¥m (tá»‘t) hay náº±m gáº§n ngoÃ i rÃ¬a cá»¥m (khÃ´ng tá»‘t) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ phÃ¢n cá»¥m. Giáº£ sá»­ cÃ³ 2 cluster A, B thÃ¬ Silhouette score lÃ : $$ s_i = \\frac{(b_i - a_i)}{max(b_i - a_i)} $$ Vá»›i $a_i, b_i$ láº§n lÆ°á»£t lÃ  khoáº£ng cÃ¡ch cá»§a Ä‘iá»ƒ $i$ Ä‘áº¿n tÃ¢m cá»¥m A vÃ  B GiÃ¡ trá»‹ nÃ y náº±m trong khoáº£ng [-1, 1]: Äiá»ƒm dá»¯ liá»‡u cÃ³ Silhouette cao, gáº§n báº±ng 1: náº±m Ä‘Ãºng trong cluster. Äiá»ƒm dá»¯ liá»‡u cÃ³ Silhouette gáº§n báº±ng 0: náº±m giá»¯a 2 cluster Äiá»ƒm dá»¯ liá»‡u cÃ³ Silhouette tháº¥p, cÃ³ giÃ¡ trá»‹ Ã¢m: thÃ¬ kháº£ nÄƒng Ä‘Ã£ náº±m sai cluster. from sklearn import metrics kmeans_train = KMeansClustering(2) kmeans_train.fit(X_pca) labels = kmeans_train.labels_ print(f'Silhouette Score (n = 2): {metrics.silhouette_score(X_pca,labels)}') #--\u003e Silhouette Score (n = 2): 0.265365408366845 kmeans_train = KMeansClustering(3) kmeans_train.fit(X_pca) labels = kmeans_train.labels_ print(f'Silhouette Score (n = 3): {metrics.silhouette_score(X_pca,labels)}') # --\u003e Silhouette Score (n = 3): 0.22528216696570613 á» PhÆ°Æ¡ng phÃ¡p Elbow, chÃºng ta cÅ©ng Ä‘Ã£ tháº¥y Ä‘Æ°á»£c $K$ tá»‘i Æ°u cho bÃ i toÃ¡n chÃ­nh lÃ  khi chá»n $K=2$. NhÆ°ng á»Ÿ bÆ°á»›c nÃ y, ta cÅ©ng tháº¥y Ä‘Æ°á»£c rÃµ rÃ ng hÆ¡n giá»¯a 2 sá»± lá»±a chá»n $K=2$ vÃ  $K=3$ báº±ng cÃ¡ch so sÃ¡nh chá»‰ sá»‘ Silhouette giá»¯a bá»n chÃºng. So sÃ¡nh: $0.265(K=2) \u003e 0.225(K=3)$ Tá»« Ä‘Ã³, má»™t láº§n ná»¯a ta tháº¥y Ä‘Æ°á»£c $K$ tá»‘i Æ°u nháº¥t cho bÃ i toÃ¡n nÃ y lÃ  $K=2$ ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:1:4","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#evaluation-metrics-of-k-means-clustering"},{"categories":["projects"],"content":"VisualizeSau táº¥t cáº£ cÃ¡c bÆ°á»›c trÃªn, dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh 2 label chÃ­nh tÆ°Æ¡ng á»©ng vá»›i tá»«ng mÃ u sáº¯c Ä‘Æ°á»£c biá»ƒu thá»‹ dÆ°á»›i hÃ¬nh váº½ sau Ä‘Ã¢y: # K means import plotly.express as px K_CLUSTERS = 2 kmeans_train = KMeansClustering(K_CLUSTERS) kmeans_train.fit(X_pca) fig = px.scatter_matrix( X_pca, labels=pca_scree, dimensions=range(4), color=kmeans_train.labels_ ) fig.update_traces(diagonal_visible=False) fig.show() Kmeans Clustering Sau khi chia cá»¥m, chÃºng ta Ä‘áº¿n vá»›i bÆ°á»›c cuá»‘i cÃ¹ng thÃ´i ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:1:5","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#visualize"},{"categories":["projects"],"content":"Data AnalysisSau khi K-means, ta cÃ³ Ä‘Æ°á»£c má»™t táº­p nhÃ£n (labels), ta sáº½ gÃ¡n cÃ¡c nhÃ£n nÃ y vÃ o bá»™ data cÃ³ giÃ¡ trá»‹ vÃ  tiáº¿n hÃ nh phÃ¢n tÃ­ch tá»«ng cá»¥m. # Data #set label value_data = new_market.copy() value_data['label'] = kmeans_train.labels_ value_data['label'].replace({0: 'A', 1: 'B'}, inplace=True) # get specific columns gtb = [col for col in value_data.columns.to_list() if 'gttb_' in col] mua = [col for col in value_data.columns.to_list() if 'total_mua' in col] ban = [col for col in value_data.columns.to_list() if 'total_ban' in col] # create new valuabel column value_data['total_ban_30'] = value_data[ban].sum(axis=1) value_data['total_mua_30'] = value_data[mua].sum(axis=1) value_data['total_volume_30'] = value_data['total_ban_30'] + value_data['total_mua_30'] value_data['mua_ban_ratio'] = value_data['total_mua_30'] / value_data['total_ban_30'] value_data bao gá»“m cÃ¡c cá»™t: label: nhÃ£n nháº­n Ä‘Æ°á»£c tá»« K means (gá»“m â€˜Aâ€™ vÃ  â€˜Bâ€™) gttb_{mÃ£}: Trung bÃ¬nh giÃ¡ cá»§a má»™t {mÃ£} cá»• phiáº¿u total_mua_{mÃ£}: Tá»•ng khá»‘i lÆ°á»£ng mua cá»§a {mÃ£} cá»• phiáº¿u total_ban_{mÃ£}: Tá»•ng khá»‘i lÆ°á»£ng bÃ¡n cá»§a {mÃ£} cá»• phiáº¿u total_mua_30: Tá»•ng khá»‘i lÆ°á»£ng mua cá»§a táº¥t cáº£ 30 cá»• phiáº¿u total_ban_30: Tá»•ng khá»‘i lÆ°á»£ng bÃ¡n cá»§a táº¥t cáº£ 30 cá»• phiáº¿u total_volume_30: Tá»•ng khá»‘i lÆ°á»£ng giao dá»‹ch cá»§a 30 cá»• phiáº¿u (total_mua_30 + total_ban_30) mua_ban_ratio: tá»‰ sá»‘ total_mua_30 / total_ban_30 Gia KL: GiÃ¡ phÃ¡i sinh gáº§n vá»›i VN30 Time-series Data theo phÃºt (5154 dÃ²ng) ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:2:0","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#data-analysis"},{"categories":["projects"],"content":"Analytical Overview import plotly.graph_objects as go import plotly.express as px from plotly.subplots import make_subplots fig = make_subplots(rows=2, cols=2, vertical_spacing=0.03) # plot A fig.add_trace(go.Bar(name='',x=value_data.index[value_data['label'] == 'A'], y=value_data['total_volume_30'][value_data['label'] == 'A']), row=1, col=1) fig.add_trace(go.Scatter(x=value_data.index[value_data['label'] == 'A'], y=value_data['Gia KL'][value_data['label'] == 'A'], mode='lines'), row=2, col=1) # plot B fig.add_trace(go.Bar(name='',x=value_data.index[value_data['label'] == 'B'], y=value_data['total_volume_30'][value_data['label'] == 'B']), row=1, col=2) fig.add_trace(go.Scatter(x=value_data.index[value_data['label'] == 'B'], y=value_data['Gia KL'][value_data['label'] == 'B'], mode='lines'), row=2, col=2) # update layout fig.update_layout(title_text=\"Stock Data Visualization\", showlegend=False, barmode='stack') fig.update_yaxes(title_text=\"Total Volume 30\", row=1, col=1) fig.update_yaxes(title_text=\"Gia KL\", row=2, col=1) fig.update_yaxes(title_text=\"Total Volume 30\", row=1, col=2) fig.update_yaxes(title_text=\"Gia KL\", row=2, col=2) fig.show() Stock Data Visualization Cluster B chá»©a cÃ¡c dá»¯ liá»‡u trong giai Ä‘oáº¡n tá»« 20/3 Ä‘áº¿n 6/4/2023 NhÃ¬n nháº­n má»™t cÃ¡ch tá»•ng quÃ¡t: Äá»‘i vá»›i cluster B, thá»‹ trÆ°á»ng luÃ´n trong tháº¿ â€œgiáº±ng coâ€ vá»›i khoáº£ng 6 Ä‘á»£t giáº£m máº¡nh vÃ  chá»«ng áº¥y Ä‘á»£t phá»¥c há»“i liÃªn tá»¥c trong suá»‘t 18 ngÃ y. Máº·c dÃ¹ GiaKL duy trÃ¬ Ä‘Æ°á»£c Ä‘Ã  tÄƒng (GiÃ¡ KL tá»« 1036 tÄƒng Ä‘áº¿n 1080) táº¡o tÃ­ch cá»±c cho thá»‹ trÆ°á»ng song tháº¿ giáº±ng co váº«n cÃ³ chiá»u hÆ°á»›ng kÃ©o dÃ i. Cluster A chá»©a cÃ¡c dá»¯ liá»‡u trong giai Ä‘oáº¡n tá»« 1/4 Ä‘áº¿n 19/4/2023: NhÃ¬n nháº­n má»™t cÃ¡ch tá»•ng quÃ¡t: Äá»‘i vá»›i cluster A cÃ¡c khoáº£ng giáº£m kÃ©o dÃ i trong nhiá»u ngÃ y dáº«n Ä‘áº¿n viá»‡c phá»¥c há»“i gáº·p khÃ³ khÄƒn Ä‘Ã¡ng ká»ƒ. Cá»¥ thá»ƒ, GiaKL cÃ³ má»©c â€œvÃ¹ng dáº­yâ€ Ä‘áº¿n ngÆ°á»¡ng 1086 Ä‘iá»ƒm táº¡i 6/4 nhÆ°ng láº¡i bá»‹ Ä‘áº©y vá» 1054 vÃ o cuá»‘i giai Ä‘oáº¡n. Ta sáº½ phÃ¢n tÃ­ch sÃ¢u hÆ¡n tá»«ng cluster má»™t ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:2:1","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#analytical-overview"},{"categories":["projects"],"content":"Cluster B import plotly.express as px gtb = [col for col in value_data.columns.to_list() if 'gttb_' in col] fig = px.line(value_data[gtb][value_data['label'] == 'B'], y=gtb, title='Mean Values by Label B') fig.update_layout(xaxis_title=\"Times\", yaxis_title=\"Mean Values\", font=dict(family=\"Courier New, monospace\", size=10, color=\"RebeccaPurple\")) fig.show() Mean Values by Label B import plotly.graph_objs as go # Create first trace trace1 = go.Bar(name='mua', x=value_data.index[value_data['label'] == 'B'], y=value_data['total_ban_30'][value_data['label'] == 'B']) # Create second trace trace2 = go.Bar(name='ban', x=value_data.index[value_data['label'] == 'B'], y=value_data['total_mua_30'][value_data['label'] == 'B']) # Create third trace trace3 = go.Scatter(name=\"GiaKL\",x=value_data.index[value_data['label'] == 'B'], y=value_data['Gia KL'][value_data['label'] == 'B'], mode='lines', yaxis='y2') # Create layout layout = go.Layout(title='The chart shows the correlation between Total Volumn and GiaKL', xaxis=dict(title='Times'), yaxis=dict(title='Total Volumn', side='left'), yaxis2=dict(title='Gia KL', side='right', overlaying='y'), barmode=\"stack\") # Add traces to figure fig = go.Figure(data=[trace1, trace2, trace3], layout=layout) # Show figure fig.show() B-Correlation between Total Volumn and GiaKL Biáº¿n Ä‘á»™ng thá»‹ trÆ°á»ng phantramtangtruong = (1081.55 - 1014.331)/1014.331 print(\"Gia tri cua phien cao nhat so voi phien nho nhat: \",phantramtangtruong) # --\u003e 0.06626929473712223 Giai Ä‘oáº¡n nÃ y cho tháº¥y sá»± gia tÄƒng cá»§a giÃ¡ trá»‹ cÃ¡c cá»• phiáº¿u, vá»›i sá»©c tÄƒng lá»›n nháº¥t trong ngÆ°á»¡ng tiá»‡m cáº­n 0.07% cho tháº¥y sá»± háº¥p dáº«n cá»§a thá»‹ trÆ°á»ng Ä‘ang trÃªn Ä‘Ã  phá»¥c há»“i. VÃ o cuá»‘i thÃ¡ng 3, nhÃ³m dá»‹ch vá»¥ tÃ i chÃ­nh tiáº¿p tá»¥c tÄƒng Ä‘iá»ƒm khÃ¡ máº¡nh, nhÃ³m ngÃ¢n hÃ ng cÅ©ng cÃ³ diá»…n biáº¿n tÃ­ch cá»±c, nhÃ³m báº¥t Ä‘á»™ng sáº£n vá»›i thÃ´ng tin kháº£ nÄƒng tiáº¿p tá»¥c háº¡ lÃ£i suáº¥t gÃºp thanh khoáº£n cáº£i thiá»‡n tá»‘t, nhiá»u mÃ£ cÃ³ tÃ­n hiá»‡u thoÃ¡t khá»i xu hÆ°á»›ng giáº£m giÃ¡ trung háº¡n kÃ©o dÃ iâ€¦ Vá»›i cÃ¡c phiÃªn tÄƒng giáº£m Ä‘an xen, khá»‘i lÆ°á»£ng giao dá»‹ch vá» tá»•ng thá»ƒ trung háº¡n váº«n Ä‘ang á»Ÿ má»©c tháº¥p. Giai Ä‘oáº¡n cuá»‘i thÃ¡ng 3, khá»‘i lÆ°á»£ng giao dá»‹ch Ä‘ang trong xu hÆ°á»›ng giáº£m, cho tháº¥y cÃ¡c trader Ä‘ang giáº£m dáº§n cÃ¡c vá»‹ tháº¿ náº¯m giá»¯ vÃ  cÃ³ thá»ƒ dá»‹ch chuyá»ƒn sang á»Ÿ thá»‹ trÆ°á»ng cÆ¡ sá»Ÿ khi trÃªn thá»‹ trÆ°á»ng cÆ¡ sá»Ÿ Ä‘ang cÃ³ nhiá»u cÆ¡ há»™i sinh lá»£i ngáº¯n háº¡n tá»‘t. Thá»‹ trÆ°á»ng Ä‘Ã£ há»“i phá»¥c 6 phiÃªn liÃªn tiáº¿p dÃ¹ Ä‘iá»ƒm sá»‘ tÄƒng tá»«ng phiÃªn khÃ´ng lá»›n nhÆ°ng Ä‘á»§ giÃºp thá»‹ trÆ°á»ng quay trá»Ÿ láº¡i kÃªnh tÄƒng giÃ¡ ngáº¯n háº¡n vÃ  náº±m trÃªn Ä‘Æ°á»ng MA20. total_ban_theo_ngay = value_data.total_ban_30[value_data['label'] == 'B'].to_frame() ngay_dau = total_ban_theo_ngay['total_ban_30'].iat[0] ngay_cuoi = total_ban_theo_ngay['total_ban_30'].iat[-1] phantramtangtruong = (ngay_cuoi - ngay_dau)/ngay_dau print(\"Tong so co phieu ban ra cua ngay cuoi giai doan so voi ngay dau co muc tang truong la: \",phantramtangtruong) # --\u003e -0.637694475209741 total_ban_theo_ngay = value_data.total_mua_30[value_data['label'] == 'B'].to_frame() ngay_dau = total_ban_theo_ngay['total_mua_30'].iat[0] ngay_cuoi = total_ban_theo_ngay['total_mua_30'].iat[-1] phantramtangtruong = (ngay_cuoi - ngay_dau)/ngay_dau print(\"Tong so co phieu mua vao cua ngay cuoi giai doan so voi ngay dau co muc tang truong la: \",phantramtangtruong) # --\u003e -0.8043500703402909 CÃ³ thá»ƒ tháº¥y, sá»‘ cá»• phiáº¿u Ä‘Æ°á»£c bÃ¡n ra á»Ÿ cuá»‘i giai Ä‘oáº¡n (Ä‘áº§u thÃ¡ng 4) so vá»›i thÃ¡ng 3 cÃ³ sá»± sá»¥t giáº£m. Cá»• phiáº¿u Ä‘Æ°á»£c mua vÃ o cÅ©ng tÄƒng trÆ°á»Ÿng Ã¢m, cÃ¡c nhÃ  Ä‘áº§u tÆ° buá»™c pháº£i giá»¯ láº¡i cÃ¡c cá»• phiáº¿u cÃ²n tá»“n Ä‘á»ng táº¡o nÃªn má»™t tháº¿ kÃ¬m hÃ£m thanh khoáº£n. Do Ä‘Ã³, trong tÆ°Æ¡ng lai gáº§n sáº½ chá»‹u tÃ¡c Ä‘á»™ng cá»§a sá»± chÃªnh lá»‡ch nÃ y. CÃ¡c sá»± kiá»‡n áº£nh hÆ°á»Ÿng NgÃ y 22-23/3/2023, láº§n thá»© 9 liÃªn tiáº¿p FED tÄƒng lÃ£i suáº¥t, nÃ¢ng phaÌ£m vi laÌƒi suÃ¢Ìt lÃªn mÆ°Ìc dao Ä‘Ã´Ì£ng tÆ°Ì€ 4,75% Ä‘ÃªÌn 5%. Má»¥c Ä‘Ã­ch Ä‘á»ƒ tráº¥n an thá»‹ trÆ°á»ng, giá»¯ uy tÃ­n vÃ  chá»‘ng láº¡m phÃ¡t. Trong bá»‘i cáº£nh thanh khoáº£n trÃªn thá»‹ trÆ°á»ng tÃ i chÃ­nh quá»‘c táº¿ tháº¯t cháº·t hÆ¡n, ChÃ­nh phá»§ vÃ  cÃ¡c doanh nghiá»‡p Viá»‡t Nam sáº½ khÃ³ huy Ä‘á»™ng vá»‘n trÃªn thá»‹ trÆ°á»ng quá»‘c táº¿ vÃ  pháº£i chá»‹u má»©c chi phÃ­ tÃ i chÃ­nh cao hÆ¡n. NgÃ y 31/3/2023, NgÃ¢n hÃ ng NhÃ  nÆ°á»›c Viá»‡t Nam Ä‘iá»u chá»‰nh giáº£m cÃ¡c má»©c lÃ£","date":"05 Sep 2023","objectID":"/stock_analysis_2/:2:2","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#cluster-b"},{"categories":["projects"],"content":"Cluster B import plotly.express as px gtb = [col for col in value_data.columns.to_list() if 'gttb_' in col] fig = px.line(value_data[gtb][value_data['label'] == 'B'], y=gtb, title='Mean Values by Label B') fig.update_layout(xaxis_title=\"Times\", yaxis_title=\"Mean Values\", font=dict(family=\"Courier New, monospace\", size=10, color=\"RebeccaPurple\")) fig.show() Mean Values by Label B import plotly.graph_objs as go # Create first trace trace1 = go.Bar(name='mua', x=value_data.index[value_data['label'] == 'B'], y=value_data['total_ban_30'][value_data['label'] == 'B']) # Create second trace trace2 = go.Bar(name='ban', x=value_data.index[value_data['label'] == 'B'], y=value_data['total_mua_30'][value_data['label'] == 'B']) # Create third trace trace3 = go.Scatter(name=\"GiaKL\",x=value_data.index[value_data['label'] == 'B'], y=value_data['Gia KL'][value_data['label'] == 'B'], mode='lines', yaxis='y2') # Create layout layout = go.Layout(title='The chart shows the correlation between Total Volumn and GiaKL', xaxis=dict(title='Times'), yaxis=dict(title='Total Volumn', side='left'), yaxis2=dict(title='Gia KL', side='right', overlaying='y'), barmode=\"stack\") # Add traces to figure fig = go.Figure(data=[trace1, trace2, trace3], layout=layout) # Show figure fig.show() B-Correlation between Total Volumn and GiaKL Biáº¿n Ä‘á»™ng thá»‹ trÆ°á»ng phantramtangtruong = (1081.55 - 1014.331)/1014.331 print(\"Gia tri cua phien cao nhat so voi phien nho nhat: \",phantramtangtruong) # -- 0.06626929473712223 Giai Ä‘oáº¡n nÃ y cho tháº¥y sá»± gia tÄƒng cá»§a giÃ¡ trá»‹ cÃ¡c cá»• phiáº¿u, vá»›i sá»©c tÄƒng lá»›n nháº¥t trong ngÆ°á»¡ng tiá»‡m cáº­n 0.07% cho tháº¥y sá»± háº¥p dáº«n cá»§a thá»‹ trÆ°á»ng Ä‘ang trÃªn Ä‘Ã  phá»¥c há»“i. VÃ o cuá»‘i thÃ¡ng 3, nhÃ³m dá»‹ch vá»¥ tÃ i chÃ­nh tiáº¿p tá»¥c tÄƒng Ä‘iá»ƒm khÃ¡ máº¡nh, nhÃ³m ngÃ¢n hÃ ng cÅ©ng cÃ³ diá»…n biáº¿n tÃ­ch cá»±c, nhÃ³m báº¥t Ä‘á»™ng sáº£n vá»›i thÃ´ng tin kháº£ nÄƒng tiáº¿p tá»¥c háº¡ lÃ£i suáº¥t gÃºp thanh khoáº£n cáº£i thiá»‡n tá»‘t, nhiá»u mÃ£ cÃ³ tÃ­n hiá»‡u thoÃ¡t khá»i xu hÆ°á»›ng giáº£m giÃ¡ trung háº¡n kÃ©o dÃ iâ€¦ Vá»›i cÃ¡c phiÃªn tÄƒng giáº£m Ä‘an xen, khá»‘i lÆ°á»£ng giao dá»‹ch vá» tá»•ng thá»ƒ trung háº¡n váº«n Ä‘ang á»Ÿ má»©c tháº¥p. Giai Ä‘oáº¡n cuá»‘i thÃ¡ng 3, khá»‘i lÆ°á»£ng giao dá»‹ch Ä‘ang trong xu hÆ°á»›ng giáº£m, cho tháº¥y cÃ¡c trader Ä‘ang giáº£m dáº§n cÃ¡c vá»‹ tháº¿ náº¯m giá»¯ vÃ  cÃ³ thá»ƒ dá»‹ch chuyá»ƒn sang á»Ÿ thá»‹ trÆ°á»ng cÆ¡ sá»Ÿ khi trÃªn thá»‹ trÆ°á»ng cÆ¡ sá»Ÿ Ä‘ang cÃ³ nhiá»u cÆ¡ há»™i sinh lá»£i ngáº¯n háº¡n tá»‘t. Thá»‹ trÆ°á»ng Ä‘Ã£ há»“i phá»¥c 6 phiÃªn liÃªn tiáº¿p dÃ¹ Ä‘iá»ƒm sá»‘ tÄƒng tá»«ng phiÃªn khÃ´ng lá»›n nhÆ°ng Ä‘á»§ giÃºp thá»‹ trÆ°á»ng quay trá»Ÿ láº¡i kÃªnh tÄƒng giÃ¡ ngáº¯n háº¡n vÃ  náº±m trÃªn Ä‘Æ°á»ng MA20. total_ban_theo_ngay = value_data.total_ban_30[value_data['label'] == 'B'].to_frame() ngay_dau = total_ban_theo_ngay['total_ban_30'].iat[0] ngay_cuoi = total_ban_theo_ngay['total_ban_30'].iat[-1] phantramtangtruong = (ngay_cuoi - ngay_dau)/ngay_dau print(\"Tong so co phieu ban ra cua ngay cuoi giai doan so voi ngay dau co muc tang truong la: \",phantramtangtruong) # -- -0.637694475209741 total_ban_theo_ngay = value_data.total_mua_30[value_data['label'] == 'B'].to_frame() ngay_dau = total_ban_theo_ngay['total_mua_30'].iat[0] ngay_cuoi = total_ban_theo_ngay['total_mua_30'].iat[-1] phantramtangtruong = (ngay_cuoi - ngay_dau)/ngay_dau print(\"Tong so co phieu mua vao cua ngay cuoi giai doan so voi ngay dau co muc tang truong la: \",phantramtangtruong) # -- -0.8043500703402909 CÃ³ thá»ƒ tháº¥y, sá»‘ cá»• phiáº¿u Ä‘Æ°á»£c bÃ¡n ra á»Ÿ cuá»‘i giai Ä‘oáº¡n (Ä‘áº§u thÃ¡ng 4) so vá»›i thÃ¡ng 3 cÃ³ sá»± sá»¥t giáº£m. Cá»• phiáº¿u Ä‘Æ°á»£c mua vÃ o cÅ©ng tÄƒng trÆ°á»Ÿng Ã¢m, cÃ¡c nhÃ  Ä‘áº§u tÆ° buá»™c pháº£i giá»¯ láº¡i cÃ¡c cá»• phiáº¿u cÃ²n tá»“n Ä‘á»ng táº¡o nÃªn má»™t tháº¿ kÃ¬m hÃ£m thanh khoáº£n. Do Ä‘Ã³, trong tÆ°Æ¡ng lai gáº§n sáº½ chá»‹u tÃ¡c Ä‘á»™ng cá»§a sá»± chÃªnh lá»‡ch nÃ y. CÃ¡c sá»± kiá»‡n áº£nh hÆ°á»Ÿng NgÃ y 22-23/3/2023, láº§n thá»© 9 liÃªn tiáº¿p FED tÄƒng lÃ£i suáº¥t, nÃ¢ng phaÌ£m vi laÌƒi suÃ¢Ìt lÃªn mÆ°Ìc dao Ä‘Ã´Ì£ng tÆ°Ì€ 4,75% Ä‘ÃªÌn 5%. Má»¥c Ä‘Ã­ch Ä‘á»ƒ tráº¥n an thá»‹ trÆ°á»ng, giá»¯ uy tÃ­n vÃ  chá»‘ng láº¡m phÃ¡t. Trong bá»‘i cáº£nh thanh khoáº£n trÃªn thá»‹ trÆ°á»ng tÃ i chÃ­nh quá»‘c táº¿ tháº¯t cháº·t hÆ¡n, ChÃ­nh phá»§ vÃ  cÃ¡c doanh nghiá»‡p Viá»‡t Nam sáº½ khÃ³ huy Ä‘á»™ng vá»‘n trÃªn thá»‹ trÆ°á»ng quá»‘c táº¿ vÃ  pháº£i chá»‹u má»©c chi phÃ­ tÃ i chÃ­nh cao hÆ¡n. NgÃ y 31/3/2023, NgÃ¢n hÃ ng NhÃ  nÆ°á»›c Viá»‡t Nam Ä‘iá»u chá»‰nh giáº£m cÃ¡c má»©c lÃ£","date":"05 Sep 2023","objectID":"/stock_analysis_2/:2:2","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#biáº¿n-Ä‘á»™ng-thá»‹-trÆ°á»ng"},{"categories":["projects"],"content":"Cluster B import plotly.express as px gtb = [col for col in value_data.columns.to_list() if 'gttb_' in col] fig = px.line(value_data[gtb][value_data['label'] == 'B'], y=gtb, title='Mean Values by Label B') fig.update_layout(xaxis_title=\"Times\", yaxis_title=\"Mean Values\", font=dict(family=\"Courier New, monospace\", size=10, color=\"RebeccaPurple\")) fig.show() Mean Values by Label B import plotly.graph_objs as go # Create first trace trace1 = go.Bar(name='mua', x=value_data.index[value_data['label'] == 'B'], y=value_data['total_ban_30'][value_data['label'] == 'B']) # Create second trace trace2 = go.Bar(name='ban', x=value_data.index[value_data['label'] == 'B'], y=value_data['total_mua_30'][value_data['label'] == 'B']) # Create third trace trace3 = go.Scatter(name=\"GiaKL\",x=value_data.index[value_data['label'] == 'B'], y=value_data['Gia KL'][value_data['label'] == 'B'], mode='lines', yaxis='y2') # Create layout layout = go.Layout(title='The chart shows the correlation between Total Volumn and GiaKL', xaxis=dict(title='Times'), yaxis=dict(title='Total Volumn', side='left'), yaxis2=dict(title='Gia KL', side='right', overlaying='y'), barmode=\"stack\") # Add traces to figure fig = go.Figure(data=[trace1, trace2, trace3], layout=layout) # Show figure fig.show() B-Correlation between Total Volumn and GiaKL Biáº¿n Ä‘á»™ng thá»‹ trÆ°á»ng phantramtangtruong = (1081.55 - 1014.331)/1014.331 print(\"Gia tri cua phien cao nhat so voi phien nho nhat: \",phantramtangtruong) # -- 0.06626929473712223 Giai Ä‘oáº¡n nÃ y cho tháº¥y sá»± gia tÄƒng cá»§a giÃ¡ trá»‹ cÃ¡c cá»• phiáº¿u, vá»›i sá»©c tÄƒng lá»›n nháº¥t trong ngÆ°á»¡ng tiá»‡m cáº­n 0.07% cho tháº¥y sá»± háº¥p dáº«n cá»§a thá»‹ trÆ°á»ng Ä‘ang trÃªn Ä‘Ã  phá»¥c há»“i. VÃ o cuá»‘i thÃ¡ng 3, nhÃ³m dá»‹ch vá»¥ tÃ i chÃ­nh tiáº¿p tá»¥c tÄƒng Ä‘iá»ƒm khÃ¡ máº¡nh, nhÃ³m ngÃ¢n hÃ ng cÅ©ng cÃ³ diá»…n biáº¿n tÃ­ch cá»±c, nhÃ³m báº¥t Ä‘á»™ng sáº£n vá»›i thÃ´ng tin kháº£ nÄƒng tiáº¿p tá»¥c háº¡ lÃ£i suáº¥t gÃºp thanh khoáº£n cáº£i thiá»‡n tá»‘t, nhiá»u mÃ£ cÃ³ tÃ­n hiá»‡u thoÃ¡t khá»i xu hÆ°á»›ng giáº£m giÃ¡ trung háº¡n kÃ©o dÃ iâ€¦ Vá»›i cÃ¡c phiÃªn tÄƒng giáº£m Ä‘an xen, khá»‘i lÆ°á»£ng giao dá»‹ch vá» tá»•ng thá»ƒ trung háº¡n váº«n Ä‘ang á»Ÿ má»©c tháº¥p. Giai Ä‘oáº¡n cuá»‘i thÃ¡ng 3, khá»‘i lÆ°á»£ng giao dá»‹ch Ä‘ang trong xu hÆ°á»›ng giáº£m, cho tháº¥y cÃ¡c trader Ä‘ang giáº£m dáº§n cÃ¡c vá»‹ tháº¿ náº¯m giá»¯ vÃ  cÃ³ thá»ƒ dá»‹ch chuyá»ƒn sang á»Ÿ thá»‹ trÆ°á»ng cÆ¡ sá»Ÿ khi trÃªn thá»‹ trÆ°á»ng cÆ¡ sá»Ÿ Ä‘ang cÃ³ nhiá»u cÆ¡ há»™i sinh lá»£i ngáº¯n háº¡n tá»‘t. Thá»‹ trÆ°á»ng Ä‘Ã£ há»“i phá»¥c 6 phiÃªn liÃªn tiáº¿p dÃ¹ Ä‘iá»ƒm sá»‘ tÄƒng tá»«ng phiÃªn khÃ´ng lá»›n nhÆ°ng Ä‘á»§ giÃºp thá»‹ trÆ°á»ng quay trá»Ÿ láº¡i kÃªnh tÄƒng giÃ¡ ngáº¯n háº¡n vÃ  náº±m trÃªn Ä‘Æ°á»ng MA20. total_ban_theo_ngay = value_data.total_ban_30[value_data['label'] == 'B'].to_frame() ngay_dau = total_ban_theo_ngay['total_ban_30'].iat[0] ngay_cuoi = total_ban_theo_ngay['total_ban_30'].iat[-1] phantramtangtruong = (ngay_cuoi - ngay_dau)/ngay_dau print(\"Tong so co phieu ban ra cua ngay cuoi giai doan so voi ngay dau co muc tang truong la: \",phantramtangtruong) # -- -0.637694475209741 total_ban_theo_ngay = value_data.total_mua_30[value_data['label'] == 'B'].to_frame() ngay_dau = total_ban_theo_ngay['total_mua_30'].iat[0] ngay_cuoi = total_ban_theo_ngay['total_mua_30'].iat[-1] phantramtangtruong = (ngay_cuoi - ngay_dau)/ngay_dau print(\"Tong so co phieu mua vao cua ngay cuoi giai doan so voi ngay dau co muc tang truong la: \",phantramtangtruong) # -- -0.8043500703402909 CÃ³ thá»ƒ tháº¥y, sá»‘ cá»• phiáº¿u Ä‘Æ°á»£c bÃ¡n ra á»Ÿ cuá»‘i giai Ä‘oáº¡n (Ä‘áº§u thÃ¡ng 4) so vá»›i thÃ¡ng 3 cÃ³ sá»± sá»¥t giáº£m. Cá»• phiáº¿u Ä‘Æ°á»£c mua vÃ o cÅ©ng tÄƒng trÆ°á»Ÿng Ã¢m, cÃ¡c nhÃ  Ä‘áº§u tÆ° buá»™c pháº£i giá»¯ láº¡i cÃ¡c cá»• phiáº¿u cÃ²n tá»“n Ä‘á»ng táº¡o nÃªn má»™t tháº¿ kÃ¬m hÃ£m thanh khoáº£n. Do Ä‘Ã³, trong tÆ°Æ¡ng lai gáº§n sáº½ chá»‹u tÃ¡c Ä‘á»™ng cá»§a sá»± chÃªnh lá»‡ch nÃ y. CÃ¡c sá»± kiá»‡n áº£nh hÆ°á»Ÿng NgÃ y 22-23/3/2023, láº§n thá»© 9 liÃªn tiáº¿p FED tÄƒng lÃ£i suáº¥t, nÃ¢ng phaÌ£m vi laÌƒi suÃ¢Ìt lÃªn mÆ°Ìc dao Ä‘Ã´Ì£ng tÆ°Ì€ 4,75% Ä‘ÃªÌn 5%. Má»¥c Ä‘Ã­ch Ä‘á»ƒ tráº¥n an thá»‹ trÆ°á»ng, giá»¯ uy tÃ­n vÃ  chá»‘ng láº¡m phÃ¡t. Trong bá»‘i cáº£nh thanh khoáº£n trÃªn thá»‹ trÆ°á»ng tÃ i chÃ­nh quá»‘c táº¿ tháº¯t cháº·t hÆ¡n, ChÃ­nh phá»§ vÃ  cÃ¡c doanh nghiá»‡p Viá»‡t Nam sáº½ khÃ³ huy Ä‘á»™ng vá»‘n trÃªn thá»‹ trÆ°á»ng quá»‘c táº¿ vÃ  pháº£i chá»‹u má»©c chi phÃ­ tÃ i chÃ­nh cao hÆ¡n. NgÃ y 31/3/2023, NgÃ¢n hÃ ng NhÃ  nÆ°á»›c Viá»‡t Nam Ä‘iá»u chá»‰nh giáº£m cÃ¡c má»©c lÃ£","date":"05 Sep 2023","objectID":"/stock_analysis_2/:2:2","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#cÃ¡c-sá»±-kiá»‡n-áº£nh-hÆ°á»Ÿng"},{"categories":["projects"],"content":"Cluster B import plotly.express as px gtb = [col for col in value_data.columns.to_list() if 'gttb_' in col] fig = px.line(value_data[gtb][value_data['label'] == 'B'], y=gtb, title='Mean Values by Label B') fig.update_layout(xaxis_title=\"Times\", yaxis_title=\"Mean Values\", font=dict(family=\"Courier New, monospace\", size=10, color=\"RebeccaPurple\")) fig.show() Mean Values by Label B import plotly.graph_objs as go # Create first trace trace1 = go.Bar(name='mua', x=value_data.index[value_data['label'] == 'B'], y=value_data['total_ban_30'][value_data['label'] == 'B']) # Create second trace trace2 = go.Bar(name='ban', x=value_data.index[value_data['label'] == 'B'], y=value_data['total_mua_30'][value_data['label'] == 'B']) # Create third trace trace3 = go.Scatter(name=\"GiaKL\",x=value_data.index[value_data['label'] == 'B'], y=value_data['Gia KL'][value_data['label'] == 'B'], mode='lines', yaxis='y2') # Create layout layout = go.Layout(title='The chart shows the correlation between Total Volumn and GiaKL', xaxis=dict(title='Times'), yaxis=dict(title='Total Volumn', side='left'), yaxis2=dict(title='Gia KL', side='right', overlaying='y'), barmode=\"stack\") # Add traces to figure fig = go.Figure(data=[trace1, trace2, trace3], layout=layout) # Show figure fig.show() B-Correlation between Total Volumn and GiaKL Biáº¿n Ä‘á»™ng thá»‹ trÆ°á»ng phantramtangtruong = (1081.55 - 1014.331)/1014.331 print(\"Gia tri cua phien cao nhat so voi phien nho nhat: \",phantramtangtruong) # -- 0.06626929473712223 Giai Ä‘oáº¡n nÃ y cho tháº¥y sá»± gia tÄƒng cá»§a giÃ¡ trá»‹ cÃ¡c cá»• phiáº¿u, vá»›i sá»©c tÄƒng lá»›n nháº¥t trong ngÆ°á»¡ng tiá»‡m cáº­n 0.07% cho tháº¥y sá»± háº¥p dáº«n cá»§a thá»‹ trÆ°á»ng Ä‘ang trÃªn Ä‘Ã  phá»¥c há»“i. VÃ o cuá»‘i thÃ¡ng 3, nhÃ³m dá»‹ch vá»¥ tÃ i chÃ­nh tiáº¿p tá»¥c tÄƒng Ä‘iá»ƒm khÃ¡ máº¡nh, nhÃ³m ngÃ¢n hÃ ng cÅ©ng cÃ³ diá»…n biáº¿n tÃ­ch cá»±c, nhÃ³m báº¥t Ä‘á»™ng sáº£n vá»›i thÃ´ng tin kháº£ nÄƒng tiáº¿p tá»¥c háº¡ lÃ£i suáº¥t gÃºp thanh khoáº£n cáº£i thiá»‡n tá»‘t, nhiá»u mÃ£ cÃ³ tÃ­n hiá»‡u thoÃ¡t khá»i xu hÆ°á»›ng giáº£m giÃ¡ trung háº¡n kÃ©o dÃ iâ€¦ Vá»›i cÃ¡c phiÃªn tÄƒng giáº£m Ä‘an xen, khá»‘i lÆ°á»£ng giao dá»‹ch vá» tá»•ng thá»ƒ trung háº¡n váº«n Ä‘ang á»Ÿ má»©c tháº¥p. Giai Ä‘oáº¡n cuá»‘i thÃ¡ng 3, khá»‘i lÆ°á»£ng giao dá»‹ch Ä‘ang trong xu hÆ°á»›ng giáº£m, cho tháº¥y cÃ¡c trader Ä‘ang giáº£m dáº§n cÃ¡c vá»‹ tháº¿ náº¯m giá»¯ vÃ  cÃ³ thá»ƒ dá»‹ch chuyá»ƒn sang á»Ÿ thá»‹ trÆ°á»ng cÆ¡ sá»Ÿ khi trÃªn thá»‹ trÆ°á»ng cÆ¡ sá»Ÿ Ä‘ang cÃ³ nhiá»u cÆ¡ há»™i sinh lá»£i ngáº¯n háº¡n tá»‘t. Thá»‹ trÆ°á»ng Ä‘Ã£ há»“i phá»¥c 6 phiÃªn liÃªn tiáº¿p dÃ¹ Ä‘iá»ƒm sá»‘ tÄƒng tá»«ng phiÃªn khÃ´ng lá»›n nhÆ°ng Ä‘á»§ giÃºp thá»‹ trÆ°á»ng quay trá»Ÿ láº¡i kÃªnh tÄƒng giÃ¡ ngáº¯n háº¡n vÃ  náº±m trÃªn Ä‘Æ°á»ng MA20. total_ban_theo_ngay = value_data.total_ban_30[value_data['label'] == 'B'].to_frame() ngay_dau = total_ban_theo_ngay['total_ban_30'].iat[0] ngay_cuoi = total_ban_theo_ngay['total_ban_30'].iat[-1] phantramtangtruong = (ngay_cuoi - ngay_dau)/ngay_dau print(\"Tong so co phieu ban ra cua ngay cuoi giai doan so voi ngay dau co muc tang truong la: \",phantramtangtruong) # -- -0.637694475209741 total_ban_theo_ngay = value_data.total_mua_30[value_data['label'] == 'B'].to_frame() ngay_dau = total_ban_theo_ngay['total_mua_30'].iat[0] ngay_cuoi = total_ban_theo_ngay['total_mua_30'].iat[-1] phantramtangtruong = (ngay_cuoi - ngay_dau)/ngay_dau print(\"Tong so co phieu mua vao cua ngay cuoi giai doan so voi ngay dau co muc tang truong la: \",phantramtangtruong) # -- -0.8043500703402909 CÃ³ thá»ƒ tháº¥y, sá»‘ cá»• phiáº¿u Ä‘Æ°á»£c bÃ¡n ra á»Ÿ cuá»‘i giai Ä‘oáº¡n (Ä‘áº§u thÃ¡ng 4) so vá»›i thÃ¡ng 3 cÃ³ sá»± sá»¥t giáº£m. Cá»• phiáº¿u Ä‘Æ°á»£c mua vÃ o cÅ©ng tÄƒng trÆ°á»Ÿng Ã¢m, cÃ¡c nhÃ  Ä‘áº§u tÆ° buá»™c pháº£i giá»¯ láº¡i cÃ¡c cá»• phiáº¿u cÃ²n tá»“n Ä‘á»ng táº¡o nÃªn má»™t tháº¿ kÃ¬m hÃ£m thanh khoáº£n. Do Ä‘Ã³, trong tÆ°Æ¡ng lai gáº§n sáº½ chá»‹u tÃ¡c Ä‘á»™ng cá»§a sá»± chÃªnh lá»‡ch nÃ y. CÃ¡c sá»± kiá»‡n áº£nh hÆ°á»Ÿng NgÃ y 22-23/3/2023, láº§n thá»© 9 liÃªn tiáº¿p FED tÄƒng lÃ£i suáº¥t, nÃ¢ng phaÌ£m vi laÌƒi suÃ¢Ìt lÃªn mÆ°Ìc dao Ä‘Ã´Ì£ng tÆ°Ì€ 4,75% Ä‘ÃªÌn 5%. Má»¥c Ä‘Ã­ch Ä‘á»ƒ tráº¥n an thá»‹ trÆ°á»ng, giá»¯ uy tÃ­n vÃ  chá»‘ng láº¡m phÃ¡t. Trong bá»‘i cáº£nh thanh khoáº£n trÃªn thá»‹ trÆ°á»ng tÃ i chÃ­nh quá»‘c táº¿ tháº¯t cháº·t hÆ¡n, ChÃ­nh phá»§ vÃ  cÃ¡c doanh nghiá»‡p Viá»‡t Nam sáº½ khÃ³ huy Ä‘á»™ng vá»‘n trÃªn thá»‹ trÆ°á»ng quá»‘c táº¿ vÃ  pháº£i chá»‹u má»©c chi phÃ­ tÃ i chÃ­nh cao hÆ¡n. NgÃ y 31/3/2023, NgÃ¢n hÃ ng NhÃ  nÆ°á»›c Viá»‡t Nam Ä‘iá»u chá»‰nh giáº£m cÃ¡c má»©c lÃ£","date":"05 Sep 2023","objectID":"/stock_analysis_2/:2:2","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#káº¿t-luáº­n-xu-hÆ°á»›ng"},{"categories":["projects"],"content":"Cluster AHÃ£y cÃ¹ng xem qua Cluster A nhÃ© import plotly.express as px gtb = [col for col in value_data.columns.to_list() if 'gttb_' in col] fig = px.line(value_data[gtb][value_data['label'] == 'A'], y=gtb, title='Mean Values by Label A') fig.update_layout(xaxis_title=\"Times\", yaxis_title=\"Mean Values\", font=dict(family=\"Courier New, monospace\", size=10, color=\"RebeccaPurple\")) fig.show() Mean Values by Label A A-Correlation between Total Volumn and GiaKL Biáº¿n Ä‘á»™ng thá»‹ trÆ°á»ng tb_SAB = value_data['gttb_SAB'].mean() print(\"Gia tri trung binh cua co phieu SAB\",tb_SAB) # --\u003e 179.1409610698177 Äá»‘i vá»›i giÃ¡ cá»• phiáº¿u trung bÃ¬nh: CÃ³ thá»ƒ tháº¥y giÃ¡ trung bÃ¬nh cá»§a cá»• phiáº¿u SAB (Tá»•ng CÃ´ng ty cá»• pháº§n Bia - RÆ°á»£u - NÆ°á»›c giáº£i khÃ¡t SÃ i GÃ²n SABECO) cÃ³ giao Ä‘á»™ng khÃ¡ á»•n Ä‘á»‹nh xung quanh giÃ¡ trá»‹ 165K. HÆ¡n ná»¯a giÃ¡ trung bÃ¬nh cá»§a SABECO trong thÃ¡ng 4/2023 lÃ  cao hÆ¡n háº³n so vá»›i cÃ¡c cá»• phiáº¿u khÃ¡c trong VN30, chá»©ng tá» thá»‹ pháº§n cá»§a cÃ´ng ty Ä‘Ã³ trong ngÃ nh cÃ³ thá»ƒ Ä‘ang tÄƒng lÃªn, vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ cao bá»Ÿi cÃ¡c nhÃ  Ä‘áº§u tÆ° vÃ¬ nÃ³ cÃ³ kháº£ nÄƒng tÄƒng trÆ°á»Ÿng máº¡nh trong tÆ°Æ¡ng lai. Tuy nhiÃªn tá»« Ä‘áº§u thÃ¡ng 4 vá» sau, Ä‘á»“ng hÃ nh cÃ¹ng vá»›i SAB lÃ  khoáº£ng 13 mÃ£ cá»• phiáº¿u khÃ¡c nhÆ° VJC, GAS, VCBâ€¦ Ä‘ang cÃ³ xu hÆ°á»›ng giáº£m giÃ¡ nháº¹. Má»™t sá»‘ mÃ£ cá»• phiáº¿u nhÆ° VCB cÃ³ sá»± giao Ä‘á»™ng khÃ¡ máº¡nh máº½ khi liÃªn tá»¥c xuá»‘ng ngÆ°á»¡ng 44K/1 cá»• phiáº¿u trong cÃ¡c ngÃ y 20, 21/03/2023. VÃ  tá»« Ä‘áº§u thÃ¡ng 4 lÃ  sá»± tuá»™t dá»‘c khÃ¡ nhanh khi tá»« khoáº£ng 93K xuá»‘ng cÃ²n táº§m 52K. NgoÃ i ra cÃ³ thá»ƒ tháº¥y ráº±ng cá»• phiáº¿u NVL cá»§a Táº­p Ä‘oÃ n Äáº§u tÆ° Äá»‹a á»‘c NOVA khÃ¡ â€œáº£m Ä‘áº¡mâ€ khi ngÆ°á»¡ng tháº¥p nháº¥t lÃ  vÃ o ngÃ y 03/04/2023 vá»›i 2.7K vÃ  cao nháº¥t lÃ  xáº¥p xá»‰ 11K. CÃ³ láº½ cá»• phiáº¿u NVL Ä‘ang ngÃ y cÃ ng â€œrá»›t giÃ¡â€, chÃ­nh vÃ¬ váº­y mÃ  cÃ¡c nhÃ  Ä‘áº§u tÆ° nÃªn bÃ¡n thÃ¡o, thá»‹ trÆ°á»ng chung cÅ©ng nháº­n Ä‘á»‹nh nÃªn BÃN máº¡nh. Äá»‘i vá»›i khá»‘i lÆ°á»£ng mua bÃ¡n cá»• phiáº¿u: Tá»« biá»ƒu Ä‘á»“ trÃªn, nhÃ¬n sÆ¡ lÆ°á»£c qua thÃ¬ ta cÃ³ thá»ƒ tháº¥y Ä‘Æ°á»£c khá»‘i lÆ°á»£ng giao dá»‹ch cÃ³ xu hÆ°Æ¡ng tÄƒng dáº§n tá»« ngÃ y 1/4, cháº¡m má»‘c cao nháº¥t vÃ o ngÃ y 6/4. Trong khoáº£ng thá»i gian nÃ y, khá»‘i lÆ°á»£ng giao dá»‹ch mua nhiá»u, Ä‘iá»u nÃ y chá»©ng tá» thá»‹ trÆ°á»ng Ä‘ang ráº¥t quan tÃ¢m vÃ  ká»³ vá»ng vÃ o sá»± tÄƒng giÃ¡ cá»§a cÃ¡c cá»• phiáº¿u. GiÃ¡ phÃ¡i sinh vÃ  khá»‘i lÆ°á»£ng giao dá»‹ch cÃ³ má»™t sá»± tÆ°Æ¡ng quan vá»›i nhau, viá»‡c khá»‘i lÆ°á»£ng giao dá»‹ch mua tÄƒng lÃªn, giÃ¡ phÃ¡i sinh trong khoáº£ng thá»i gian nÃ y cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº©y lÃªn. Sau sá»± gia tÄƒng giÃ¡ Ä‘áº¿n má»™t má»©c cao nháº¥t lÃ  vÃ o ngÃ y 6/4, thÃ¬ sau Ä‘Ã³ giÃ¡ phÃ¡i sinh láº¡i khÃ¡ áº£m Ä‘áº¡m. Sau ngÃ y 17/4 thÃ¬ báº¯t Ä‘áº§u cÃ³ dáº¥u hiá»‡u giáº£m máº¡nh vÃ  tháº¥p nháº¥t vÃ o ngÃ y 19/4. Trong khoáº£ng thá»i gian nÃ y, khá»‘i lÆ°á»£ng giao dá»‹ch cÅ©ng giáº£m dáº§n, khá»‘i lÆ°á»£ng giao dá»‹ch bÃ¡n tÄƒng nhiá»u hÆ¡n so vá»›i kÃ¬ trÆ°á»›c. Má»©c giáº£m nÃ y nháº­n Ä‘á»‹nh lÃ  khÃ¡ máº¡nh, trong khi khá»‘i lÆ°á»£ng giao dá»‹ch mua láº¡i khÃ´ng nhiá»u. Thá»‹ trÆ°á»ng khÃ´ng cÃ³ nhiá»u Ä‘iá»ƒm nháº¥n trong bá»‘i cáº£nh phá»¥c há»“i thanh khoÃ¡n tháº¥p. total_ban_theo_ngay = value_data.total_ban_30[value_data['label'] == 'A'].to_frame() ngay_dau = total_ban_theo_ngay['total_ban_30'].iat[0] ngay_cuoi = total_ban_theo_ngay['total_ban_30'].iat[-1] phantramtangtruong = (ngay_cuoi - ngay_dau)/ngay_dau print(\"Tong so co phieu ban ra cua ngay cuoi giai doan so voi ngay dau co muc tang truong la: \",phantramtangtruong) # --\u003e -0.7704310701624562 Vá» biáº¿n Ä‘á»™ng giÃ¡ phÃ¡i sinh: VN30Index phiÃªn má»Ÿ Ä‘áº§u thÃ¡ng 4 giao dá»‹ch tÄƒng Ä‘iá»ƒm tÃ­ch cá»±c vÃ  duy trÃ¬ Ä‘Ã  tÄƒng Ä‘áº¿n cuá»‘i phiÃªn. Sá»‘ liá»‡u cuá»‘i cÃ¹ng ghi nháº­n Ä‘Æ°á»£c vÃ o ngÃ y 03/04/2023 lÃ  1.081,28 Ä‘iá»ƒm (+1.38% so vá»›i 1.070,14 vÃ o 31/03/2023) Ä‘á»ƒ hÆ°á»›ng Ä‘áº¿n 1.085-1.095 Ä‘iá»ƒm. Tuy nhiÃªn, vÃ o tuáº§n thá»© 2 tá»« 14/04/2023 VN30Index biáº¿n Ä‘á»™ng tiÃªu cá»±c hÆ¡n. PhiÃªn Ä‘áº§u tuáº§n, má»Ÿ cá»­a á»Ÿ vÃ¹ng giÃ¡ 1.073 Ä‘iá»ƒm vÃ  chá»‹u Ã¡p lá»±c Ä‘iá»u chá»‰nh á»Ÿ vÃ¹ng giÃ¡ 1.070-1.075 Ä‘iá»ƒm Ä‘á»ƒ káº¿t thÃºc tuáº§n giao dá»‹ch vá»›i phiÃªn giáº£m Ä‘iá»ƒm máº¡nh. Tuáº§n Ä‘iá»u chá»‰nh Ä‘Ã£ diá»…n ra nhÆ° dá»± Ä‘oÃ¡n khi trong tuáº§n qua Vn30Index giáº£m 16.82 Ä‘iá»ƒm (-1,57%) vá»›i khá»‘i lÆ°á»£ng giao dá»‹ch tiáº¿p tá»¥c á»Ÿ má»©c cao, Ä‘iá»ƒm sá»‘ Ä‘iá»u chá»‰nh tuy khÃ´ng lá»›n nhÆ°ng trong bá»‘i cáº£nh thá»‹ trÆ°á»ng Ä‘ang trong khu vá»±c giao Ä‘á»™ng háº¹p thÃ¬ Ä‘á»£t Ä‘iá»u chá»‰nh nÃ y cÅ©ng táº¡o ra cáº£m giÃ¡c báº¥t an cho nhÃ  Ä‘áº§u tÆ°. Äáº¿n ngÃ y 19/04/2023. Ná»— lá»±c phá»¥c há»“i tá»« 2 phiÃªn Ä‘áº§u tuáº§n Ä‘Ã£ khÃ´ng Ä‘Æ°á»£c tiáº¿p tá»¥c duy trÃ¬ trong phiÃªn nÃ y khi Thá»i Ä‘iá»ƒm cuá»‘i cÃ¹ng lÃ  xáº¥p xá»‰ 1.055 Ä‘iá»ƒm. ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:2:3","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#cluster-a"},{"categories":["projects"],"content":"Cluster AHÃ£y cÃ¹ng xem qua Cluster A nhÃ© import plotly.express as px gtb = [col for col in value_data.columns.to_list() if 'gttb_' in col] fig = px.line(value_data[gtb][value_data['label'] == 'A'], y=gtb, title='Mean Values by Label A') fig.update_layout(xaxis_title=\"Times\", yaxis_title=\"Mean Values\", font=dict(family=\"Courier New, monospace\", size=10, color=\"RebeccaPurple\")) fig.show() Mean Values by Label A A-Correlation between Total Volumn and GiaKL Biáº¿n Ä‘á»™ng thá»‹ trÆ°á»ng tb_SAB = value_data['gttb_SAB'].mean() print(\"Gia tri trung binh cua co phieu SAB\",tb_SAB) # -- 179.1409610698177 Äá»‘i vá»›i giÃ¡ cá»• phiáº¿u trung bÃ¬nh: CÃ³ thá»ƒ tháº¥y giÃ¡ trung bÃ¬nh cá»§a cá»• phiáº¿u SAB (Tá»•ng CÃ´ng ty cá»• pháº§n Bia - RÆ°á»£u - NÆ°á»›c giáº£i khÃ¡t SÃ i GÃ²n SABECO) cÃ³ giao Ä‘á»™ng khÃ¡ á»•n Ä‘á»‹nh xung quanh giÃ¡ trá»‹ 165K. HÆ¡n ná»¯a giÃ¡ trung bÃ¬nh cá»§a SABECO trong thÃ¡ng 4/2023 lÃ  cao hÆ¡n háº³n so vá»›i cÃ¡c cá»• phiáº¿u khÃ¡c trong VN30, chá»©ng tá» thá»‹ pháº§n cá»§a cÃ´ng ty Ä‘Ã³ trong ngÃ nh cÃ³ thá»ƒ Ä‘ang tÄƒng lÃªn, vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ cao bá»Ÿi cÃ¡c nhÃ  Ä‘áº§u tÆ° vÃ¬ nÃ³ cÃ³ kháº£ nÄƒng tÄƒng trÆ°á»Ÿng máº¡nh trong tÆ°Æ¡ng lai. Tuy nhiÃªn tá»« Ä‘áº§u thÃ¡ng 4 vá» sau, Ä‘á»“ng hÃ nh cÃ¹ng vá»›i SAB lÃ  khoáº£ng 13 mÃ£ cá»• phiáº¿u khÃ¡c nhÆ° VJC, GAS, VCBâ€¦ Ä‘ang cÃ³ xu hÆ°á»›ng giáº£m giÃ¡ nháº¹. Má»™t sá»‘ mÃ£ cá»• phiáº¿u nhÆ° VCB cÃ³ sá»± giao Ä‘á»™ng khÃ¡ máº¡nh máº½ khi liÃªn tá»¥c xuá»‘ng ngÆ°á»¡ng 44K/1 cá»• phiáº¿u trong cÃ¡c ngÃ y 20, 21/03/2023. VÃ  tá»« Ä‘áº§u thÃ¡ng 4 lÃ  sá»± tuá»™t dá»‘c khÃ¡ nhanh khi tá»« khoáº£ng 93K xuá»‘ng cÃ²n táº§m 52K. NgoÃ i ra cÃ³ thá»ƒ tháº¥y ráº±ng cá»• phiáº¿u NVL cá»§a Táº­p Ä‘oÃ n Äáº§u tÆ° Äá»‹a á»‘c NOVA khÃ¡ â€œáº£m Ä‘áº¡mâ€ khi ngÆ°á»¡ng tháº¥p nháº¥t lÃ  vÃ o ngÃ y 03/04/2023 vá»›i 2.7K vÃ  cao nháº¥t lÃ  xáº¥p xá»‰ 11K. CÃ³ láº½ cá»• phiáº¿u NVL Ä‘ang ngÃ y cÃ ng â€œrá»›t giÃ¡â€, chÃ­nh vÃ¬ váº­y mÃ  cÃ¡c nhÃ  Ä‘áº§u tÆ° nÃªn bÃ¡n thÃ¡o, thá»‹ trÆ°á»ng chung cÅ©ng nháº­n Ä‘á»‹nh nÃªn BÃN máº¡nh. Äá»‘i vá»›i khá»‘i lÆ°á»£ng mua bÃ¡n cá»• phiáº¿u: Tá»« biá»ƒu Ä‘á»“ trÃªn, nhÃ¬n sÆ¡ lÆ°á»£c qua thÃ¬ ta cÃ³ thá»ƒ tháº¥y Ä‘Æ°á»£c khá»‘i lÆ°á»£ng giao dá»‹ch cÃ³ xu hÆ°Æ¡ng tÄƒng dáº§n tá»« ngÃ y 1/4, cháº¡m má»‘c cao nháº¥t vÃ o ngÃ y 6/4. Trong khoáº£ng thá»i gian nÃ y, khá»‘i lÆ°á»£ng giao dá»‹ch mua nhiá»u, Ä‘iá»u nÃ y chá»©ng tá» thá»‹ trÆ°á»ng Ä‘ang ráº¥t quan tÃ¢m vÃ  ká»³ vá»ng vÃ o sá»± tÄƒng giÃ¡ cá»§a cÃ¡c cá»• phiáº¿u. GiÃ¡ phÃ¡i sinh vÃ  khá»‘i lÆ°á»£ng giao dá»‹ch cÃ³ má»™t sá»± tÆ°Æ¡ng quan vá»›i nhau, viá»‡c khá»‘i lÆ°á»£ng giao dá»‹ch mua tÄƒng lÃªn, giÃ¡ phÃ¡i sinh trong khoáº£ng thá»i gian nÃ y cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº©y lÃªn. Sau sá»± gia tÄƒng giÃ¡ Ä‘áº¿n má»™t má»©c cao nháº¥t lÃ  vÃ o ngÃ y 6/4, thÃ¬ sau Ä‘Ã³ giÃ¡ phÃ¡i sinh láº¡i khÃ¡ áº£m Ä‘áº¡m. Sau ngÃ y 17/4 thÃ¬ báº¯t Ä‘áº§u cÃ³ dáº¥u hiá»‡u giáº£m máº¡nh vÃ  tháº¥p nháº¥t vÃ o ngÃ y 19/4. Trong khoáº£ng thá»i gian nÃ y, khá»‘i lÆ°á»£ng giao dá»‹ch cÅ©ng giáº£m dáº§n, khá»‘i lÆ°á»£ng giao dá»‹ch bÃ¡n tÄƒng nhiá»u hÆ¡n so vá»›i kÃ¬ trÆ°á»›c. Má»©c giáº£m nÃ y nháº­n Ä‘á»‹nh lÃ  khÃ¡ máº¡nh, trong khi khá»‘i lÆ°á»£ng giao dá»‹ch mua láº¡i khÃ´ng nhiá»u. Thá»‹ trÆ°á»ng khÃ´ng cÃ³ nhiá»u Ä‘iá»ƒm nháº¥n trong bá»‘i cáº£nh phá»¥c há»“i thanh khoÃ¡n tháº¥p. total_ban_theo_ngay = value_data.total_ban_30[value_data['label'] == 'A'].to_frame() ngay_dau = total_ban_theo_ngay['total_ban_30'].iat[0] ngay_cuoi = total_ban_theo_ngay['total_ban_30'].iat[-1] phantramtangtruong = (ngay_cuoi - ngay_dau)/ngay_dau print(\"Tong so co phieu ban ra cua ngay cuoi giai doan so voi ngay dau co muc tang truong la: \",phantramtangtruong) # -- -0.7704310701624562 Vá» biáº¿n Ä‘á»™ng giÃ¡ phÃ¡i sinh: VN30Index phiÃªn má»Ÿ Ä‘áº§u thÃ¡ng 4 giao dá»‹ch tÄƒng Ä‘iá»ƒm tÃ­ch cá»±c vÃ  duy trÃ¬ Ä‘Ã  tÄƒng Ä‘áº¿n cuá»‘i phiÃªn. Sá»‘ liá»‡u cuá»‘i cÃ¹ng ghi nháº­n Ä‘Æ°á»£c vÃ o ngÃ y 03/04/2023 lÃ  1.081,28 Ä‘iá»ƒm (+1.38% so vá»›i 1.070,14 vÃ o 31/03/2023) Ä‘á»ƒ hÆ°á»›ng Ä‘áº¿n 1.085-1.095 Ä‘iá»ƒm. Tuy nhiÃªn, vÃ o tuáº§n thá»© 2 tá»« 14/04/2023 VN30Index biáº¿n Ä‘á»™ng tiÃªu cá»±c hÆ¡n. PhiÃªn Ä‘áº§u tuáº§n, má»Ÿ cá»­a á»Ÿ vÃ¹ng giÃ¡ 1.073 Ä‘iá»ƒm vÃ  chá»‹u Ã¡p lá»±c Ä‘iá»u chá»‰nh á»Ÿ vÃ¹ng giÃ¡ 1.070-1.075 Ä‘iá»ƒm Ä‘á»ƒ káº¿t thÃºc tuáº§n giao dá»‹ch vá»›i phiÃªn giáº£m Ä‘iá»ƒm máº¡nh. Tuáº§n Ä‘iá»u chá»‰nh Ä‘Ã£ diá»…n ra nhÆ° dá»± Ä‘oÃ¡n khi trong tuáº§n qua Vn30Index giáº£m 16.82 Ä‘iá»ƒm (-1,57%) vá»›i khá»‘i lÆ°á»£ng giao dá»‹ch tiáº¿p tá»¥c á»Ÿ má»©c cao, Ä‘iá»ƒm sá»‘ Ä‘iá»u chá»‰nh tuy khÃ´ng lá»›n nhÆ°ng trong bá»‘i cáº£nh thá»‹ trÆ°á»ng Ä‘ang trong khu vá»±c giao Ä‘á»™ng háº¹p thÃ¬ Ä‘á»£t Ä‘iá»u chá»‰nh nÃ y cÅ©ng táº¡o ra cáº£m giÃ¡c báº¥t an cho nhÃ  Ä‘áº§u tÆ°. Äáº¿n ngÃ y 19/04/2023. Ná»— lá»±c phá»¥c há»“i tá»« 2 phiÃªn Ä‘áº§u tuáº§n Ä‘Ã£ khÃ´ng Ä‘Æ°á»£c tiáº¿p tá»¥c duy trÃ¬ trong phiÃªn nÃ y khi Thá»i Ä‘iá»ƒm cuá»‘i cÃ¹ng lÃ  xáº¥p xá»‰ 1.055 Ä‘iá»ƒm. ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:2:3","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#biáº¿n-Ä‘á»™ng-thá»‹-trÆ°á»ng-1"},{"categories":["projects"],"content":"Cluster AHÃ£y cÃ¹ng xem qua Cluster A nhÃ© import plotly.express as px gtb = [col for col in value_data.columns.to_list() if 'gttb_' in col] fig = px.line(value_data[gtb][value_data['label'] == 'A'], y=gtb, title='Mean Values by Label A') fig.update_layout(xaxis_title=\"Times\", yaxis_title=\"Mean Values\", font=dict(family=\"Courier New, monospace\", size=10, color=\"RebeccaPurple\")) fig.show() Mean Values by Label A A-Correlation between Total Volumn and GiaKL Biáº¿n Ä‘á»™ng thá»‹ trÆ°á»ng tb_SAB = value_data['gttb_SAB'].mean() print(\"Gia tri trung binh cua co phieu SAB\",tb_SAB) # -- 179.1409610698177 Äá»‘i vá»›i giÃ¡ cá»• phiáº¿u trung bÃ¬nh: CÃ³ thá»ƒ tháº¥y giÃ¡ trung bÃ¬nh cá»§a cá»• phiáº¿u SAB (Tá»•ng CÃ´ng ty cá»• pháº§n Bia - RÆ°á»£u - NÆ°á»›c giáº£i khÃ¡t SÃ i GÃ²n SABECO) cÃ³ giao Ä‘á»™ng khÃ¡ á»•n Ä‘á»‹nh xung quanh giÃ¡ trá»‹ 165K. HÆ¡n ná»¯a giÃ¡ trung bÃ¬nh cá»§a SABECO trong thÃ¡ng 4/2023 lÃ  cao hÆ¡n háº³n so vá»›i cÃ¡c cá»• phiáº¿u khÃ¡c trong VN30, chá»©ng tá» thá»‹ pháº§n cá»§a cÃ´ng ty Ä‘Ã³ trong ngÃ nh cÃ³ thá»ƒ Ä‘ang tÄƒng lÃªn, vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ cao bá»Ÿi cÃ¡c nhÃ  Ä‘áº§u tÆ° vÃ¬ nÃ³ cÃ³ kháº£ nÄƒng tÄƒng trÆ°á»Ÿng máº¡nh trong tÆ°Æ¡ng lai. Tuy nhiÃªn tá»« Ä‘áº§u thÃ¡ng 4 vá» sau, Ä‘á»“ng hÃ nh cÃ¹ng vá»›i SAB lÃ  khoáº£ng 13 mÃ£ cá»• phiáº¿u khÃ¡c nhÆ° VJC, GAS, VCBâ€¦ Ä‘ang cÃ³ xu hÆ°á»›ng giáº£m giÃ¡ nháº¹. Má»™t sá»‘ mÃ£ cá»• phiáº¿u nhÆ° VCB cÃ³ sá»± giao Ä‘á»™ng khÃ¡ máº¡nh máº½ khi liÃªn tá»¥c xuá»‘ng ngÆ°á»¡ng 44K/1 cá»• phiáº¿u trong cÃ¡c ngÃ y 20, 21/03/2023. VÃ  tá»« Ä‘áº§u thÃ¡ng 4 lÃ  sá»± tuá»™t dá»‘c khÃ¡ nhanh khi tá»« khoáº£ng 93K xuá»‘ng cÃ²n táº§m 52K. NgoÃ i ra cÃ³ thá»ƒ tháº¥y ráº±ng cá»• phiáº¿u NVL cá»§a Táº­p Ä‘oÃ n Äáº§u tÆ° Äá»‹a á»‘c NOVA khÃ¡ â€œáº£m Ä‘áº¡mâ€ khi ngÆ°á»¡ng tháº¥p nháº¥t lÃ  vÃ o ngÃ y 03/04/2023 vá»›i 2.7K vÃ  cao nháº¥t lÃ  xáº¥p xá»‰ 11K. CÃ³ láº½ cá»• phiáº¿u NVL Ä‘ang ngÃ y cÃ ng â€œrá»›t giÃ¡â€, chÃ­nh vÃ¬ váº­y mÃ  cÃ¡c nhÃ  Ä‘áº§u tÆ° nÃªn bÃ¡n thÃ¡o, thá»‹ trÆ°á»ng chung cÅ©ng nháº­n Ä‘á»‹nh nÃªn BÃN máº¡nh. Äá»‘i vá»›i khá»‘i lÆ°á»£ng mua bÃ¡n cá»• phiáº¿u: Tá»« biá»ƒu Ä‘á»“ trÃªn, nhÃ¬n sÆ¡ lÆ°á»£c qua thÃ¬ ta cÃ³ thá»ƒ tháº¥y Ä‘Æ°á»£c khá»‘i lÆ°á»£ng giao dá»‹ch cÃ³ xu hÆ°Æ¡ng tÄƒng dáº§n tá»« ngÃ y 1/4, cháº¡m má»‘c cao nháº¥t vÃ o ngÃ y 6/4. Trong khoáº£ng thá»i gian nÃ y, khá»‘i lÆ°á»£ng giao dá»‹ch mua nhiá»u, Ä‘iá»u nÃ y chá»©ng tá» thá»‹ trÆ°á»ng Ä‘ang ráº¥t quan tÃ¢m vÃ  ká»³ vá»ng vÃ o sá»± tÄƒng giÃ¡ cá»§a cÃ¡c cá»• phiáº¿u. GiÃ¡ phÃ¡i sinh vÃ  khá»‘i lÆ°á»£ng giao dá»‹ch cÃ³ má»™t sá»± tÆ°Æ¡ng quan vá»›i nhau, viá»‡c khá»‘i lÆ°á»£ng giao dá»‹ch mua tÄƒng lÃªn, giÃ¡ phÃ¡i sinh trong khoáº£ng thá»i gian nÃ y cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº©y lÃªn. Sau sá»± gia tÄƒng giÃ¡ Ä‘áº¿n má»™t má»©c cao nháº¥t lÃ  vÃ o ngÃ y 6/4, thÃ¬ sau Ä‘Ã³ giÃ¡ phÃ¡i sinh láº¡i khÃ¡ áº£m Ä‘áº¡m. Sau ngÃ y 17/4 thÃ¬ báº¯t Ä‘áº§u cÃ³ dáº¥u hiá»‡u giáº£m máº¡nh vÃ  tháº¥p nháº¥t vÃ o ngÃ y 19/4. Trong khoáº£ng thá»i gian nÃ y, khá»‘i lÆ°á»£ng giao dá»‹ch cÅ©ng giáº£m dáº§n, khá»‘i lÆ°á»£ng giao dá»‹ch bÃ¡n tÄƒng nhiá»u hÆ¡n so vá»›i kÃ¬ trÆ°á»›c. Má»©c giáº£m nÃ y nháº­n Ä‘á»‹nh lÃ  khÃ¡ máº¡nh, trong khi khá»‘i lÆ°á»£ng giao dá»‹ch mua láº¡i khÃ´ng nhiá»u. Thá»‹ trÆ°á»ng khÃ´ng cÃ³ nhiá»u Ä‘iá»ƒm nháº¥n trong bá»‘i cáº£nh phá»¥c há»“i thanh khoÃ¡n tháº¥p. total_ban_theo_ngay = value_data.total_ban_30[value_data['label'] == 'A'].to_frame() ngay_dau = total_ban_theo_ngay['total_ban_30'].iat[0] ngay_cuoi = total_ban_theo_ngay['total_ban_30'].iat[-1] phantramtangtruong = (ngay_cuoi - ngay_dau)/ngay_dau print(\"Tong so co phieu ban ra cua ngay cuoi giai doan so voi ngay dau co muc tang truong la: \",phantramtangtruong) # -- -0.7704310701624562 Vá» biáº¿n Ä‘á»™ng giÃ¡ phÃ¡i sinh: VN30Index phiÃªn má»Ÿ Ä‘áº§u thÃ¡ng 4 giao dá»‹ch tÄƒng Ä‘iá»ƒm tÃ­ch cá»±c vÃ  duy trÃ¬ Ä‘Ã  tÄƒng Ä‘áº¿n cuá»‘i phiÃªn. Sá»‘ liá»‡u cuá»‘i cÃ¹ng ghi nháº­n Ä‘Æ°á»£c vÃ o ngÃ y 03/04/2023 lÃ  1.081,28 Ä‘iá»ƒm (+1.38% so vá»›i 1.070,14 vÃ o 31/03/2023) Ä‘á»ƒ hÆ°á»›ng Ä‘áº¿n 1.085-1.095 Ä‘iá»ƒm. Tuy nhiÃªn, vÃ o tuáº§n thá»© 2 tá»« 14/04/2023 VN30Index biáº¿n Ä‘á»™ng tiÃªu cá»±c hÆ¡n. PhiÃªn Ä‘áº§u tuáº§n, má»Ÿ cá»­a á»Ÿ vÃ¹ng giÃ¡ 1.073 Ä‘iá»ƒm vÃ  chá»‹u Ã¡p lá»±c Ä‘iá»u chá»‰nh á»Ÿ vÃ¹ng giÃ¡ 1.070-1.075 Ä‘iá»ƒm Ä‘á»ƒ káº¿t thÃºc tuáº§n giao dá»‹ch vá»›i phiÃªn giáº£m Ä‘iá»ƒm máº¡nh. Tuáº§n Ä‘iá»u chá»‰nh Ä‘Ã£ diá»…n ra nhÆ° dá»± Ä‘oÃ¡n khi trong tuáº§n qua Vn30Index giáº£m 16.82 Ä‘iá»ƒm (-1,57%) vá»›i khá»‘i lÆ°á»£ng giao dá»‹ch tiáº¿p tá»¥c á»Ÿ má»©c cao, Ä‘iá»ƒm sá»‘ Ä‘iá»u chá»‰nh tuy khÃ´ng lá»›n nhÆ°ng trong bá»‘i cáº£nh thá»‹ trÆ°á»ng Ä‘ang trong khu vá»±c giao Ä‘á»™ng háº¹p thÃ¬ Ä‘á»£t Ä‘iá»u chá»‰nh nÃ y cÅ©ng táº¡o ra cáº£m giÃ¡c báº¥t an cho nhÃ  Ä‘áº§u tÆ°. Äáº¿n ngÃ y 19/04/2023. Ná»— lá»±c phá»¥c há»“i tá»« 2 phiÃªn Ä‘áº§u tuáº§n Ä‘Ã£ khÃ´ng Ä‘Æ°á»£c tiáº¿p tá»¥c duy trÃ¬ trong phiÃªn nÃ y khi Thá»i Ä‘iá»ƒm cuá»‘i cÃ¹ng lÃ  xáº¥p xá»‰ 1.055 Ä‘iá»ƒm. ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:2:3","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#sá»±-kiá»‡n-áº£nh-hÆ°á»Ÿng"},{"categories":["projects"],"content":"Cluster AHÃ£y cÃ¹ng xem qua Cluster A nhÃ© import plotly.express as px gtb = [col for col in value_data.columns.to_list() if 'gttb_' in col] fig = px.line(value_data[gtb][value_data['label'] == 'A'], y=gtb, title='Mean Values by Label A') fig.update_layout(xaxis_title=\"Times\", yaxis_title=\"Mean Values\", font=dict(family=\"Courier New, monospace\", size=10, color=\"RebeccaPurple\")) fig.show() Mean Values by Label A A-Correlation between Total Volumn and GiaKL Biáº¿n Ä‘á»™ng thá»‹ trÆ°á»ng tb_SAB = value_data['gttb_SAB'].mean() print(\"Gia tri trung binh cua co phieu SAB\",tb_SAB) # -- 179.1409610698177 Äá»‘i vá»›i giÃ¡ cá»• phiáº¿u trung bÃ¬nh: CÃ³ thá»ƒ tháº¥y giÃ¡ trung bÃ¬nh cá»§a cá»• phiáº¿u SAB (Tá»•ng CÃ´ng ty cá»• pháº§n Bia - RÆ°á»£u - NÆ°á»›c giáº£i khÃ¡t SÃ i GÃ²n SABECO) cÃ³ giao Ä‘á»™ng khÃ¡ á»•n Ä‘á»‹nh xung quanh giÃ¡ trá»‹ 165K. HÆ¡n ná»¯a giÃ¡ trung bÃ¬nh cá»§a SABECO trong thÃ¡ng 4/2023 lÃ  cao hÆ¡n háº³n so vá»›i cÃ¡c cá»• phiáº¿u khÃ¡c trong VN30, chá»©ng tá» thá»‹ pháº§n cá»§a cÃ´ng ty Ä‘Ã³ trong ngÃ nh cÃ³ thá»ƒ Ä‘ang tÄƒng lÃªn, vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ cao bá»Ÿi cÃ¡c nhÃ  Ä‘áº§u tÆ° vÃ¬ nÃ³ cÃ³ kháº£ nÄƒng tÄƒng trÆ°á»Ÿng máº¡nh trong tÆ°Æ¡ng lai. Tuy nhiÃªn tá»« Ä‘áº§u thÃ¡ng 4 vá» sau, Ä‘á»“ng hÃ nh cÃ¹ng vá»›i SAB lÃ  khoáº£ng 13 mÃ£ cá»• phiáº¿u khÃ¡c nhÆ° VJC, GAS, VCBâ€¦ Ä‘ang cÃ³ xu hÆ°á»›ng giáº£m giÃ¡ nháº¹. Má»™t sá»‘ mÃ£ cá»• phiáº¿u nhÆ° VCB cÃ³ sá»± giao Ä‘á»™ng khÃ¡ máº¡nh máº½ khi liÃªn tá»¥c xuá»‘ng ngÆ°á»¡ng 44K/1 cá»• phiáº¿u trong cÃ¡c ngÃ y 20, 21/03/2023. VÃ  tá»« Ä‘áº§u thÃ¡ng 4 lÃ  sá»± tuá»™t dá»‘c khÃ¡ nhanh khi tá»« khoáº£ng 93K xuá»‘ng cÃ²n táº§m 52K. NgoÃ i ra cÃ³ thá»ƒ tháº¥y ráº±ng cá»• phiáº¿u NVL cá»§a Táº­p Ä‘oÃ n Äáº§u tÆ° Äá»‹a á»‘c NOVA khÃ¡ â€œáº£m Ä‘áº¡mâ€ khi ngÆ°á»¡ng tháº¥p nháº¥t lÃ  vÃ o ngÃ y 03/04/2023 vá»›i 2.7K vÃ  cao nháº¥t lÃ  xáº¥p xá»‰ 11K. CÃ³ láº½ cá»• phiáº¿u NVL Ä‘ang ngÃ y cÃ ng â€œrá»›t giÃ¡â€, chÃ­nh vÃ¬ váº­y mÃ  cÃ¡c nhÃ  Ä‘áº§u tÆ° nÃªn bÃ¡n thÃ¡o, thá»‹ trÆ°á»ng chung cÅ©ng nháº­n Ä‘á»‹nh nÃªn BÃN máº¡nh. Äá»‘i vá»›i khá»‘i lÆ°á»£ng mua bÃ¡n cá»• phiáº¿u: Tá»« biá»ƒu Ä‘á»“ trÃªn, nhÃ¬n sÆ¡ lÆ°á»£c qua thÃ¬ ta cÃ³ thá»ƒ tháº¥y Ä‘Æ°á»£c khá»‘i lÆ°á»£ng giao dá»‹ch cÃ³ xu hÆ°Æ¡ng tÄƒng dáº§n tá»« ngÃ y 1/4, cháº¡m má»‘c cao nháº¥t vÃ o ngÃ y 6/4. Trong khoáº£ng thá»i gian nÃ y, khá»‘i lÆ°á»£ng giao dá»‹ch mua nhiá»u, Ä‘iá»u nÃ y chá»©ng tá» thá»‹ trÆ°á»ng Ä‘ang ráº¥t quan tÃ¢m vÃ  ká»³ vá»ng vÃ o sá»± tÄƒng giÃ¡ cá»§a cÃ¡c cá»• phiáº¿u. GiÃ¡ phÃ¡i sinh vÃ  khá»‘i lÆ°á»£ng giao dá»‹ch cÃ³ má»™t sá»± tÆ°Æ¡ng quan vá»›i nhau, viá»‡c khá»‘i lÆ°á»£ng giao dá»‹ch mua tÄƒng lÃªn, giÃ¡ phÃ¡i sinh trong khoáº£ng thá»i gian nÃ y cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº©y lÃªn. Sau sá»± gia tÄƒng giÃ¡ Ä‘áº¿n má»™t má»©c cao nháº¥t lÃ  vÃ o ngÃ y 6/4, thÃ¬ sau Ä‘Ã³ giÃ¡ phÃ¡i sinh láº¡i khÃ¡ áº£m Ä‘áº¡m. Sau ngÃ y 17/4 thÃ¬ báº¯t Ä‘áº§u cÃ³ dáº¥u hiá»‡u giáº£m máº¡nh vÃ  tháº¥p nháº¥t vÃ o ngÃ y 19/4. Trong khoáº£ng thá»i gian nÃ y, khá»‘i lÆ°á»£ng giao dá»‹ch cÅ©ng giáº£m dáº§n, khá»‘i lÆ°á»£ng giao dá»‹ch bÃ¡n tÄƒng nhiá»u hÆ¡n so vá»›i kÃ¬ trÆ°á»›c. Má»©c giáº£m nÃ y nháº­n Ä‘á»‹nh lÃ  khÃ¡ máº¡nh, trong khi khá»‘i lÆ°á»£ng giao dá»‹ch mua láº¡i khÃ´ng nhiá»u. Thá»‹ trÆ°á»ng khÃ´ng cÃ³ nhiá»u Ä‘iá»ƒm nháº¥n trong bá»‘i cáº£nh phá»¥c há»“i thanh khoÃ¡n tháº¥p. total_ban_theo_ngay = value_data.total_ban_30[value_data['label'] == 'A'].to_frame() ngay_dau = total_ban_theo_ngay['total_ban_30'].iat[0] ngay_cuoi = total_ban_theo_ngay['total_ban_30'].iat[-1] phantramtangtruong = (ngay_cuoi - ngay_dau)/ngay_dau print(\"Tong so co phieu ban ra cua ngay cuoi giai doan so voi ngay dau co muc tang truong la: \",phantramtangtruong) # -- -0.7704310701624562 Vá» biáº¿n Ä‘á»™ng giÃ¡ phÃ¡i sinh: VN30Index phiÃªn má»Ÿ Ä‘áº§u thÃ¡ng 4 giao dá»‹ch tÄƒng Ä‘iá»ƒm tÃ­ch cá»±c vÃ  duy trÃ¬ Ä‘Ã  tÄƒng Ä‘áº¿n cuá»‘i phiÃªn. Sá»‘ liá»‡u cuá»‘i cÃ¹ng ghi nháº­n Ä‘Æ°á»£c vÃ o ngÃ y 03/04/2023 lÃ  1.081,28 Ä‘iá»ƒm (+1.38% so vá»›i 1.070,14 vÃ o 31/03/2023) Ä‘á»ƒ hÆ°á»›ng Ä‘áº¿n 1.085-1.095 Ä‘iá»ƒm. Tuy nhiÃªn, vÃ o tuáº§n thá»© 2 tá»« 14/04/2023 VN30Index biáº¿n Ä‘á»™ng tiÃªu cá»±c hÆ¡n. PhiÃªn Ä‘áº§u tuáº§n, má»Ÿ cá»­a á»Ÿ vÃ¹ng giÃ¡ 1.073 Ä‘iá»ƒm vÃ  chá»‹u Ã¡p lá»±c Ä‘iá»u chá»‰nh á»Ÿ vÃ¹ng giÃ¡ 1.070-1.075 Ä‘iá»ƒm Ä‘á»ƒ káº¿t thÃºc tuáº§n giao dá»‹ch vá»›i phiÃªn giáº£m Ä‘iá»ƒm máº¡nh. Tuáº§n Ä‘iá»u chá»‰nh Ä‘Ã£ diá»…n ra nhÆ° dá»± Ä‘oÃ¡n khi trong tuáº§n qua Vn30Index giáº£m 16.82 Ä‘iá»ƒm (-1,57%) vá»›i khá»‘i lÆ°á»£ng giao dá»‹ch tiáº¿p tá»¥c á»Ÿ má»©c cao, Ä‘iá»ƒm sá»‘ Ä‘iá»u chá»‰nh tuy khÃ´ng lá»›n nhÆ°ng trong bá»‘i cáº£nh thá»‹ trÆ°á»ng Ä‘ang trong khu vá»±c giao Ä‘á»™ng háº¹p thÃ¬ Ä‘á»£t Ä‘iá»u chá»‰nh nÃ y cÅ©ng táº¡o ra cáº£m giÃ¡c báº¥t an cho nhÃ  Ä‘áº§u tÆ°. Äáº¿n ngÃ y 19/04/2023. Ná»— lá»±c phá»¥c há»“i tá»« 2 phiÃªn Ä‘áº§u tuáº§n Ä‘Ã£ khÃ´ng Ä‘Æ°á»£c tiáº¿p tá»¥c duy trÃ¬ trong phiÃªn nÃ y khi Thá»i Ä‘iá»ƒm cuá»‘i cÃ¹ng lÃ  xáº¥p xá»‰ 1.055 Ä‘iá»ƒm. ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:2:3","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#káº¿t-luáº­n-xu-hÆ°á»›ng-1"},{"categories":["projects"],"content":"Káº¿t thÃºcQua Ä‘á»“ Ã¡n â€œStock Analysisâ€ chÃºng ta Ä‘Ã£ thá»±c hÃ nh dÃ¹ng cÃ¡c ká»¹ thuáº­t nhÆ° Cleaning data, Scaling, PCA, K-means Clusteringâ€¦ cÃ¹ng cÃ¡c ká»¹ nÄƒng phÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘á»ƒ lÃ m rÃµ insight cÃ¹ng vá»›i tÃ¬nh hÃ¬nh cá»§a thá»‹ trÆ°á»ng chá»©ng khoÃ¡n phÃ¡i sinh VN30 trong 31 ngÃ y. Tá»« Ä‘Ã¢y cÃ³ thá»ƒ nháº­n Ä‘á»‹nh xu hÆ°á»›ng cá»§a chá»©ng khoÃ¡n trong thá»i gian tá»›i, Ä‘Ã³ lÃ  xu hÆ°á»›ng tÃ­ch lÅ©y. Má»™t sá»‘ há»£p Ä‘á»“ng cÃ³ thá»ƒ tham kháº£o nhÆ° VN30F2306 vÃ  VN30F2Q Ä‘Æ°á»£c dáº«n dáº¯t bá»Ÿi cÃ¡c cá»• phiáº¿u thuá»™c nhÃ³m ngÃ nh xÃ¢y dá»±ng (DIG), ngÃ¢n hÃ ng (VCB), chá»©ng khoÃ¡n (SSI)â€¦ Cáº£m Æ¡n báº¡n Ä‘Ã£ Ä‘á»c Ä‘áº¿n giá» phÃºt nÃ y, OG cáº£m Ä‘á»™ng quÃ¡ ğŸ˜„ Hy vá»ng bÃ i viáº¿t nÃ y sáº½ giÃºp cho báº¡n cáº£m tháº¥y thÃº vá»‹. ChÃºc báº¡n má»™t ngÃ y tá»‘t lÃ nh ğŸ˜„ -Mew- ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:3:0","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#káº¿t-thÃºc"},{"categories":["projects"],"content":"Related Football ETL Analysis A Data Engineer project building pipeline to analyze football data Read more... Stock Analysis Stock Analysis using PCA and K-means Read more... ","date":"05 Sep 2023","objectID":"/stock_analysis_2/:0:0","series":["Stock Analysis"],"tags":["Machine learning","math"],"title":"Stock Analysis P2","uri":"/stock_analysis_2/#related"},{"categories":["projects"],"content":"Stock Analysis using PCA and K-means","date":"31 Aug 2023","objectID":"/stock_analysis/","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/"},{"categories":["projects"],"content":"Warning ÄÃ¢y lÃ  kiáº¿n thá»©c tÃ­ch gÃ³p tá»« nhiá»u nguá»“n vÃ  nghiÃªn cá»©u cá»§a nhÃ³m OG, táº¥t nhiÃªn khÃ´ng thá»ƒ trÃ¡nh khá»i sai sÃ³t. Hy vá»ng bÃ i viáº¿t láº§n nÃ y thÃº vá»‹ vÃ  giÃºp báº¡n Ä‘á»c thÆ° giÃ£n, tham kháº£o. Source PhongHuynh0394 Stock-Analysis Hello! OG Ä‘Ã¢y. á» project láº§n nÃ y mÃ¬nh sáº½ phÃ¢n tÃ­ch gia trá»‹ cá»• phiáº¿u phÃ¡i sinh VN30 Index báº±ng cÃ¡ch sá»­ dá»¥ng PCA vÃ  K-means. Xin vÃ´ cÃ¹ng cáº£m Æ¡n sá»± Ä‘Ã³ng gÃ³p cá»§a 5 thÃ nh viÃªn team OG vÃ  tháº§y Minh Máº«n vÃ  tháº§y HoÃ ng Äá»©c Ä‘Ã£ táº­n tÃ¬nh hÆ°á»›ng dáº«n Ä‘á»ƒ team cÃ³ thá»ƒ hoÃ n thÃ nh Ä‘á»“ Ã¡n má»™t cÃ¡ch tá»‘t nháº¥t. Rá»“i bÃ¢y giá» gÃ©t gÃ´ thooiii ğŸ˜„ ","date":"31 Aug 2023","objectID":"/stock_analysis/:0:0","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#"},{"categories":["projects"],"content":"IntroStock Analysis hay cÃ²n gá»i lÃ  Market Analysis Ä‘á» cáº­p Ä‘áº¿n phÆ°Æ¡ng phÃ¡p mÃ  nhÃ  Ä‘áº§u tÆ° hoáº·c nhÃ  giao dá»‹ch sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ vÃ  Ä‘iá»u tra má»™t cÃ´ng cá»¥ giao dá»‹ch cá»¥ thá»ƒ, lÄ©nh vá»±c Ä‘áº§u tÆ° hoáº·c toÃ n bá»™ thá»‹ trÆ°á»ng chá»©ng khoÃ¡n. KhÃ´ng nhá»¯ng tháº¿, nÃ³ liÃªn quan Ä‘áº¿n viá»‡c nghiÃªn cá»©u dá»¯ liá»‡u thá»‹ trÆ°á»ng trong quÃ¡ khá»© vÃ  hiá»‡n táº¡i vÃ  táº¡o ra má»™t phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ chá»n cá»• phiáº¿u phÃ¹ há»£p Ä‘á»ƒ giao dá»‹ch. CÃ¡c nhÃ  Ä‘áº§u tÆ° sáº½ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh mua hoáº·c bÃ¡n dá»±a trÃªn thÃ´ng tin phÃ¢n tÃ­ch chá»©ng khoÃ¡n. Trong project nÃ y ta sáº½ phÃ¢n tÃ­ch, trá»±c quan hÃ³a bá»™ dá»¯ liá»‡u giáº£ Ä‘á»‹nh Ä‘Æ°á»£c cung cáº¥p bá»Ÿi khÃ¡ch hÃ ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ thá»‹ trÆ°á»ng chá»©ng khoÃ¡n trong khoáº£ng thá»i gian 1 thÃ¡ng cá»§a 30 cÃ´ng ty thuá»™c VN30 DÆ°á»›i Ä‘Ã¢y lÃ  tÃ³m táº¯t sÆ¡ lÆ°á»£c tá»«ng bÆ°á»›c Ä‘á»ƒ xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch: EDA (Exploratory Data Analysis) Data Preprocessing PCA (Principle Component Analysis) K-Means Clustering Data Analysis References (chi tiáº¿t trong notebook á»Ÿ github) Raw Data Source: df_merged.pkl Raw data lÃ  dá»¯ liá»‡u báº£ng giÃ¡ cá»• phiáº¿u cá»§a 30 cÃ´ng ty thuá»™c VN30 Index + 1 trÆ°á»ng giÃ¡ phÃ¡i sinh trong 1 thÃ¡ng ","date":"31 Aug 2023","objectID":"/stock_analysis/:1:0","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#intro"},{"categories":["projects"],"content":"Exploratory Data AnalysisÄÃ¢y lÃ  bÆ°á»›c Ä‘áº§u tiÃªn, chÃºng ta sáº½ cÃ¹ng nhau tÃ¬m hiá»ƒu sÆ¡ lÆ°á»£c raw data cÅ©ng nhÆ° tÃ¬m hiá»ƒu cÃ¡i nhÃ¬n tá»•ng quÃ¡t vá» dá»¯ liá»‡u ta sáº¯p pháº£i phÃ¢n tÃ­ch Ä‘á»ƒ tá»« Ä‘Ã³ cÃ³ cÃ¡ch tiá»n xá»­ lÃ½ phÃ¹ há»£p. LÃ m gÃ¬ thÃ¬ lÃ m cá»© pháº£i import packages Ä‘á»ƒ Ä‘á»c data cÃ¡i Ä‘Ã£ ","date":"31 Aug 2023","objectID":"/stock_analysis/:2:0","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#exploratory-data-analysis"},{"categories":["projects"],"content":"Data AcquistionTa sáº½ import má»™t sá»‘ packages quen thuá»™c Ä‘á»ƒ Ä‘á»c file df_merged.pkl import pickle import numpy as np import pandas as pd import matplotlib.pyplot as plt data = pd.read_pickle('https://github.com/PhongHuynh0394/My-respository/blob/main/df_merged.pkl?raw=true') # Check the data type type(data) # --\u003e list Data nháº­n Ä‘Æ°á»£c tá»« pickle file lÃ  má»™t list, bÃ¢y giá» ta sáº½ tÃ¬m kiáº¿m cÃ¡i nhÃ¬n tá»•ng quan vá» dá»¯ liá»‡u nÃ y ","date":"31 Aug 2023","objectID":"/stock_analysis/:2:1","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#data-acquistion"},{"categories":["projects"],"content":"A Brief View Dá»¯ liá»‡u lÆ°u á»Ÿ pickle lÃ  má»™t list chá»©a 23 dataframe (df) Má»—i df cÃ³ index theo datetime (nghÄ©a lÃ  Ä‘Ã¢y lÃ  loáº¡i dá»¯ liá»‡u thuá»™c timeseries) CÃ¡c columns láº§n lÆ°á»£t lÃ  tá»«ng mÃ£ cá»• phiáº¿u, chá»©a khá»‘i lÆ°á»£ng/ giÃ¡ cá»§a cÃ¡c lá»‡nh mua/bÃ¡n sÃ¡t vá»›i lá»‡nh khá»›p I vÃ  khá»‘i lÆ°á»£ng cá»§a cÃ¡c lá»‡nh mua/bÃ¡n sÃ¡t vá»›i giÃ¡ khá»›p lá»‡nh II print('So luong df:', len(data)) # --\u003e So luong df: 23 Raw data lÃ  giÃ¡ lá»‡nh mua/bÃ¡n I II vÃ  khá»‘i lÆ°á»£ng giao dá»‹ch cá»§a cá»• phiáº¿u 30 cÃ´ng ty VN30raw data \" Raw data lÃ  giÃ¡ lá»‡nh mua/bÃ¡n I II vÃ  khá»‘i lÆ°á»£ng giao dá»‹ch cá»§a cá»• phiáº¿u 30 cÃ´ng ty VN30 Thá»i gian thu tháº­p Ä‘Æ°á»£c cáº­p nháº­t vá»›i chu kÃ¬ lÃ  10 giÃ¢y báº¯t Ä‘áº§u tá»« ngÃ y 20 thÃ¡ng 3 Ä‘áº¿n ngÃ y 19 thÃ¡ng 4, tá»« 2 giá» 15 Ä‘áº¿n 7 giá» 30 má»—i ngÃ y. NhÆ°ng cÃ³ má»™t sá»‘ ngÃ y bá»‹ miss trong bá»™ dá»¯ liá»‡u nÃ y (Chi tiáº¿t hÆ¡n trong notebook á»Ÿ source code) CÃ¹ng xem qua vá» sá»‘ lÆ°á»£ng observations cá»§a má»—i báº£ng Tá»•ng cá»™ng ta cÃ³ 181 fields vÃ  má»—i báº£ng khoáº£ng 1345 observations (tá»•ng cá»™ng 30538 quan sÃ¡t). CÅ©ng khÃ¡ nhiá»u pháº£i khÃ´ng nÃ o. Ta sáº½ cÃ¹ng tiá»n xá»­ lÃ½ chÃºng nÃ o ","date":"31 Aug 2023","objectID":"/stock_analysis/:2:2","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#a-brief-view"},{"categories":["projects"],"content":"Data PreprocessingSau khi Ä‘Ã£ biáº¿t khÃ¡i quÃ¡t raw data, ta sáº½ cáº§n pháº£i tiá»n xá»­ lÃ½ nhá»¯ng dá»¯ liá»‡u thÃ´ nÃ y trÆ°á»›c khi cÃ³ thá»ƒ Ã¡p dá»¥ng cÃ¡c mÃ´ hÃ¬nh mÃ¡y há»c hoáº·c giáº£m chiá»u dá»¯ liá»‡u ","date":"31 Aug 2023","objectID":"/stock_analysis/:3:0","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#data-preprocessing"},{"categories":["projects"],"content":"Data CleaningHÃ£y sá»­ dá»¥ng method describe() cá»§a pandas Ä‘á»ƒ cÃ³ cÃ¡i nhÃ¬n sÆ¡ bá»™ nháº¥t vá» df cá»§a chÃºng ta data[0].describe() Äáº§u tiÃªn, ta sáº½ drop duplicate vÃ  Ä‘á»‹nh dáº¡ng láº¡i index thá»i gian market = pd.DataFrame(columns=data[0].columns.to_list()) #create empty df # Data cleaning for _, df in enumerate(data): df.drop_duplicates() cols = df.columns.to_list() #convert/ replace 0 for col in cols: df[col] = pd.to_numeric(df[col], errors='coerce') # #missing handling df.fillna(0, inplace=True) market = pd.concat([market,df]).copy() #concat all clean df into market #datetime format market.reset_index(inplace=True) market = market.rename(columns={'index': 'datetime'}) market['datetime'] = market['datetime'].dt.strftime('%Y-%m-%d%H:%M:%S') market['datetime'] = pd.to_datetime(market['datetime']) market = market.sort_values(\"datetime\", ascending=True) market.set_index('datetime', inplace=True) Káº¿ tiáº¿p hÃ£y xá»­ lÃ½ missing value báº±ng phÆ°Æ¡ng phÃ¡p ná»™i suy (interpolation) vá»›i method padding, vÃ  sau Ä‘Ã³ sáº½ dÃ¹ng backfill ÄÃ¢y lÃ  phÆ°Æ¡ng phÃ¡p Æ°á»›c tÃ­nh giÃ¡ trá»‹ cá»§a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u chÆ°a biáº¿t trong pháº¡m vi cá»§a má»™t táº­p há»£p rá»i ráº¡c chá»©a má»™t sá»‘ Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Ã£ biáº¿t. Nghe cÃ³ váº» láº±ng nháº±ng, Ä‘Æ¡n giáº£n lÃ  tháº¿ nÃ y: .interpolate(method=â€˜padâ€™): fill null values báº±ng giÃ¡ trá»‹ liá»n ká» nÃ³ láº§n lÆ°á»£t tá»« trÃªn xuá»‘ng (nÃ³ giá»‘ng nhÆ° ffill()) .fillna(method=â€˜backfillâ€™): ÄÃ¢y lÃ  phÆ°Æ¡ng phÃ¡p ngÆ°á»£c láº¡i bÃªn trÃªn, fill null báº±ng giÃ¡ trá»‹ liá»n ká» tá»« dÆ°á»›i lÃªn Note CÃ³ ráº¥t nhiá»u phÆ°Æ¡ng phÃ¡p ná»™i suy nhÆ° linear (default) hay polynomial,â€¦ NhÆ°ng OG chá»n padding vÃ  backfill vÃ¬ 2 phÆ°Æ¡ng phÃ¡p nÃ y cÃ³ thá»ƒ giá»¯ cho data missing á»Ÿ giÃ¡ trá»‹ sÃ¡t nháº¥t vá»›i giÃ¡ trá»‹ thá»±c gáº§n nháº¥t vÃ  giÃºp cho káº¿t quáº£ sau khi fill sÃ¡t vá»›i thá»±c táº¿ nháº¥t. NgoÃ i ra 2 phÆ°Æ¡ng phÃ¡p nÃ y cÃ³ thá»ƒ fill Ä‘Æ°á»£c vá»‹ trÃ­ Ä‘áº§u vÃ  cuá»‘i cÃ¹ng má»™t cÃ¡ch hiá»‡u quáº£. def handle_null(X: pd.DataFrame) -\u003e pd.DataFrame: ''' handle missing value ''' for col in X.columns.to_list(): X[col].interpolate(method='pad', inplace=True) X[col].fillna(method='backfill', inplace=True) return X ","date":"31 Aug 2023","objectID":"/stock_analysis/:3:1","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#data-cleaning"},{"categories":["projects"],"content":"Data transformingOG nháº­n tháº¥y ráº±ng vá»›i cÃ¡c trÆ°á»ng data hiá»‡n táº¡i chÆ°a thá»±c sá»± giÃºp Ã­ch quÃ¡ nhiá»u trong viá»‡c phÃ¢n tÃ­ch sau nÃ y (giÃ¡ mua/bÃ¡n vÃ  sá»‘ lÆ°á»£ng mua/bÃ¡n + giÃ¡ phÃ¡i sinh (label) ) Do Ä‘Ã³ OG cáº§n má»™t dataframe má»›i vá»›i cÃ¡c trÆ°á»ng má»›i cÃ³ nhiá»u giÃ¡ trá»‹ phÃ¢n tÃ­ch hÆ¡n: gttb_ (GiÃ¡ trá»‹ trung bÃ¬nh): lÃ  column má»›i Ä‘Æ°á»£c tÃ­nh trÃªn bÃ¬nh quÃ¢n giÃ¡ cáº£ mua vÃ o, bÃ¡n ra cá»§a tá»«ng cá»• phiáº¿u Ä‘Æ°á»£c giao dá»‹ch THÃ€NH CÃ”NG trÃªn thá»‹ trÆ°á»ng. total_ban \u0026 total_mua (Tá»•ng bÃ¡n/mua khá»‘i lÆ°á»£ng 1): lÃ  column má»›i Ä‘á»ƒ tÃ­nh tá»•ng giÃ¡ bÃ¡n khá»‘i lÆ°á»£ng 1 cÅ©ng nhÆ° mua khá»‘i lÆ°á»£ng 1 cá»§a tá»«ng cá»‘ phiáº¿u Ä‘Æ°á»£c giao dá»‹ch trÃªn thá»‹ trÆ°á»ng. Gia_KL: sao chÃ©p giÃ¡ khá»‘i lÆ°á»£ng cá»§a tá»«ng mÃ£ cá»• phiáº¿u tá»« bá»™ dá»¯ liá»‡u ban Ä‘áº§u. (label) CÃ i Ä‘áº·t láº¡i index thá»i gian: group by cÃ¡c time-series theo phÃºt. def transform_raw(market: pd.DataFrame) -\u003e pd.DataFrame: # split stock name name = [col.split('_1')[-1] for col in market.columns.to_list() if 'mua_gia_1' in col] new_df = pd.DataFrame() for i in name: # calculate gttb (mean) new_df[f'gttb_{i}'] = ((market[f'mua_gia_1{i}'] * market[f'mua_kl_1{i}'] + market[f'ban_gia_1{i}'] * market[f'ban_kl_1{i}']) /(market[f'mua_kl_1{i}'] + market[f'ban_kl_1{i}'])).copy() # get ban_kl and mua_kl new_df[f'total_ban_{i}'] = market[f'ban_kl_1{i}'].copy() new_df[f'total_mua_{i}'] = market[f'mua_kl_1{i}'].copy() # get Gia KL new_df['Gia KL'] = market['Gia KL'].copy() new_df.set_index(market.index, inplace=True) gttb = [col for col in new_df.columns.to_list() if 'gttb' in col] + ['Gia KL'] mua_ban = [col for col in new_df.columns.to_list() if col not in gttb] # Group by minute result = new_df[gttb].groupby([new_df.index.date, new_df.index.hour, new_df.index.minute]).mean() result = pd.concat([result,new_df[mua_ban].groupby([new_df.index.date, new_df.index.hour, new_df.index.minute ]).sum()],axis=1) #Set index in minute index = pd.to_datetime([f\"{d}{h}:{m}:00\" for (d, h, m) in result.index]) result.index = index #handle missing value result = handle_null(result) return result Rá»“i giá» transform rá»“i kiá»ƒm tra láº¡i sá»‘ lÆ°á»£ng quan sÃ¡t á»Ÿ báº£ng má»›i thÃ´i # Check the length of new data len(new_market) # --\u003e 5154 Vá»›i káº¿t quáº£ má»›i, chá»‰ cÃ²n láº¡i 5154 quan sÃ¡t mÃ  thÃ´i, khi rÃºt láº¡i má»™t sá»‘ lÆ°á»£ng quan sÃ¡t lá»›n nhÆ° váº­y, ta sáº½ pháº£i cháº¥p nháº­n rá»§i ro máº¥t Ä‘i nhiá»u thÃ´ng tin vá» dá»¯ liá»‡u mÃ  cá»¥ thá»ƒ lÃ  dá»¯ liá»‡u theo giÃ¢y (cá»© 10 giÃ¢y cáº­p nháº­t). NhÆ°ng Ä‘á»•i láº¡i, data sáº½ cÃ´ Ä‘á»™ng hÆ¡n vÃ  bá»›t nhiá»…u vÃ¬ vá»›i sá»± biáº¿n Ä‘á»•i cá»§a thá»‹ trÆ°á»ng trong cáº£ 1 thÃ¡ng, sá»± thay Ä‘á»•i cá»§a cÃ¡c trÆ°á»ng trong má»—i 10 giÃ¢y lÃ  quÃ¡ nhá» vÃ  khÃ´ng Ä‘Ã¡ng ká»ƒ. ","date":"31 Aug 2023","objectID":"/stock_analysis/:3:2","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#data-transforming"},{"categories":["projects"],"content":"Data ScalingSau khi cÃ³ bá»™ dataframe má»›i tá»‘t hÆ¡n vÃ  sáº¡ch sáº½, bÆ°á»›c káº¿ tiáº¿p sáº½ lÃ  scale láº¡i dá»¯ liá»‡u vá» má»™t chuáº©n Ä‘á»ƒ tÄƒng hiá»‡u quáº£ cá»§a cÃ¡c thuáº­t toÃ¡n há»c mÃ¡y CÃ³ má»™t sá»‘ phÆ°Æ¡ng phÃ¡p scale data nhÆ°: Standardization, Normalization,â€¦ á» project nÃ y, OG sáº½ dÃ¹ng phÆ°Æ¡ng phÃ¡p Normalization Ä‘á»ƒ scale data. PhÆ°Æ¡ng phÃ¡p chuáº©n hÃ³a nÃ y Ä‘Æ°a tá»· lá»‡ dá»¯ liá»‡u tá»« pháº¡m vi ban Ä‘áº§u vá» chuáº©n pháº¡m vi tá»« 0 Ä‘áº¿n 1, giÃ¡ trá»‹ Ä‘Æ°á»£c normalize theo cÃ´ng thá»©c sau: $$ x' = \\frac{x - min}{max - min} $$ Vá»›i $x$ lÃ  giÃ¡ trá»‹ cáº§n Ä‘Æ°á»£c chuáº©n hÃ³a, $max$ vÃ  $min$ lÃ  láº§n lÆ°á»£t lÃ  giÃ¡ trá»‹ lá»›n nháº¥t vÃ  nhá» nháº¥t trong táº¥t cáº£ cÃ¡c observations cá»§a feature trong táº­p dá»¯ liá»‡u. Ta sáº½ dÃ¹ng MinMaxScaler cá»§a scikit-learn trong tÃ¡c vá»¥ nÃ y. from sklearn.preprocessing import MinMaxScaler # Normalization data using libraries min_max = MinMaxScaler() X = new_market.values X_std = min_max.fit_transform(X) print('Data after scaling: ') X_std # array([[9.10048201e-01, 9.43990665e-01, 9.59215952e-01, ..., # 1.31664615e-02, 1.45711006e-02, 2.90267046e-03], # [9.14492108e-01, 9.61493582e-01, 9.57989455e-01, ..., # 1.42007963e-02, 1.10109072e-04, 3.64335188e-03], # [9.12286536e-01, 9.57992999e-01, 9.56950233e-01, ..., # 3.58702686e-03, 1.43141794e-03, 4.40405173e-04], # ..., # [9.23665190e-01, 9.04317386e-01, 8.96622210e-01, ..., # 1.22024151e-01, 3.04635100e-03, 2.10293470e-02], # [9.24218272e-01, 8.89565349e-01, 8.97159958e-01, ..., # 1.05691866e-02, 1.13779375e-03, 2.88265204e-02], # [9.28532923e-01, 9.04317386e-01, 8.98196897e-01, ..., # 8.84087818e-03, 3.67030241e-04, 7.79383700e-03]] NhÆ° váº­y lÃ  Ä‘Ã£ chuáº©n bá»‹ hoÃ n táº¥t cho bÆ°á»›c tiáº¿p theo rá»“i. ChÃºng ta sáº½ bÆ°á»›c vÃ o thuáº­t toÃ¡n chÃ­nh Ä‘áº§u tiÃªn trong project nÃ y. ","date":"31 Aug 2023","objectID":"/stock_analysis/:3:3","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#data-scaling"},{"categories":["projects"],"content":"Principle Component Analysis (PCA)ChÃºng ta Ä‘Ã£ Ä‘i qua viá»‡c tiá»n xá»­ lÃ½ dÃ i ngoáº±n tá»« cleaning, transforming Ä‘áº¿n scaling. Váº­y cÃ¢u há»i lÃ : dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ Ã¡p dá»¥ng cho cÃ¡c mÃ´ hÃ¬nh mÃ¡y há»c hay chÆ°a ? CÃ¢u tráº£ lá»i cho trÆ°á»ng há»£p nÃ y lÃ : ChÆ°a. Táº¡i sao váº­y ? Bá»Ÿi vÃ¬ táº­p dá»¯ liá»‡u cá»§a chÃºng ta cÃ³ quÃ¡ nhiá»u features Feature cá»§a táº­p data lÃ  gÃ¬ ? DÃ nh cho báº¡n chÆ°a biáº¿t, feature cá»§a táº­p data cÃ²n Ä‘Æ°á»£c gá»i lÃ  cÃ¡c trÆ°á»ng (hay field) cá»§a táº­p data Ä‘Ã³. ÄÃ³ lÃ  cÃ¡c cá»™t, má»—i cá»™t lÃ  má»™t â€œtÃ­nh cháº¥tâ€ khÃ¡c nhau cá»§a Ä‘á»‘i tÆ°á»£ng aka quan sÃ¡t (observation) thÆ°á»ng lÃ  cÃ¡c hÃ ng. Hiá»‡n táº¡i cÃ³ thá»ƒ tháº¥y cleaning data cá»§a chÃºng ta cÃ³ 91 features: gttb_(cá»• phiáº¿u): 30 cá»™t giÃ¡ trá»‹ trung bÃ¬nh giao dá»‹ch cá»§a 30 cá»• phiáº¿u trong 1 phÃºt total_ban_(cá»• phiáº¿u): 30 cá»™t tá»•ng khá»‘i lÆ°á»£ng bÃ¡n cá»§a 30 cá»• phiáº¿u trong 1 phÃºt total_mua_(cá»• phiáº¿u): 30 cá»™t tá»•ng khá»‘i lÆ°á»£ng mua cá»§a 30 cá»• phiáº¿u trong 1 phÃºt Gia_KL: 1 cá»™t giÃ¡ phÃ¡i sinh VN30 Index (label) Vá»›i sá»‘ lÆ°á»£ng feature lá»›n nhÆ° váº­y, sáº½ vÃ´ cÃ¹ng kÃ©m hiá»‡u quáº£ náº¿u ngay láº­p tá»©c sá»­ dá»¥ng train cho cÃ¡c mÃ´ hÃ¬nh machine learning. Giáº£i phÃ¡p á»Ÿ Ä‘Ã¢y chÃ­nh lÃ  ta sáº½ giáº£m chiá»u dá»¯ liá»‡u xuá»‘ng má»©c vá»«a Ä‘áº¡t hiá»‡u nÄƒng tá»‘t khi training mÃ  cÅ©ng khÃ´ng lÃ m máº¥t quÃ¡ nhiá»u thÃ´ng tin cá»§a dá»¯ liá»‡u. VÃ¢ng Ä‘Ãºng váº­y, phÆ°Æ¡ng phÃ¡p OG muá»‘n giá»›i thiá»‡u chÃ­nh lÃ  PCA hay cÃ²n Ä‘Æ°á»£c biáº¿t vá»›i tÃªn viá»‡t hÃ³a lÃ  PhÃ¢n tÃ­ch thÃ nh pháº§n chÃ­nh. Má»¥c tiÃªu cá»§a phÆ°Æ¡ng phÃ¡p nÃ y lÃ  Ä‘Æ°a bá»™ dá»¯ liá»‡u ban Ä‘áº§u sang há»‡ tá»a Ä‘á»™ má»›i dá»±a trÃªn cÃ¡c thÃ nh pháº§n chÃ­nh. Dá»¯ liá»‡u á»Ÿ há»‡ tá»a Ä‘á»™ má»›i cÃ³ Ã­t chiá»u hÆ¡n nhÆ°ng váº«n giá»¯ Ä‘Æ°á»£c nhiá»u nháº¥t thÃ´ng tin cÃ³ thá»ƒ, tá»« Ä‘Ã³ giÃºp tÄƒng tá»‘c Ä‘á»™ tÃ­nh toÃ¡n vÃ  giáº£m Ä‘á»™ phá»©c táº¡p mÃ´ hÃ¬nh hÆ¡n ráº¥t nhiá»u. NÃ³i tÃ³m táº¯t cho dá»… hiá»ƒu CÆ¡ báº£n lÃ  phÆ°Æ¡ng phÃ¡p nÃ y Ä‘Æ°a bá»™ data cá»§a ta vÃ o má»™t â€œtháº¿ giá»›i song songâ€ cÃ³ sá»‘ chiá»u má»›i Ã­t hÆ¡n (chiá»u aka features). Báº¡n cÃ³ thá»ƒ hiá»ƒu nhÆ° lÃ  nhÃ¬n dá»¯ liá»‡u cá»§a mÃ¬nh á»Ÿ má»™t gÃ³c khÃ¡c váº­y. á» pháº§n nÃ y chÃºng ta sáº½ sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p nÃ y thÃ´ng qua sá»± phÃ¢n rÃ£ cá»§a ma tráº­n hiá»‡p phÆ°Æ¡ng sai (Eigen decomposition of covariance matrix) ","date":"31 Aug 2023","objectID":"/stock_analysis/:4:0","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#principle-component-analysis-pca"},{"categories":["projects"],"content":"EigenVector vÃ  EigenValueMa tráº­n hiá»‡p phÆ°Æ¡ng sai Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ : $$ S = \\frac{1}{N}\\hat{X}^T\\hat{X} $$ Vá»›i $\\hat{X} = X - \\hat{x}1^T$ lÃ  zero-corrected data hay dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hoÃ¡. Ta sáº½ viáº¿t hÃ m get_eigenpairs() Ä‘á»ƒ tÃ¬m cÃ¡c vector riÃªng vÃ  giÃ¡ trá»‹ riÃªng cá»§a ma tráº­n hiá»‡p phÆ°Æ¡ng sai: $$ Su_i = \\lambda_iu_i $$ Trong Ä‘Ã³: cÃ¡c $(\\lambda_i,u_i)$ lÃ  cÃ¡c cáº·p trá»‹ riÃªng (khÃ´ng Ã¢m) vÃ  vector riÃªng cá»§a ma tráº­n hiá»‡p phÆ°Æ¡ng sai $S$ Táº¡i sao láº¡i cáº§n tÃ¬m cÃ¡c vector riÃªng vÃ  giÃ¡ trá»‹ riÃªng cá»§a ma tráº­n hiá»‡p phÆ°Æ¡ng sai ? Viá»‡c sá»­ dá»¥ng cÃ¡c giÃ¡ trá»‹ riÃªng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ sá»± quan trá»ng cá»§a má»—i thÃ nh pháº§n chÃ­nh Ä‘Æ°á»£c táº¡o ra tá»« viá»‡c giáº£m chiá»u dá»¯ liá»‡u. CÃ¡c giÃ¡ trá»‹ riÃªng cÃ ng lá»›n thÃ¬ thÃ nh pháº§n chÃ­nh tÆ°Æ¡ng á»©ng cÃ ng quan trá»ng. CÃ¡c vector riÃªng tÆ°Æ¡ng á»©ng vá»›i cÃ¡c giÃ¡ trá»‹ riÃªng nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh hÆ°á»›ng cá»§a cÃ¡c thÃ nh pháº§n chÃ­nh. GiÃ¡ trá»‹ riÃªng (Eigenvalues $\\lambda_i$): CÃ¡c há»‡ sá»‘ Ä‘Æ°á»£c gáº¯n vá»›i cÃ¡c vector riÃªng, cung cáº¥p cho Ä‘á»™ lá»›n cá»§a trá»¥c. Trong trÆ°á»ng há»£p nÃ y, chÃºng lÃ  thÆ°á»›c Ä‘o hiá»‡p phÆ°Æ¡ng sai cá»§a dá»¯ liá»‡u. Vector riÃªng (EigenVector $u_i$):CÃ¡c vector (khÃ¡c 0) khÃ´ng thay Ä‘á»•i hÆ°á»›ng khi Ã¡p dá»¥ng báº¥t ká»³ phÃ©p biáº¿n Ä‘á»•i tuyáº¿n tÃ­nh (linear transformation) nÃ o, nÃ³ chá»‰ thay Ä‘á»•i theo há»‡ sá»‘ vÃ´ hÆ°á»›ng. HÃ m sáº¯p xáº¿p cÃ¡c vector riÃªng (Sort eigenvalues): Báº±ng cÃ¡ch sáº¯p xáº¿p cÃ¡c vector riÃªng theo thá»© tá»± cá»§a giÃ¡ trá»‹ riÃªng, ta cÃ³ thá»ƒ chá»n ra cÃ¡c vector riÃªng cÃ³ giÃ¡ trá»‹ riÃªng lá»›n nháº¥t Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c thÃ nh pháº§n chÃ­nh cá»§a dá»¯ liá»‡u (Ä‘Ã³ng gÃ³p nhiá»u nháº¥t vÃ o viá»‡c giáº£i thÃ­ch sá»± biáº¿n thiÃªn cá»§a dá»¯ liá»‡u). CÃ¡c thÃ nh pháº§n chÃ­nh nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tÃ¡i cáº¥u trÃºc dá»¯ liá»‡u ban Ä‘áº§u mÃ  váº«n giá»¯ Ä‘Æ°á»£c Ä‘á»™ giá»‘ng nhau cá»§a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u ban Ä‘áº§u. def get_eigenpairs(X: np.array) -\u003e list: ''' Input: X: np.array (init matrix) return eigenpairs containing eigenvalues and eigenvectors of covariance matrix ''' # Covariance matrix cov_mat = np.cov(X.T) # Eigenvalues and Eigenvectors evals, evecs = np.linalg.eigh(cov_mat) # Sort eigenvalues epairs = [(abs(eval), evec) for (eval, evec) in zip(evals, evecs.T)] epairs = sorted(epairs, key = lambda pair: pair[0], reverse = True) return epairs ","date":"31 Aug 2023","objectID":"/stock_analysis/:4:1","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#eigenvector-vÃ -eigenvalue"},{"categories":["projects"],"content":"Cumulative Sum of ComponentsTÃ­nh tá»•ng tÃ­ch lÅ©y cá»§a cÃ¡c thÃ nh pháº§n trong PCA (Cumulative Sum of Explained Variance) Ä‘á»ƒ xÃ¡c Ä‘á»‹nh tá»•ng pháº§n trÄƒm phÆ°Æ¡ng sai Ä‘Æ°á»£c giáº£i thÃ­ch bá»Ÿi cÃ¡c thÃ nh pháº§n Ä‘Æ°á»£c giá»¯ láº¡i trong mÃ´ hÃ¬nh PCA. $$ r_K = \\frac{\\sum^K_{i=1}\\lambda_i}{\\sum^D_{j=1}\\lambda_j} $$ lÃ  lÆ°á»£ng thÃ´ng tin Ä‘Æ°á»£c giá»¯ láº¡i khi sá»‘ chiá»u dá»¯ liá»‡u má»›i sau PCA lÃ  K. HÃ m findNumVec() thá»±c hiá»‡n viá»‡c láº¥y cÃ¡c giÃ¡ trá»‹ riÃªng tá»« danh sÃ¡ch cÃ¡c eigenpairs vÃ  chuyá»ƒn Ä‘á»•i chÃºng thÃ nh má»™t máº£ng numpy. Sau Ä‘Ã³, nÃ³ tÃ­nh tá»•ng tÃ­ch lÅ©y cá»§a cÃ¡c giÃ¡ trá»‹ riÃªng, sá»­ dá»¥ng hÃ m np.cumsum () chuáº©n hÃ³a tá»•ng cá»§a chÃºng =\u003e cho ra má»™t danh sÃ¡ch cÃ¡c giÃ¡ trá»‹ (trong khoáº£ng tá»« 0 Ä‘áº¿n 1) Ä‘áº¡i diá»‡n cho tá»· lá»‡ pháº§n trÄƒm phÆ°Æ¡ng sai Ä‘Æ°á»£c giáº£i thÃ­ch bá»Ÿi má»—i thÃ nh pháº§n chÃ­nh. Sau Ä‘Ã³, hÃ m láº·p qua danh sÃ¡ch tá»•ng tÃ­ch lÅ©y vÃ  tÃ¬m chá»‰ má»¥c cá»§a giÃ¡ trá»‹ Ä‘áº§u tiÃªn lá»›n hÆ¡n hoáº·c báº±ng tá»· lá»‡ pháº§n trÄƒm phÆ°Æ¡ng sai mong muá»‘n Ä‘Æ°á»£c giáº£i thÃ­ch. Chá»‰ sá»‘ nÃ y Ä‘áº¡i diá»‡n cho sá»‘ lÆ°á»£ng thÃ nh pháº§n chÃ­nh cáº§n thiáº¿t Ä‘á»ƒ giáº£i thÃ­ch tá»· lá»‡ pháº§n trÄƒm phÆ°Æ¡ng sai Ä‘Ã³, vÃ¬ váº­y hÃ m tráº£ vá» giÃ¡ trá»‹ nÃ y cá»™ng vá»›i 1 (vÃ¬ láº­p chá»‰ má»¥c Python báº¯t Ä‘áº§u tá»« 0). def findNumVec(eigenpairs: list, percent = 0.9): ''' Find number of principal components (eigenvectors) -\u003e return the number of principal components when total accumulate \u003e= percent ''' # Get eigenvalues eigenvals = [eigenval for (eigenval, _) in eigenpairs] eigenvals = np.array(eigenvals) # Cumulative sum and calculate percent cumsum = np.cumsum(eigenvals) cumsum /= cumsum[-1] # Find number of principal components that accumulate \u003e= percent for i, val in enumerate(cumsum): if val \u003e= percent: return i + 1 Ta sáº½ thá»­ tÃ¬m xem sá»‘ thÃ nh pháº§n chÃ­nh cáº§n Ä‘á»ƒ giá»¯ Ä‘Æ°á»£c 80% dá»¯ liá»‡u: print(findNumVec(epairs, 0.8)) # --\u003e 28 ","date":"31 Aug 2023","objectID":"/stock_analysis/:4:2","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#cumulative-sum-of-components"},{"categories":["projects"],"content":"Scree ChartTa sáº½ váº½ má»™t biá»ƒu Ä‘á»“ thá»ƒ hiá»‡n quan há»‡ cá»§a sá»‘ lÆ°á»£ng thÃ nh pháº§n chÃ­nh vÃ  pháº§n trÄƒm phÆ°Æ¡ng sai giáº£i thÃ­ch tÃ­ch lÅ©y def screeplot(eigenpairs): ''' Scree plot ''' fig, axes = plt.subplots(nrows = 2, ncols = 1, sharex = True) eigenvals = [eigenval for (eigenval, _) in eigenpairs] eigenvals = np.array(eigenvals) cumsum = np.cumsum(eigenvals) # extracts the eigenvalues from the eigenpairs and calculates their cumulative sum cumsum /= cumsum[-1] name = [f'PCA {i}' for i in range(len(cumsum))] # line plot # the eigenvalues are plotted against the number of principal components axes[0].plot(range(len(eigenvals)), eigenvals, marker = '.', color = 'b', label = 'Eigenvalue') # the cumulative proportion of the variance explained by each component is plotted against the number of principal components axes[1].plot(range(len(cumsum)), cumsum, marker = '.', color = 'green', label = 'Cumulative propotion') # y axis label axes[0].set_ylabel('Eigen values') axes[1].set_ylabel('Cumulative explained variance') # item legend axes[0].legend() axes[1].legend() # grid axes[0].grid() axes[1].grid() # title fig.supxlabel('Number of components') plt.tight_layout() plt.show() #print the cumsum of eigenvalues print(pd.DataFrame(cumsum, columns = ['Cumulative total'], index = name)) result = { str(i): f\"PC {i+1}({var:.1f}%)\" for i, var in enumerate(cumsum*100) } return result pca_scree = screeplot(epairs) Scree plotScree plot \" Scree plot Giáº£i thÃ­ch ÄÆ°á»ng cá»§a giÃ¡ trá»‹ riÃªng mÃ u xanh nÆ°á»›c biá»ƒn trÃªn biá»ƒu Ä‘á»“ cho ta biáº¿t Ä‘á»™ lá»›n cá»§a má»—i thÃ nh pháº§n chÃ­nh vÃ  táº§m quan trá»ng cá»§a chÃºng trong giáº£i thÃ­ch sá»± biáº¿n thiÃªn cá»§a dá»¯ liá»‡u. Náº¿u giÃ¡ trá»‹ riÃªng cá»§a má»™t thÃ nh pháº§n chÃ­nh lÃ  lá»›n, thÃ¬ thÃ nh pháº§n Ä‘Ã³ cÃ³ táº§m quan trá»ng cao trong viá»‡c giáº£i thÃ­ch sá»± biáº¿n thiÃªn cá»§a dá»¯ liá»‡u. ÄÆ°á»ng mÃ u xanh lÃ¡ thá»ƒ hiá»‡n tá»•ng tÃ­ch lÅ©y cho ta biáº¿t tá»•ng pháº§n trÄƒm Ä‘á»™ lá»›n cá»§a sá»± biáº¿n thiÃªn cá»§a dá»¯ liá»‡u mÃ  cÃ¡c thÃ nh pháº§n chÃ­nh cÃ³ thá»ƒ giáº£i thÃ­ch. Dá»±a vÃ o biá»ƒu Ä‘á»“ trÃªn cÃ³ thá»ƒ nháº­n tháº¥y náº¿u chá»‰ cÃ³ 2 chiá»u, ta chá»‰ giá»¯ Ä‘Æ°á»£c khoáº£ng 37% dá»¯ liá»‡u ban Ä‘áº§u. ","date":"31 Aug 2023","objectID":"/stock_analysis/:4:3","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#scree-chart"},{"categories":["projects"],"content":"Visualize PCABÃ¢y giá», ta sáº½ thá»±c hiá»‡n chiáº¿u dá»¯ liá»‡u ban Ä‘áº§u Ä‘Ã£ chuáº©n hÃ³a $\\hat{X}$ xuá»‘ng khÃ´ng gian con tÃ¬m Ä‘Æ°á»£c vÃ  láº¥y ra ma tráº­n cÃ¡c thÃ nh pháº§n chÃ­nh Ä‘á»ƒ tiáº¿p tá»¥c cÃ´ng viá»‡c phÃ¢n tÃ­ch vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh. HÃ m getPC() tráº£ vá» má»™t ma tráº­n cÃ¡c thÃ nh pháº§n chÃ­nh tá»« ma tráº­n ban Ä‘áº§u, dá»±a trÃªn sá»‘ lÆ°á»£ng thÃ nh pháº§n Ä‘Ã£ cho hoáº·c sá»‘ lÆ°á»£ng thÃ nh pháº§n giá»¯ Ä‘Æ°á»£c 80% dá»¯ liá»‡u (náº¿u num_components khÃ´ng Ä‘Æ°á»£c Ä‘Æ°a ra). Ma tráº­n trá»ng sá»‘ $W$ lÃ  ma tráº­n chuyá»ƒn Ä‘á»•i tuyáº¿n tÃ­nh Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u gá»‘c vÃ o khÃ´ng gian má»›i, trong Ä‘Ã³ má»—i thÃ nh pháº§n chÃ­nh Ä‘Æ°á»£c sáº¯p xáº¿p theo Ä‘á»™ quan trá»ng giáº£m dáº§n. Cá»¥ thá»ƒ, má»—i cá»™t cá»§a ma tráº­n $W$ lÃ  má»™t vector riÃªng chuáº©n hÃ³a tÆ°Æ¡ng á»©ng vá»›i cÃ¡c giÃ¡ trá»‹ riÃªng cá»§a ma tráº­n hiá»‡p phÆ°Æ¡ng sai $s$. Thá»±c hiá»‡n viá»‡c nhÃ¢n ma tráº­n $W$ vá»›i hoÃ¡n vá»‹ cá»§a ma tráº­n Ä‘Ã£ chuáº©n hÃ³a $\\hat{X}$ (init_matrix). Ma tráº­n káº¿t quáº£ sau Ä‘Ã³ tiáº¿p tá»¥c Ä‘Æ°á»£c hoÃ¡n vá»‹ Ä‘á»ƒ phÃ¹ há»£p vá»›i hÃ¬nh dáº¡ng ban Ä‘áº§u cá»§a init_matrix vÃ  tráº£ vá» káº¿t quáº£. def getPC(eigenpairs, init_matrix, num_components = None): ''' Return matrix of principal components from init_matrix ''' # default num_components = number which to keep 80% data if num_components is None: num_components = findNumVec(eigenpairs, 0.8) # extracts the eigen vectors corresponding to the top num_components eigenvalues from the eigenpairs list eigenvecs = [eigenvec for (_, eigenvec) in eigenpairs[:num_components]] W = np.array([e.T for e in eigenvecs]) # stacks the eigen vectors into a weight matrix W return (W @ init_matrix.T).T X_pca = getPC(epairs, X_std) Váº­y lÃ  ta Ä‘Ã£ giáº£m Ä‘Æ°á»£c Ä‘á»™ phá»©c táº¡p cho bá»™ dá»¯ liá»‡u khÃ¡ â€œnhá»c nháº±nâ€ nÃ y. HÃ£y trá»±c quan hÃ³a lÃªn biá»ƒu Ä‘á»“ Ä‘á»ƒ cÃ³ má»™t gÃ³c nhÃ¬n cá»¥ thá»ƒ vÃ  rÃµ rÃ ng hÆ¡n. Biá»ƒu Ä‘á»“ scatter plot sau khi PCA cÃ³ thá»ƒ giÃºp cho chÃºng ta nhÃ¬n tháº¥y cÃ¡ch dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n bá»‘ trÃªn cÃ¡c thÃ nh pháº§n chÃ­nh (principal components) vÃ  kiá»ƒm tra xem liá»‡u chÃºng ta cÃ³ thá»ƒ tÃ¬m tháº¥y cÃ¡c cluster hoáº·c pattern nÃ o trong dá»¯ liá»‡u. plt.scatter(X_pca[:,0], X_pca[:,1]) plt.xlabel('PC1') plt.ylabel('PC2') plt.title('Visualizing data through PCA', fontsize=18) plt.gca().set_aspect('equal', 'datalim') plt.grid() plt.show() Visualizing data via PCAVisualizing data via PCA \" Visualizing data via PCA Okayy dá»±a vÃ o biá»ƒu Ä‘á»“ trÃªn, cÅ©ng cÃ³ thá»ƒ tháº¥y lÃ  dá»¯ liá»‡u á»Ÿ khÃ´ng gian má»›i Ä‘Ã£ phÃ¢n tÃ¡ch khÃ¡ rÃµ rÃ ng rá»“i. Äiá»u nÃ y nghÄ©a lÃ  phÆ°Æ¡ng phÃ¡p PCA Ä‘Ã£ giáº£m sá»‘ chiá»u cá»§a dá»¯ liá»‡u má»™t cÃ¡ch hiá»‡u quáº£. BÆ°á»›c tiáº¿p theo chÃ­nh lÃ  Ã¡p vÃ o mÃ´ hÃ¬nh K-Means Ä‘á»ƒ phÃ¢n cá»¥m vÃ  tÃ¬m pattern. ChÃºng ta sáº½ cÃ¹ng chiáº¿n tiáº¿p á»Ÿ pháº§n 2 nhÃ© ","date":"31 Aug 2023","objectID":"/stock_analysis/:4:4","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#visualize-pca"},{"categories":["projects"],"content":"To be ContinueChÃºng ta Ä‘Ã£ thá»±c hiá»‡n cÃ¡c bÆ°á»›c tiá»n xá»­ lÃ½ dá»¯ liá»‡u vÃ  sau Ä‘Ã³ lÃ  thá»±c hiá»‡n PCA Ä‘á»ƒ giáº£m chiá»u dá»¯ liá»‡u má»™t cÃ¡ch hiá»‡u quáº£. BÃ i sau pháº§n 2, OG sáº½ thá»±c hiá»‡n training mÃ´ hÃ¬nh K-means clustering vÃ  cuá»‘i cÃ¹ng lÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u chá»©ng khoÃ¡ng. ÄÃ¢y lÃ  kiáº¿n thá»©c tÃ­ch gÃ³p tá»« nhiá»u nguá»“n vÃ  nghiÃªn cá»©u cá»§a nhÃ³m OG, táº¥t nhiÃªn khÃ´ng thá»ƒ trÃ¡nh khá»i sai sÃ³t. Hy vá»ng bÃ i viáº¿t láº§n nÃ y thÃº vá»‹ vÃ  giÃºp báº¡n Ä‘á»c thÆ° giÃ£n, tham kháº£o. -Mew- ","date":"31 Aug 2023","objectID":"/stock_analysis/:5:0","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#to-be-continue"},{"categories":["projects"],"content":"Related Football ETL Analysis A Data Engineer project building pipeline to analyze football data Read more... Spotify Analysis Analyze data from Spotify platform utilizing the Spotify API and MongoDB, Apache Hadoop, Pyspark, Dremio and Power BI Read more... ","date":"31 Aug 2023","objectID":"/stock_analysis/:0:0","series":["Stock analysis"],"tags":["Machine learning","math"],"title":"Stock analysis","uri":"/stock_analysis/#related"},{"categories":[],"content":"NgÃ nh Data cÃ³ gÃ¬ hot mÃ  mÃ¬nh láº¡i dÃ­nh","date":"30 Aug 2023","objectID":"/start_journey/","series":["Data lÃº"],"tags":[],"title":"Tháº±ng nhÃ³c thÃ­ch code vÃ  data","uri":"/start_journey/"},{"categories":[],"content":"Quáº£ng CÃ¡o ChÃ o má»«ng Ä‘áº¿n vá»›i â€œData lÃºâ€ Giá»›i thiá»‡u vá»›i má»i ngÆ°á»i Ä‘Ã¢y lÃ  series Ä‘áº§u tiÃªn cá»§a kÃªnh nÃ y ká»ƒ máº¥y cÃ¢u chuyá»‡n kÃ¬ thÃº áº£o ma canada cá»§a OG trong tháº¿ giá»›i data rá»™ng lá»›n ğŸ˜‚ ÄÃ¹a chÃºt thÃ´i, Ä‘Ã¢y sáº½ lÃ  series vui váº» vá» cÃ¢u chuyá»‡n Data mÃ  OG tráº£i nghiá»‡m, gÃ³p nháº·t Ä‘Æ°á»£c. Hy vá»ng báº¡n sáº½ thÃ­ch nÃ³ hihi ğŸ˜ GÃ²i dzo Hellooo OG Ä‘Ã¢yy ! ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i sá»‘ Ä‘áº§u tiÃªn, láº§n Ä‘áº§u cÃ²n bá»¡ ngá»¡, nÃªn mÃ¬nh sáº½ ká»ƒ cÆ¡ duyÃªn Ä‘Æ°a mÃ¬nh Ä‘áº¿n vá»›i ngÃ nh Data vÃ  quyáº¿t Ä‘á»‹nh dáº¥n thÃ¢n vÃ o con Ä‘Æ°á»ng trá»Ÿ thÃ nh má»™t Data Engineer ğŸ˜— GÃ©t Goo! ","date":"30 Aug 2023","objectID":"/start_journey/:0:0","series":["Data lÃº"],"tags":[],"title":"Tháº±ng nhÃ³c thÃ­ch code vÃ  data","uri":"/start_journey/#"},{"categories":[],"content":"á»¦a ngÃ nh Data Science ?Khoan Khoan â€¦ BÃªn trÃªn lÃ  Engineer, qua Ä‘Ã¢y lÃ  Science lÃ  sao OG ? Tá»« tá»« nÃ o ğŸ˜„ Má»i chuyá»‡n báº¯t Ä‘áº§u khi mÃ¬nh Ä‘áº­u vÃ o má»™t ngÃ nh Ä‘Æ°á»£c ca ngá»£i lÃ  ngÃ nh â€œquyáº¿n rÅ©â€ nháº¥t tháº¿ ká»· 21 theo Harvard Business Review , Ä‘Ã³ lÃ  Data Science. KhÃºc nÃ y mÃ¬nh nghe cÅ©ng oÃ¡ch oÃ¡ch, nhÆ°ng chÃ­nh xÃ¡c Data Science lÃ  gÃ¬ ? VÃ  cÃ¡c nhÃ  khoa há»c dá»¯ liá»‡u (data scientist) lÃ m gÃ¬ ? ","date":"30 Aug 2023","objectID":"/start_journey/:1:0","series":["Data lÃº"],"tags":[],"title":"Tháº±ng nhÃ³c thÃ­ch code vÃ  data","uri":"/start_journey/#á»§a-ngÃ nh-data-science-"},{"categories":[],"content":"Data Science lÃ  gÃ¬ nhá»‰?NgÃ nh Khoa há»c dá»¯ liá»‡u hay Data Science lÃ  má»™t lÄ©nh vá»±c liÃªn ngÃ nh á»©ng dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p khoa há»c, thuáº­t toÃ¡n vÃ  cÃ¡c phÃ¢n tÃ­ch thá»‘ng kÃª Ä‘á»ƒ tÃ¬m kiáº¿m Ã½ nghÄ©a tá»« dá»¯ liá»‡u. Hay nÃ³i báº±ng cÃ¡ch dá»… hiá»ƒu, Data Science lÃ  ngÃ nh tÃ¬m kiáº¿m, phÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘á»ƒ khai thÃ¡c táº¥t cáº£ nhá»¯ng giÃ¡ trá»‹ mÃ  dá»¯ liá»‡u mang láº¡i Ä‘á»ƒ phá»¥c vá»¥ nhiá»u má»¥c Ä‘Ã­ch khÃ¡c nhau. Data Science lÃ  á»©ng dá»¥ng khoa há»c Ä‘á»ƒ tÃ¬m kiáº¿m Ã½ nghÄ©a cá»§a dá»¯ liá»‡u Ä‘á»ƒ dá»± Ä‘oÃ¡n tÆ°Æ¡ng lai Má»™t nhÃ  khoa há»c dá»¯ liá»‡u (Data Scientist) lÃ  ngÆ°á»i chá»‹u trÃ¡ch nhiá»‡m Ä‘Æ°a ra cÃ¡c dáº«n chá»©ng tá»« dá»¯ liá»‡u, Ä‘á»ƒ tá»« Ä‘Ã³ Ä‘á» xuáº¥t cÃ¡c giáº£i phÃ¡p, káº¿ hoáº¡ch hay Ä‘á»‹nh hÆ°á»›ng tá»« Ã½ nghÄ©a tÃ¬m Ä‘Æ°á»£c tá»« dá»¯ liá»‡u Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n kinh doanh khÃ¡c nhau. Má»™t data scientist cáº§n pháº£i biáº¿t ká»¹ nÄƒng gÃ¬? Láº­p trÃ¬nh: Python vÃ  R lÃ  2 ngÃ´n ngá»¯ chÃ­nh Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»‘i vá»›i ngÃ nh nÃ y. Python lÃ  má»™t ngÃ´n ngá»¯ láº­p trÃ¬nh linh hoáº¡t phá»• biáº¿n vá»›i ráº¥t nhiá»u thÆ° viá»‡n Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u nhÆ° numpy, pandas, matplotlib,â€¦ Trong khi Ä‘Ã³ R tá» lÃ  lÃ  má»™t ngÃ´n ngá»¯ máº¡nh máº½ vá» phÃ¢n tÃ­ch vÃ  thá»‘ng kÃª, ngoÃ i ra R cÅ©ng thÆ°á»ng Ä‘Æ°á»£c dÃ¹ng trong nghiÃªn cá»©u vÃ  há»c thuáº­t. Thá»‘ng kÃª vÃ  á»©ng dá»¥ng toÃ¡n há»c: Náº¿u báº¡n khÃ´ng yÃªu thÃ­ch toÃ¡n há»c, cháº¯c háº³n báº¡n cÅ©ng sáº½ khÃ´ng thá»ƒ lÃ m Ä‘iá»u Ä‘Ã³ vá»›i data science. Háº³n váº­y, lÃ  má»™t nhÃ  khoa há»c dá»¯ liá»‡u, báº¡n cáº§n cÃ³ má»™t ná»n táº£ng kiáº¿n thá»©c toÃ¡n há»c vá»¯ng, Ä‘áº·c biá»‡t lÃ  vá» xÃ¡c suáº¥t thá»‘ng kÃª vÃ  Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh,â€¦ SQL vÃ  DBMS: Ta pháº£i tiáº¿p xÃºc ráº¥t nhiá»u vá»›i há»‡ quáº£n trá»‹ cÆ¡ sá»Ÿ dá»¯ liá»‡u (Database Management System hay DBMS), Ä‘Ã³ cÃ³ thá»ƒ lÃ  há»‡ quáº£n trá»‹ cÆ¡ sá»Ÿ dá»¯ liá»‡u Quan Há»‡ (Relational Database Management System) nhÆ° MySQL, Postgres, SQL serverâ€¦ hay NoSQL database nhÆ° MongoDB, Cassandra,â€¦ VÃ  Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i database (RDBMS), Ä‘iá»u khÃ´ng thá»ƒ thiáº¿u chÃ­nh lÃ  SQL (Structured query language aka si cá»“ hay Ã©t qui eo ğŸ˜‚ ). CÆ¡ báº£n thÃ¬ Ä‘Ã¢y lÃ  ngÃ´n ngá»¯ dÃ¹ng Ä‘á»ƒ truy suáº¥t dá»¯ liá»‡u, giao tiáº¿p vá»›i database, Ä‘áº·c biá»‡t lÃ  cÃ¡c RDBMS. AI, Machine learning: Khi cÃ³ má»™t lÆ°á»£ng dá»¯ liá»‡u khá»•ng lá»“, má»™t data scientist cÃ³ thá»ƒ sáº½ dÃ¹ng chÃºng Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh há»c mÃ¡y hoáº·c máº¡ng Ä‘á»ƒ giáº£i cÃ¡c bÃ i toÃ¡n há»“i quy vÃ  Ä‘Æ°a ra Ä‘Æ°á»£c cÃ¡c dá»± Ä‘oÃ¡n vá» xu hÆ°á»›ng data hay giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i. CÃ³ hiá»ƒu biáº¿t vá» cÃ¡c thuáº­t toÃ¡n mÃ¡y há»c vÃ  kiáº¿n trÃºc máº¡ng noron cÅ©ng lÃ  má»™t Ä‘iá»u cáº§n cÃ³ á»Ÿ nhÃ  khoa há»c dá»¯ liá»‡u. Äá»c Ä‘áº¿n Ä‘Ã¢y, cÃ³ thá»ƒ báº¡n sáº½ cÃ³ cáº£m giÃ¡c â€œDÃ¨jÃ  vuâ€ nháº¹ â€¦ Sao nhiá»u chá»• giá»‘ng Data Analyst tháº¿ nhá»‰ ? MÃ  thiá»‡t ra lÃ  khÃ´ng giá»‘ng Ä‘Ã¢u nhÃ©, hai ngÃ nh nÃ y chá»‰ lÃ  anh em xÃ£ há»™i vá»›i nhau mÃ  thÃ´i ğŸ˜‚ ","date":"30 Aug 2023","objectID":"/start_journey/:1:1","series":["Data lÃº"],"tags":[],"title":"Tháº±ng nhÃ³c thÃ­ch code vÃ  data","uri":"/start_journey/#data-science-lÃ -gÃ¬-nhá»‰"},{"categories":[],"content":"Data Scientist vs Data AnalystSáºµn tiá»‡n ká»ƒ má»™t chÃºt vá» vai trÃ² cá»§a má»™t ngÆ°á»i Data Analyst. Vá» cÆ¡ báº£n, vai trÃ² cá»§a há» cÅ©ng giá»‘ng vá»›i cÃ¡c data scientist, há» cÅ©ng phÃ¢n tÃ­ch dá»¯ liá»‡u, cá»‘ gáº¯ng tÃ¬m kiáº¿m vÃ  rÃºt ra giÃ¡ trá»‹ tá»« chÃºng. NhÆ°ng sáº½ cÃ³ má»™t sá»‘ Ä‘iá»ƒm khÃ¡c biá»‡t: Data Analyst Data Science ChuyÃªn viÃªn phÃ¢n tÃ­ch dá»¯ liá»‡u NhÃ  khoa há»c dá»¯ liá»‡u Váº«n lÃ m cÃ´ng viá»‡c cá»§a DS nhÆ°ng vá»›i quy mÃ´ nhá» Tá»a sÃ¡ng vá»›i lÆ°á»£ng data khá»•ng lá»“ (BigData) KhÃ´ng cáº§n nhiá»u kiáº¿n thá»©c láº­p trÃ¬nh Cáº§n kiáº¿n thá»©c láº­p trÃ¬nh Cáº§n cÃ³ kiáº¿n thá»©c vá» hoáº¡t Ä‘á»™ng kinh doanh nhiá»u hÆ¡n vÃ  vá»¯ng vá» kiáº¿n thá»©c thá»‘ng kÃª Cáº§n cÃ³ kiáº¿n thá»©c khÃ´ng chá»‰ toÃ¡n thá»‘ng kÃª, á»©ng dá»¥ng mÃ  cÃ²n pháº£i cÃ³ kiáº¿n thá»©c vá» computer science, AI/ML,â€¦ Dá»±a vÃ o dá»¯ liá»‡u Ä‘Æ°a ra cÃ¡c giÃ¡ trá»‹ cÃ³ Ã­ch vÃ  cÃ¡i nhÃ¬n trá»±c quan vá» dá»¯ liá»‡u ÄÆ°á»£c yÃªu cáº§u phÃ¡t triá»ƒn â€œdata productâ€ Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh cÃ³ Ã­ch tá»« táº­p dá»¯ liá»‡u lá»›n Data Science and Data Analytic Rá»“i okay nÃ£y giá» lÃ  cáº£ data science (DS) vÃ  data analytic (DA) rá»“i. Giá» lÃ  má»›i Ä‘áº¿n data engineer cá»§a tui nÃ¨ hihi ğŸ˜„ ","date":"30 Aug 2023","objectID":"/start_journey/:1:2","series":["Data lÃº"],"tags":[],"title":"Tháº±ng nhÃ³c thÃ­ch code vÃ  data","uri":"/start_journey/#data-scientist-vs-data-analyst"},{"categories":[],"content":"Data Engineer lÃ  gÃ¬ ?Tuy há»c Data Science, nhÆ°ng thá»±c ra ngay tá»« nhá»¯ng lÃºc cÃ²n mÆ¡n má»Ÿn cáº¥p 3, OG Ä‘Ã£ tá»«ng cÃ³ Æ°á»›c muá»‘n trá»Ÿ thÃ nh má»™t láº­p trÃ¬nh viÃªn má»™t tay cafe má»™t tay chÃ©m code bÃ¬nh loáº¡n thiÃªn háº¡ ğŸ˜‚ VÃ  tháº¿ lÃ  tÃ¬m Ä‘Æ°á»£c má»™t ngÃ nh thÃ­ch há»£p Ä‘Æ°á»£c coi lÃ  â€œSoftware engineer cho dataâ€, ngÃ nh nÃ y lÃ  má»™t trong cÃ¡c ngÃ nh cÃ³ xu hÆ°á»›ng phÃ¡t triá»ƒn nhanh nháº¥t trong nhÃ³m ngÃ nh cÃ´ng nghá»‡. VÃ¢ng Ä‘Ã³ chÃ­nh lÃ  Data Engineer Äáº§u tiÃªn, Data Engineer hay DE Ä‘Æ°á»£c gá»i lÃ  ká»¹ sÆ° dá»¯ liá»‡u. ÄÃ¢y lÃ  vai trÃ² Ä‘áº£m nhiá»‡m viá»‡c phÃ¢n tÃ­ch nguá»“n dá»¯ liá»‡u, xÃ¢y dá»±ng vÃ  duy trÃ¬ há»‡ thá»‘ng cÆ¡ sá»Ÿ dá»¯ liá»‡u hiá»‡u quáº£. NgoÃ i ra cÅ©ng lÃ  ngÆ°á»i Ä‘áº£m báº£o cháº¥t lÆ°á»£ng dá»¯ liá»‡u cho cÃ¡c phÃ²ng ban khÃ¡c sá»­ dá»¥ng. CÆ¡ báº£n Ä‘á»ƒ lÃ  Ä‘á»ƒ cho DS vÃ  DA lÃ m viá»‡c má»™t cÃ¡ch hiá»‡u quáº£ nháº¥t, há» cáº§n cÃ³ má»™t nguá»“n data á»•n Ä‘á»‹nh vÃ  sáº¡ch sáº½. VÃ  ngÆ°á»i Ä‘áº£m nhiá»‡m viá»‡c luÃ¢n chuyá»ƒn data Ä‘Ã³ tá»›i cho há» chÃ­nh lÃ  Data Engineer. KhÃ´ng chá»‰ cÃ³ DS vÃ  DA mÃ  data engineer phá»¥c vá»¥ cho táº¥t cáº£ cÃ¡c phÃ²ng ban khÃ¡c Data Engineer NÃ³i tÃ³m láº¡i, Data Engineer lÃ  ngÆ°á»i xÃ¢y dá»±ng cÃ¡c Ä‘Æ°á»ng á»‘ng dá»¯ liá»‡u (data pipeline) Ä‘á»ƒ truyá»n dá»¯ liá»‡u tá»« nÆ¡i nÃ y sang nÆ¡i khÃ¡c má»™t cÃ¡ch cháº¥t lÆ°á»£ng nháº¥t :)) KhÃ¡i niá»‡m cÆ¡ báº£n lÃ  tháº¿ thÃ´i, nghe cÃ³ váº» Ä‘Æ¡n giáº£n pháº£i khÃ´ng. HÃ£y tiáº¿p tá»¥c vá»›i má»¥c tiáº¿p theo Ä‘á»ƒ xem liá»‡u ta cáº§n gÃ¬ Ä‘á»ƒ trá»Ÿ thÃ nh data engineer ","date":"30 Aug 2023","objectID":"/start_journey/:2:0","series":["Data lÃº"],"tags":[],"title":"Tháº±ng nhÃ³c thÃ­ch code vÃ  data","uri":"/start_journey/#data-engineer-lÃ -gÃ¬-"},{"categories":[],"content":"Data Engineer thÃ¬ cáº§n biáº¿t gÃ¬ ?Má»™t data Engineer vá» báº£n cháº¥t lÃ  xÃ¢y dá»±ng cÃ¡c data pipeline Ä‘á»ƒ luÃ¢n chuyá»ƒn dá»¯ liá»‡u. Äá»ƒ lÃ m tá»‘t viá»‡c Ä‘Ã³, ká»¹ sÆ° dá»¯ liá»‡u pháº£i biáº¿t: Ká»¹ nÄƒng láº­p trÃ¬nh: Táº¥t nhiÃªn rá»“i, báº¡n lÃ  má»™t nhÃ¢n viÃªn IT thÃ¬ Ä‘iá»u nÃ y lÃ  pháº£i cÃ³. CÃ¡c ngÃ´n ngá»¯ mÃ  DE thÆ°á»ng dÃ¹ng lÃ  SQL, Python vÃ  R. Há»‡ cÆ¡ sá»Ÿ dá»¯ liá»‡u quan há»‡ vÃ  phi quan há»‡: Dá»¯ liá»‡u cÃ³ ráº¥t nhiá»u dáº¡ng: Structure/Semi/Unstructure data, do Ä‘Ã³ cÅ©ng cáº§n cÃ³ nhiá»u loáº¡i database quáº£n lÃ½ chÃºng. VÃ  DE lÃ m viá»‡c ráº¥t nhiá»u vá»›i database. Há» sáº½ lÃ  ngÆ°á»i trá»±c tiáº¿p tÆ°Æ¡ng tÃ¡c ká»ƒ cáº£ vá»›i SQL vÃ  NoSQL database. ETL/ELT: ETL aka Extract Transform Load hay ELT aka Extract Load Transform lÃ  quy trÃ¬nh xá»­ lÃ½ vÃ  luÃ¢n chuyá»ƒn dá»¯ liá»‡u tá»« nguá»“n Ä‘áº¿n Ä‘Ã­ch. Má»™t DE pháº£i náº¯m Ä‘Æ°á»£c Ä‘á»ƒ thiáº¿t káº¿ data pipeline má»™t cÃ¡ch hiá»‡u quáº£ nháº¥t Data Warehouse: hay Ä‘Æ°á»£c biáº¿t Ä‘áº¿n lÃ  kho chá»©a dá»¯ liá»‡u. Báº¡n cÃ³ thá»ƒ sáº½ pháº£i xÃ¢y dá»±ng, thiáº¿t káº¿ cáº¥u trÃºc data warehouse trÃªn cloud platform vÃ  xÃ¢y dá»±ng cÃ¡c káº¿t ná»‘i dá»¯ liá»‡u Ä‘á»ƒ tá»‘i Æ°u hÃ³a tá»‘c Ä‘á»™ truy xuáº¥t vÃ  Ä‘áº£m báº£o viá»‡c phÃ¢n tÃ­ch dá»¯ liá»‡u. Big Data: Báº¡n cÅ©ng cáº§n pháº£i biáº¿t cÃ¡c kiáº¿n trÃºc lÆ°u trá»¯ vÃ  xá»­ lÃ½ táº­p dá»¯ liá»‡u lá»›n nhÆ° Hadoop, Spark,â€¦ Cloud: Táº¥t nhiÃªn lÃ  pháº£i cÃ³ rá»“i, cÃ¡c cloud platform nhÆ° Google Cloud Platform, AWS, Azure,â€¦ Ä‘Ã£ ráº¥t ná»•i tiáº¿ng trong viá»‡c há»— trá»£ xÃ¢y dá»±ng vÃ  thiáº¿t káº¿ há»‡ thá»‘ng pipeline cÅ©ng nhÆ° há»— trá»£ tá»‘i Ä‘a viá»‡c xá»­ lÃ½ bigdata cÅ©ng nhÆ° deploy há»‡ thá»‘ng háº¡ táº§ng má»™t cÃ¡ch nhanh chÃ³ng. Báº¡n cÃ³ thá»ƒ sáº½ pháº£i lÃ m viá»‡c vá»›i lÆ°á»£ng dá»¯ liá»‡u khá»•ng lá»“ vÃ  táº­p dá»¯ liá»‡u lá»›n. VÃ  Ä‘á»ƒ xÃ¢y dá»±ng há»‡ thá»‘ng xá»­ lÃ½ Ä‘Æ°á»£c lÆ°á»£ng dá»¯ liá»‡u Ä‘Ã³, cháº¯c cháº¯n pháº£i cÃ³ sá»± gÃ³p máº·t cá»§a cÃ¡c ná»n táº£ng Ä‘Ã¡m mÃ¢y. Wellâ€¦ NhÃ¬n chung cÅ©ng nhiá»u thá»© cáº§n pháº£i biáº¿t Ä‘áº¥y nhá»‰, táº¥t nhiÃªn Ä‘Ã³ chá»‰ lÃ  má»™t sá»‘ Ä‘iá»u quan trá»ng nháº¥t. NgoÃ i ra báº¡n cÅ©ng cáº§n pháº£i biáº¿t má»™t sá»‘ kiáº¿n thá»©c khÃ¡c vá» Unix vÃ  Linux, Docker, Git, Batch/Stream Processing,â€¦ VÃ  cÃ²n ti tá»‰ thá»© khÃ¡c mÃ  OG cÃ³ ká»ƒ Ä‘áº¿n rÄƒng long Ä‘áº§u báº¡c cÃ³ láº½ cÅ©ng chÆ°a háº¿t ğŸ˜‚ ","date":"30 Aug 2023","objectID":"/start_journey/:2:1","series":["Data lÃº"],"tags":[],"title":"Tháº±ng nhÃ³c thÃ­ch code vÃ  data","uri":"/start_journey/#data-engineer-thÃ¬-cáº§n-biáº¿t-gÃ¬-"},{"categories":[],"content":"Táº¡m káº¿tHÃ nh trÃ¬nh nÃ o khi báº¯t Ä‘áº§u cÅ©ng gian nan, cáº£ báº£n thÃ¢n OG khi báº¯t Ä‘áº§u cÅ©ng khÃ´ng biáº¿t gÃ¬ cáº£. NhÆ°ng khi nháº¥c ngÃ³n chÃ¢n lÃªn vÃ  Ä‘i thÃ¬ má»›i cáº£m nháº­n Ä‘Æ°á»£c tháº¿ giá»›i chá»© ğŸ˜„ Hy vá»ng bÃ i viáº¿t nÃ y giÃºp báº¡n thÆ° giÃ£n vÃ  cÃ³ má»™t cÃ¡i nhÃ¬n chung vá» ngÃ nh data nhÃ©. Háº¹n gáº·p láº¡i trong bÃ i tiáº¿p theo hehe -Meww- ","date":"30 Aug 2023","objectID":"/start_journey/:3:0","series":["Data lÃº"],"tags":[],"title":"Tháº±ng nhÃ³c thÃ­ch code vÃ  data","uri":"/start_journey/#táº¡m-káº¿t"},{"categories":null,"content":"Continuous of Football ETL series","date":"01 Aug 2023","objectID":"/football_etl_2/","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/"},{"categories":null,"content":"Source PhongHuynh0394 Football_ETL_Analysis Hello! Hello! OG Ä‘Ã¢y, sau pháº§n 1 chÃºng ta Ä‘Ã£ setup cÃ¡c kiá»ƒu vÃ  Ä‘áº£m báº£o má»i thá»© trÆ¡n tru rá»“i, á»Ÿ pháº§n nÃ y chÃºng ta sáº½ chuáº©n bá»‹ Data Source, vÃ  khá»Ÿi cháº¡y pipeline á»Ÿ Implement sau Ä‘Ã³ sáº½ Visualize cleaned data cÃ³ Ä‘Æ°á»£c tá»« data warehouse thÃ nh Dashboard. Báº¯t Ä‘áº§u thÃ´i nÃ o ! ","date":"01 Aug 2023","objectID":"/football_etl_2/:0:0","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#"},{"categories":null,"content":"Data Source","date":"01 Aug 2023","objectID":"/football_etl_2/:1:0","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#data-source"},{"categories":null,"content":"Chuáº©n bá»‹ file lÃ m raw dataCÃ¡c file csv sá»­ dá»¥ng lÃ m dá»¯ liá»‡u Ä‘Æ°á»£c táº£i tá»« Football Database - Kaggle. ÄÃ¢y lÃ  dá»¯ liá»‡u thá»‘ng kÃª cá»§a cáº§u thá»§, Ä‘á»™i bÃ³ng Ä‘áº¿n tá»« 5 giáº£i bÃ³ng hÃ ng Ä‘áº§u ChÃ¢u Ã‚u (Premier League, Laliga, Seria A, Budesliga, League 1) Ta sáº½ cÃ³ schema nhÆ° sau: Schema trong Ä‘Ã³: games: báº£ng chá»©a thÃ´ng tin thá»‘ng kÃª cá»§a tá»«ng tráº­n Ä‘áº¥u (gameID) teams: Báº£ng chá»©a tÃªn cÃ¡c Ä‘á»™i bÃ³ng (teamID) players: Báº£ng chá»©a tÃªn cÃ¡c cáº§u thá»§ (playerID) leagues: Báº£ng chÆ°a tÃªn cÃ¡c giáº£i Ä‘áº¥u (leagueID) appearances: Báº£ng thá»‘ng kÃª cá»§a cáº§u thá»§ á»Ÿ cÃ¡c game mÃ  há» tham gia (gameID, playerID) teamstats: Báº£ng thá»‘ng kÃª cá»§a Ä‘á»™i bÃ³ng á»Ÿ tá»«ng game (gameID, teamID) ","date":"01 Aug 2023","objectID":"/football_etl_2/:1:1","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#chuáº©n-bá»‹-file-lÃ m-raw-data"},{"categories":null,"content":"Load data vÃ o MySQLCÃ³ nhiá»u cÃ¡ch Ä‘á»ƒ load data vÃ o MySQL, á»Ÿ Ä‘Ã¢y mÃ¬nh sáº½ sá»­ dá»¥ng cÃ¡ch LOAD LOCAL_INFILE cá»§a MySQL luÃ´n. Tip HÃ£y Ä‘áº£m báº£o báº¡n Ä‘Ã£ make up láº§n Ä‘áº§u rá»“i nhÃ© ! HÃ£y copy folder chá»©a cÃ¡c file csv vÃ o de_mysql container: docker cp /football de_mysql:/tmp/dataset/ docker cp /load_data de_mysql:/tmp/dataset/ Sau Ä‘Ã³ táº¡o báº£ng trá»‘ng sáºµn trong MySQL: make mysql_create #Create table in mysql Tiáº¿p tá»¥c vá»›i lá»‡nh: make to_mysql_root # ----- You will access to MySQL container SET GLOBAL LOCAL_INFILE=TRUE; #Set local_infile variable to load data from local exit; # ----- Exit container make mysql_load #load data make mysql_create_relation #create table relation Tháº¿ lÃ  Ä‘Ã£ chuáº©n bá»‹ xong dá»¯ liá»‡u cho MySQL. ","date":"01 Aug 2023","objectID":"/football_etl_2/:1:2","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#load-data-vÃ o-mysql"},{"categories":null,"content":"Init PostgreSQL SchemaTa cÅ©ng cáº§n pháº£i táº¡o sáºµn schema sáºµn trong Posgres nhÆ° sau: make to_psql CREATE SCHEMA IF NOT EXISTS analysis; exit; Tháº¿ lÃ  Ä‘Ã£ hoÃ n táº¥t viá»‡c chuáº©n bá»‹ data, giá» thÃ¬ ta báº¯t Ä‘áº§u vÃ o pháº§n viá»‡c chÃ­nh thÃ´i ","date":"01 Aug 2023","objectID":"/football_etl_2/:1:3","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#init-postgresql-schema"},{"categories":null,"content":"ImplementCÃ´ng viá»‡c chÃ­nh trong pháº§n nÃ y lÃ  xÃ¢y dá»±ng cÃ¡c data pipeline báº±ng dagster. CÆ¡ báº£n cÃ³ thá»ƒ hiá»ƒu lÃ  ta táº¡o cÃ¡c Asset vÃ  chuyá»ƒn chÃºng tá»« database nÃ y sang database khÃ¡c. ","date":"01 Aug 2023","objectID":"/football_etl_2/:2:0","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#implement"},{"categories":null,"content":"ExtractionÄá»ƒ cÃ³ thá»ƒ quáº£n lÃ½ viá»‡c truy xuáº¥t dá»¯ liá»‡u tá»« MySQL vÃ  load vÃ o MinIO Ä‘á»ƒ lÆ°u táº¡m, ta sáº½ xÃ¢y dá»±ng má»™t I/O Manager phá»¥c vá»¥ viá»‡c Ä‘Ã³. Äáº§u tiÃªn, hÃ£y vÃ o Ä‘Æ°á»ng dáº«n: ./etl_pipeline/etl_pipeline/resources/ Ta sáº½ xÃ¢y dá»±ng MySQL io manager báº±ng cÃ¡ch táº¡o file mysql_io_manager.py vá»›i ná»™i dung sau: from contextlib import contextmanager from datetime import datetime import pandas as pd from dagster import IOManager, OutputContext, InputContext from sqlalchemy import create_engine @contextmanager def connect_mysql(config): conn_info = ( f\"mysql+pymysql://{config['user']}:{config['password']}\" + f\"@{config['host']}:{config['port']}\" + f\"/{config['database']}\" ) db_conn = create_engine(conn_info) try: yield db_conn except Exception: raise class MySQLIOManager(IOManager): def __init__(self, config): self.config = config def handle_output(self, context: OutputContext, obj: pd.DataFrame): pass def load_input(self, context: InputContext) -\u003e pd.DataFrame: pass def extract_data(self, sql: str) -\u003e pd.DataFrame: with connect_mysql(self.config) as db_conn: pd_data = pd.read_sql_query(sql, db_conn) return pd_data Sau Ä‘Ã³, tiáº¿p tá»¥c Ä‘á»‘i vá»›i minio_io_manager.py: import os from contextlib import contextmanager from datetime import datetime from typing import Union import pandas as pd import pyarrow as pa import pyarrow.parquet as pq from dagster import IOManager, InputContext, OutputContext from minio import Minio @contextmanager def connect_minio(config): client = Minio( endpoint=config.get(\"endpoint_url\"), access_key=config.get(\"aws_access_key_id\"), secret_key=config.get(\"aws_secret_access_key\"), secure=False ) try: yield client except Exception: raise class MinIOIOManager(IOManager): def __init__(self, config): self._config= config def _get_path(self, context: Union[InputContext, OutputContext]): layer, schema, table = context.asset_key.path key = \"/\".join([layer, schema, table.replace(f\"{layer}_\", \"\")]) tmp_file_path = \"/tmp/file-{}-{}.parquet\".format( datetime.today().strftime(\"%Y%m%d%H%M%S\"), \"-\".join(context.asset_key.path) ) if context.has_asset_partitions: start, end = context.asset_partitions_time_window dt_format = \"%Y%m%d%H%M%S\" partition_str = start.strftime(dt_format) + \"_\" + end.strftime(dt_format) return os.path.join(key, f\"{partition_str}.pq\"), tmp_file_path else: return f\"{key}.pq\", tmp_file_path def handle_output(self, context: OutputContext, obj: pd.DataFrame): # convert to parquet format key_name, tmp_file_path = self._get_path(context) table = pa.Table.from_pandas(obj) pq.write_table(table, tmp_file_path) # upload to MinIO try: bucket_name = self._config.get(\"bucket\") with connect_minio(self._config) as client: # Make bucket if not exist. found = client.bucket_exists(bucket_name) if not found: client.make_bucket(bucket_name) else: print(f\"Bucket {bucket_name}already exists\") client.fput_object(bucket_name, key_name, tmp_file_path) row_count = len(obj) context.add_output_metadata({\"path\": key_name, \"tmp\": tmp_file_path}) # clean up tmp file os.remove(tmp_file_path) except Exception: raise def load_input(self, context: InputContext) -\u003e pd.DataFrame: bucket_name = self._config.get(\"bucket\") key_name, tmp_file_path = self._get_path(context) try: with connect_minio(self._config) as client: #Make bucket if not exist found = client.bucket_exists(bucket_name) if not found: client.make_bucket(bucket_name) else: print(f\"Bucket {bucket_name}already exist\") client.fget_object(bucket_name, key_name, tmp_file_path) pd_data = pd.read_parquet(tmp_file_path) return pd_data except Exception: raise Sau khi Ä‘Ã£ táº¡o thÃ nh cÃ´ng cÃ¡c io manager cho mysql vÃ  minio, ta sáº½ báº¯t Ä‘áº§u xÃ¢y dá»±ng bronze layer Note nho nhá» Trong project nÃ y mÃ¬nh chia cÃ¡c giai Ä‘oáº¡n transformation thÃ nh cÃ¡c layer: bronze layer: Giai Ä‘oáº¡n chá» má»›i load raw data, cÃ³ thá»ƒ hiá»ƒu Ä‘Ã¢y lÃ  data chÆ°a transform gÃ¬ cáº£ siler layer: Transform má»™t pháº§n tá»« bronze layer, á»Ÿ Ä‘oáº¡n nÃ y data Ä‘Ã£ Ä‘Æ°á»£c cleaning sÆ¡ gold layer: Sau khi transform má»™t láº§n ná»¯a tá»« silver layer, giai Ä‘oáº¡n nÃ y sáº½ truy váº¥n ra cÃ¡c thÃ´n","date":"01 Aug 2023","objectID":"/football_etl_2/:2:1","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#extraction"},{"categories":null,"content":"TransformationTiáº¿p tá»¥c táº¡o file silver_layer.py cÃ¹ng folder vá»›i bronze layer: from dagster import asset, Output, AssetIn import pandas as pd @asset( io_manager_key=\"minio_io_manager\", required_resource_keys={\"minio_io_manager\"}, ins={ \"teamstats\": AssetIn( key_prefix=[\"football\", \"bronze\"] ), \"games\": AssetIn( key_prefix=[\"football\", \"bronze\"] ), \"leagues\": AssetIn( key_prefix=[\"football\", \"bronze\"] ) }, key_prefix=[\"football\", \"silver\"], description='Statistic of teams in games', group_name=\"Silver_layer\", compute_kind=\"Pandas\" ) def silver_statsTeamOnGames(teamstats: pd.DataFrame, games: pd.DataFrame, leagues: pd.DataFrame) -\u003e Output[pd.DataFrame]: ts = teamstats.copy() gs = games.copy() lgs = leagues.copy() #Drop unsusable columns in games gs.drop(columns=gs.columns.to_list()[13:], inplace=True) #create StatperLeagueSeason result = pd.merge(ts, gs, on=\"gameID\") result = result.merge(lgs, on=\"leagueID\", how=\"left\") result.drop(columns=['season_y', 'date_y'],inplace=True) result = result.rename(columns={'season_x': 'season', 'date_x': 'date'}) return Output( result, metadata={ \"table\": \"statsTeamOnGames\", \"records\": len(result) } ) @asset( io_manager_key=\"minio_io_manager\", required_resource_keys={\"minio_io_manager\"}, ins={ \"appearances\": AssetIn( key_prefix=[\"football\", \"bronze\"] ), \"games\": AssetIn( key_prefix=[\"football\", \"bronze\"] ), \"players\": AssetIn( key_prefix=[\"football\", \"bronze\"] ) }, key_prefix=[\"football\", \"silver\"], group_name=\"Silver_layer\", description='statistic of players in games', compute_kind=\"Pandas\" ) def silver_playerAppearances(appearances: pd.DataFrame, games: pd.DataFrame, players: pd.DataFrame) -\u003e Output[pd.DataFrame]: app = appearances.copy() ga = games.copy() pla = players.copy() #Drop unusable column ga.drop(columns=ga.columns.to_list()[13:], inplace=True) #Merge player_appearances = pd.merge(app, pla, on=\"playerID\", how=\"left\") player_appearances = pd.merge(player_appearances, ga, on=\"gameID\", how=\"left\") #drop unecessary columns and rename player_appearances.drop(columns=['leagueID_y'],inplace=True) player_appearances.rename(columns={'leagueID_x': 'leagueID'}, inplace=True) return Output( player_appearances, metadata={ \"table\": \"playerAppearances\", \"records\": len(player_appearances) } ) @asset( io_manager_key=\"minio_io_manager\", required_resource_keys={\"minio_io_manager\"}, ins={ \"teams\": AssetIn( key_prefix=[\"football\", \"bronze\"] ) }, key_prefix=[\"football\", \"silver\"], group_name=\"Silver_layer\", description='Teams', compute_kind=\"Pandas\" ) def silver_teams(teams: pd.DataFrame) -\u003e Output[pd.DataFrame]: return Output( teams, metadata={ \"table\": 'teams', 'records': len(teams) } ) LÃºc nÃ y mÃ¬nh cÃ³ 3 silver assets, Ä‘Æ°á»£c join tá»« cÃ¡c báº£ng á»Ÿ bronze Tiáº¿p Ä‘áº¿n lÃ  gold_layer, lÃºc nÃ y ta sáº½ tÃ­nh cÃ¡c thÃ´ng sá»‘ thá»‘ng kÃª cá»§a tá»«ng giáº£i Ä‘Ã¢u tá»«ng mÃ¹a, cÃ¡c thá»‘ng kÃª cá»§a cáº§u thá»§ trong 90 phÃºt thi Ä‘áº¥u, vÃ  cáº£ thá»‘ng kÃª cá»§a tá»«ng cáº§u thá»§ trong tá»«ng mÃ¹a giáº£i gold_layer.py sáº½ cÃ³ ná»™i dung: from dagster import asset, Output, AssetIn import pandas as pd @asset( io_manager_key=\"minio_io_manager\", ins={ \"silver_statsTeamOnGames\": AssetIn( key_prefix=[\"football\", \"silver\"] ) }, group_name=\"Gold_layer\", key_prefix=[\"football\", \"gold\"], description='Statistic of all league in each season', compute_kind=\"Pandas\" ) def gold_statsPerLeagueSeason(silver_statsTeamOnGames: pd.DataFrame) -\u003e Output[pd.DataFrame]: st = silver_statsTeamOnGames.copy() result = ( st.groupby(['name', 'season']) .agg({\"goals\": \"sum\", \"xGoals\": \"sum\", \"shots\": \"sum\", \"shotsOnTarget\": \"sum\", \"fouls\": \"sum\", \"yellowCards\": \"sum\", \"redCards\": \"sum\",'corners': 'sum', \"gameID\": 'count'}) .reset_index() ) result = result.rename(columns={'gameID':\"games\"}) result['goalPerGame']= result.goals/result.games result['season'] = result['season'].astype('string') return Output( result, metadata={ 'table': 'statPerLeagueSeason', 'records': len(result) } ) @asset( io_manager_key=\"minio_io_manager\", ins={ \"silver_playerAppearances\": AssetIn( key_prefix=[\"football\", \"silver\"] ) },","date":"01 Aug 2023","objectID":"/football_etl_2/:2:2","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#transformation"},{"categories":null,"content":"LoadTrÆ°á»›c háº¿t hÃ£y táº¡o IO Manager cho Postgres Ä‘á»ƒ quáº£n lÃ½ viá»‡c load cleaned data. Ta táº¡o file psql_io_manager.py á»Ÿ vá»‹ trÃ­ mÃ  ta Ä‘Ã£ táº¡o 2 io manager trÆ°á»›c vá»›i ná»™i dung: from contextlib import contextmanager from datetime import datetime import pandas as pd from dagster import IOManager, OutputContext, InputContext from sqlalchemy import create_engine @contextmanager def connect_psql(config): conn_info = ( f\"postgresql+psycopg2://{config['user']}:{config['password']}\" + f\"@{config['host']}:{config['port']}\" + f\"/{config['database']}\" ) db_conn = create_engine(conn_info) try: yield db_conn except Exception: raise class PostgreSQLIOManager(IOManager): def __init__(self, config): self._config = config def load_input(self, context: InputContext) -\u003e pd.DataFrame: pass def handle_output(self, context: OutputContext, obj: pd.DataFrame): schema, table = context.asset_key.path[-2], context.asset_key.path[-1] with connect_psql(self._config) as conn: # insert new data ls_columns = (context.metadata or {}).get(\"columns\", []) obj[ls_columns].to_sql( name=f\"{table}\", con=conn, schema=schema, if_exists=\"replace\", index=False, chunksize=10000, method=\"multi\" ) Sau Ä‘Ã³, táº¡o má»™t asset warehouse_layer.py: from dagster import multi_asset, Output, AssetIn, AssetOut, asset import pandas as pd @multi_asset( ins={ \"gold_statsPerLeagueSeason\": AssetIn( key_prefix=[\"football\", \"gold\"] ) }, outs={ \"statsperleagueseason\": AssetOut( io_manager_key=\"psql_io_manager\", key_prefix=[\"statsPerLeagueSeason\", 'analysis'], metadata={ \"columns\": [ \"name\", \"season\", \"goals\", \"xGoals\", \"shots\", \"shotsOnTarget\", \"fouls\", \"yellowCards\", \"redCards\", \"corners\", \"games\", \"goalPerGame\" ] } ), }, compute_kind=\"PostgreSQL\", group_name=\"Warehouse_layer\" ) def statsPerLeagueSeason(gold_statsPerLeagueSeason: pd.DataFrame) -\u003e Output[pd.DataFrame]: return Output( gold_statsPerLeagueSeason, metadata={ \"schema\": \"analysis\", \"table\": \"statsPerLeagueSeason\", \"records\": len(gold_statsPerLeagueSeason) } ) @multi_asset( ins={ \"gold_statsPerPlayerSeason\": AssetIn( key_prefix=['football', 'gold'] ) }, outs={ \"statsperplayerseason\": AssetOut( io_manager_key=\"psql_io_manager\", key_prefix=[\"statsPerPlayerSeason\", 'analysis'], metadata={ \"columns\": [ \"playerID\", \"name\", \"season\", \"goals\", \"shots\", \"xGoals\", \"xGoalsChain\", \"xGoalsBuildup\", \"assists\", \"keyPasses\", \"xAssists\", \"gDiff\", \"gDiffRatio\" ] } ) }, compute_kind=\"PostgreSQL\", group_name=\"Warehouse_layer\" ) def statsPerPlayerSeason(gold_statsPerPlayerSeason: pd.DataFrame) -\u003e Output[pd.DataFrame]: return Output( gold_statsPerPlayerSeason, metadata={ \"schema\": \"analysis\", \"table\": \"statsPerPlayerSeason\", \"records\": len(gold_statsPerPlayerSeason) } ) @multi_asset( ins={ \"gold_statsPlayerPer90\": AssetIn( key_prefix=['football', 'gold'] ) }, outs={ \"statsplayerper90\": AssetOut( io_manager_key=\"psql_io_manager\", key_prefix=[\"statsPlayerPer90\", 'analysis'], metadata={ \"columns\": [ 'playerID', 'name', 'total_goals', 'total_assists', 'total_time', 'goalsPer90', 'assistsPer90', 'scorers' ] } ) }, compute_kind=\"PostgreSQL\", group_name=\"Warehouse_layer\" ) def statsPlayerPer90(gold_statsPlayerPer90: pd.DataFrame) -\u003e Output[pd.DataFrame]: return Output( gold_statsPlayerPer90, metadata={ \"schema\": \"analysis\", \"table\": \"statsPlayerPer90\", \"records\": len(gold_statsPlayerPer90) } ) ","date":"01 Aug 2023","objectID":"/football_etl_2/:2:3","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#load"},{"categories":null,"content":"Run systemCuá»‘i cÃ¹ng, ta sáº½ káº¿t há»£p táº¥t cáº£ cÃ¡c asset láº¡i giÃºp dagster nháº­n diá»‡n vÃ  quáº£n lÃ½ vá»›i file __init__.py á»Ÿ etl_pipeline/etl_pipeline/__init__.py import os from dagster import Definitions from .assets.silver_layer import * from .assets.gold_layer import * from .assets.bronze_layer import * from .assets.warehouse_layer import * from .resources.minio_io_manager import MinIOIOManager from .resources.mysql_io_manager import MySQLIOManager from .resources.psql_io_manager import PostgreSQLIOManager MYSQL_CONFIG = { \"host\": os.getenv(\"MYSQL_HOST\"), \"port\": os.getenv(\"MYSQL_PORT\"), \"database\": os.getenv(\"MYSQL_DATABASE\"), \"user\": os.getenv(\"MYSQL_USER\"), \"password\": os.getenv(\"MYSQL_PASSWORD\") } MINIO_CONFIG = { \"endpoint_url\": os.getenv(\"MINIO_ENDPOINT\"), \"bucket\": os.getenv(\"DATALAKE_BUCKET\"), \"aws_access_key_id\": os.getenv(\"AWS_ACCESS_KEY_ID\"), \"aws_secret_access_key\": os.getenv(\"AWS_SECRET_ACCESS_KEY\") } PSQL_CONFIG = { \"host\": os.getenv(\"POSTGRES_HOST\"), \"port\": os.getenv(\"POSTGRES_PORT\"), \"database\": os.getenv(\"POSTGRES_DB\"), \"user\": os.getenv(\"POSTGRES_USER\"), \"password\": os.getenv(\"POSTGRES_PASSWORD\") } ls_asset=[asset_factory(table) for table in tables] + [silver_statsTeamOnGames, silver_teams , silver_playerAppearances, gold_statsPerLeagueSeason, gold_statsPerPlayerSeason, gold_statsPlayerPer90, statsPerLeagueSeason, statsPerPlayerSeason, statsPlayerPer90] defs = Definitions( assets=ls_asset, resources={ \"mysql_io_manager\": MySQLIOManager(MYSQL_CONFIG), \"minio_io_manager\": MinIOIOManager(MINIO_CONFIG), \"psql_io_manager\": PostgreSQLIOManager(PSQL_CONFIG), } ) sau Ä‘Ã³ hÃ£y dÃ¹ng lá»‡nh sau Ä‘á»ƒ cáº­p nháº­t cÃ¡c assets docker restart etl_pipeline ","date":"01 Aug 2023","objectID":"/football_etl_2/:2:4","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#run-system"},{"categories":null,"content":"Check UIHÃ£y kiá»ƒm tra Dagit UI á»Ÿ localhost:3001 Ä‘á»ƒ cháº¯c cháº¯n ráº±ng má»i thá»© váº«n á»•n NgoÃ i ra cÅ©ng cÃ³ thá»ƒ check MinIO: localhost:9000 ","date":"01 Aug 2023","objectID":"/football_etl_2/:2:5","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#check-ui"},{"categories":null,"content":"VisualizationCuá»‘i cÃ¹ng lÃ  váº½ dashboard, Ä‘áº§u tiÃªn ta cáº§n pháº£i láº¥y Ä‘Æ°á»£c data tá»« psql, hÃ£y vÃ o táº¡o file: ./streamlit/src/psql_connect.py: import os import psycopg2 from dotenv import load_dotenv import pandas as pd #load environment load_dotenv() #list table in database table = ['statsperleagueseason','statsperplayerseason', 'statsplayerper90'] PSQL_CONFIG = { \"host\": os.getenv(\"POSTGRES_HOST\"), \"port\": os.getenv(\"POSTGRES_PORT\"), \"database\": os.getenv(\"POSTGRES_DB\"), \"user\": os.getenv(\"POSTGRES_USER\"), \"password\": os.getenv(\"POSTGRES_PASSWORD\") } #create connection def init_connection(config): return psycopg2.connect( database=config['database'], user=config['user'], password=config['password'], host=config['host'], port=config['port'] ) def extract_data(): conn = init_connection(PSQL_CONFIG) return [pd.read_sql(f'SELECT * FROM analysis.{tab}', conn) for tab in table] Cuá»‘i cÃ¹ng lÃ  táº¡o main.py ngay trong thÆ° má»¥c scr: import streamlit as st import pandas as pd import plotly.express as px import plotly.graph_objects as go from psql_connect import extract_data import numpy as np # #extract data from PostgreSQL ls_df = extract_data() l_season = ls_df[0] p_season = ls_df[1] p_match = ls_df[2] st.set_page_config(page_title = 'Dashboard Football', layout='wide', page_icon='chart_with_upwards_trend') #Overview def overview(table: pd.DataFrame, detail: str): if (st.checkbox('Do you want to see Data ?')): table col1, col2 = st.columns(2) co_df = table.columns.to_list() with col1: st.bar_chart(table.describe()) if (st.checkbox('Do you want to see describe each column ?')): for col in co_df: if table[col].dtypes not in ['int64', 'float64']: continue st.bar_chart(table[col].describe()) with col2: st.caption(f':red[Columns]: {len(co_df)}') st.caption(f':red[Records]: {len(table)}') st.caption(f':red[Description]: {detail}') st.caption(f':red[Columns name]:{co_df}') #league statistic def statleague(): Cards = l_season[['name','season','yellowCards', 'redCards', 'fouls']] #Card_fouls col1, col2 = st.columns(2) with col1: #Goals per games fig = px.bar(l_season, x=\"name\", y=\"goalPerGame\", color=\"name\", barmode=\"stack\", facet_col=\"season\", labels={\"name\": \"League\", \"goals/games\": \"GPG\"}) fig.update_layout(showlegend=False, title='Goals per Game') st.plotly_chart(fig) #fouls fig = px.line(Cards, x='season', y='fouls', color='name') fig.update_layout(title='Fouls of leagues', xaxis_title='Season', yaxis_title='Fouls', legend_title='League') st.plotly_chart(fig) with col2: #Red card fig = px.line(Cards, x='season', y='redCards', color='name') fig.update_layout(title='Red Cards of leagues', xaxis_title='Season', yaxis_title='RedCards', legend_title='League') st.plotly_chart(fig) #yellow card fig = px.line(Cards, x='season', y='yellowCards', color='name') fig.update_layout(title='Yellow Cards of leagues', xaxis_title='Season', yaxis_title='YellowCards', legend_title='League') st.plotly_chart(fig) #Player statistic def statplayer(): col1, col2 = st.columns(2) with col1: #Best offensive player top_player90= p_match[(p_match['goalsPer90'] \u003e 0.8) | (p_match['assistsPer90'] \u003e 0.4)] fig = px.scatter(p_match[['name','goalsPer90', 'assistsPer90']], x='goalsPer90', y='assistsPer90', hover_name='name') fig.add_trace( go.Scatter(x=top_player90['goalsPer90'], y=top_player90['assistsPer90'], mode='markers+text', marker_size=5, text=top_player90['name'], textposition='bottom center', textfont=dict(size=15)) ) fig.update_layout(title='Best offensive Players (2018-2020)', xaxis_title='Goals Per 90min', yaxis_title='Assists Per 90min') st.plotly_chart(fig) #goals-xgoal fig = px.scatter(p_season, x=\"xGoals\", y=\"goals\", color=(p_season['xGoals'] - p_season['goals'] \u003c 10), color_discrete_sequence=[\"red\", \"green\"], opacity=0.5) fig.update_layout(title=\"Goals (G) and Expected Goals (xG)\", xaxis_title=\"xG\", yaxis_title=\"G\", ) st.plotly_chart(fig) with col2: #Top score player topPlayer = p_season.groupby(['name']).agg({'goals': 'sum'}).sort_values('goals', ascending=False).res","date":"01 Aug 2023","objectID":"/football_etl_2/:3:0","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#visualization"},{"categories":null,"content":"ConclusionCuá»‘i cÃ¹ng cÅ©ng Ä‘Ã£ xong má»™t project xÃ¢y dá»±ng data pipeline cÆ¡ báº£n, trong lÃºc thá»±c hiá»‡n cháº¯c cháº¯n sáº½ cÃ³ cáº£ táº¥n lá»—i xáº£y ra, nhÆ°ng OG tin lÃ  má»i gian khÃ³ Ä‘á»u sáº½ vÆ°á»£t quan Ä‘Æ°á»£c, thá»© Ä‘á»ng láº¡i chÃ­nh lÃ  kiáº¿n thá»©c vÃ  ká»¹ nÄƒng cá»§a chÃºng ta. ChÃºc báº¡n thÃ nh cÃ´ng vÃ  Ä‘Ã³n xem tiáº¿p cÃ¡c dá»± Ã¡n tiáº¿p theo cá»§a OG nhÃ© ! -Mew- ","date":"01 Aug 2023","objectID":"/football_etl_2/:4:0","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#conclusion"},{"categories":null,"content":"Related Content Football ETL Analysis A Data Engineer project building pipeline to analyze football data Read more... Stock Analysis Basic Analyzing VN30 stock using PCA and K-Means Read more... ","date":"01 Aug 2023","objectID":"/football_etl_2/:0:0","series":["Football ETL"],"tags":[],"title":"Football ETL Analysis P2","uri":"/football_etl_2/#related-content"},{"categories":["projects"],"content":"A Data Engineer project building pipeline to analyze football data","date":"31 Jul 2023","objectID":"/football_etl/","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/"},{"categories":["projects"],"content":"Source PhongHuynh0394 Football_ETL_Analysis ","date":"31 Jul 2023","objectID":"/football_etl/:0:0","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#"},{"categories":["projects"],"content":"IntroduceTrong project nÃ y, OG sáº½ build end-to-end ETL data pipeline hoÃ n chá»‰nh Ä‘á»ƒ phÃ¢n tÃ­ch football data tá»« Kaggle vá»›i data pipeline nhÆ° sau: Data Pipeline CÃ¡c bÆ°á»›c cá»¥ thá»ƒ: Set up: DÃ¹ng Docker táº¡o container vÃ  cÃ¡c images cáº§n thiáº¿t cho pipeline, trong Ä‘Ã³ cÃ³ cáº£ Dagster dÃ¹ng xÃ¢y dá»±ng pipeline. Chuáº©n bá»‹ data source: load cÃ¡c file csv (cÃ³ Ä‘Æ°á»£c tá»« Kaggle) vÃ o MySQL nháº±m má»¥c Ä‘Ã­ch lÆ°u trá»¯ raw data (mÃ´ phá»ng source data) Extract: Láº¥y data tá»« MySQL vÃ  load vÃ o MinIO chuáº©n bá»‹ cho bÆ°á»›c transform Transform: Sá»­ dá»¥ng Pandas Ä‘á»ƒ truy váº¥n cÃ¡c file tá»« MinIO Load: Cleaned vÃ  transformed data Ä‘Æ°á»£c load vÃ o warehouse PostgreSQL Visualization: Sá»­ dá»¥ng Streamlit Ä‘á»ƒ lÃ m Dashboard ","date":"31 Jul 2023","objectID":"/football_etl/:1:0","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#introduce"},{"categories":["projects"],"content":"Set upBáº¯t Ä‘áº§u vá»›i Docker, ta sáº½ xÃ¢y dá»±ng láº§n lÆ°á»£t tá»«ng image báº±ng cÃ¡ch viáº¿t docker-compose.yml Tip nho nhá» HÃ£y pull/build láº§n lÆ°á»£t tá»«ng loáº¡i framework láº§n lÆ°á»£t Ä‘á»ƒ cháº¯c cháº¯n ráº±ng chÃºng hoáº¡t Ä‘á»™ng trÆ¡n tru nháº¥t trÆ°á»›c Hoáº·c báº¡n cÅ©ng cÃ³ thá»ƒ xem luÃ´n pháº§n hoÃ n chá»‰nh HoÃ n chá»‰nh set up ","date":"31 Jul 2023","objectID":"/football_etl/:2:0","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#set-up"},{"categories":["projects"],"content":"MinIOMinIO lÃ  má»™t server lÆ°u trá»¯ Ä‘á»‘i tÆ°á»£ng dáº¡ng phÃ¢n tÃ¡n vá»›i hiá»‡u nÄƒng cao vÃ  cung cáº¥p cÃ¡c api giá»‘ng vá»›i Amazon S3, ta cÃ³ thá»ƒ upload, download file,â€¦ má»™t cÃ¡ch Ä‘Æ¡n giáº£n. minio:hostname:minioimage:minio/miniocontainer_name:miniovolumes:- ./MinIO/storage:/data- ./MinIO/config:/root/.minioports:- \"9000:9000\"- \"9090:9090\"env_file:- ./.envcommand:server /data --console-address \":9090\"networks:- de_networkmc:image:minio/mccontainer_name:mchostname:mcenv_file:- ./.enventrypoint:\u003e/bin/sh -c \" until (/usr/bin/mc config host add minio http://minio:9000 minio minio123) do echo '...waiting...' \u0026\u0026 sleep 1;done; /usr/bin/mc mb minio/warehouse; /usr/bin/mc policy set public minio/warehouse; exit 0; \"depends_on:- minionetworks:- de_network Note Vá» .env file, Ä‘Ã¢y lÃ  file chá»©a thÃ´ng tin cÃ¡c biáº¿n mÃ´i trÆ°á»ng thiáº¿t láº­p cho tá»«ng image, mÃ¬nh sáº½ nÃ³i sau ","date":"31 Jul 2023","objectID":"/football_etl/:2:1","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#minio"},{"categories":["projects"],"content":"MySQLMySQL lÃ  má»™t trong sá»‘ cÃ¡c pháº§n má»m RDBMS (Relational DataBase Management Systems) phá»• biáº¿n nháº¥t, ta sáº½ sá»­ dá»¥ng database nÃ y Ä‘á»ƒ lÆ°u raw data mÃ´ phá»ng cho source data cáº§n ingest de_mysql:image:mysql:8.0container_name:de_mysqlports:- \"3306:3306\"volumes:- ./storage/mysql_data:/var/lib/mysql- ./dataset:/tmp/datasetenv_file:- ./.envnetworks:- de_network ","date":"31 Jul 2023","objectID":"/football_etl/:2:2","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#mysql"},{"categories":["projects"],"content":"PostgeSQLPostgreSQL lÃ  má»™t há»‡ thá»‘ng quáº£n trá»‹ cÆ¡ sá»Ÿ dá»¯ liá»‡u quan há»‡-Ä‘á»‘i tÆ°á»£ng (object-relational database management system), vÃ  ta sáº½ dung nÃ³ lÃ m data warehouse cho project láº§n nÃ y. de_psql:container_name:de_psqlimage:postgres:15-alpineenv_file:- ./.envports:- '5432:5432'volumes:- ./storage/postgres_data:/var/lib/postgresql/datanetworks:- de_network ","date":"31 Jul 2023","objectID":"/football_etl/:2:3","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#postgesql"},{"categories":["projects"],"content":"DagsterDagster lÃ  má»™t cÃ´ng cá»¥ mÃ£ nguá»“n má»Ÿ há»— trá»£ Orchestrate Task (quáº£n lÃ½, tá»• chá»©c, Ä‘iá»u phá»‘i cÃ¡c tÃ¡c vá»¥ vÃ  cÃ´ng viá»‡c), há»— trá»£ giÃºp xÃ¢y dá»±ng data pipeline khÃ¡ tá»‘t. MÃ¬nh tháº¥y cÃ´ng cá»¥ nÃ y gá»n nháº¹ hÆ¡n Apache Airflow vÃ  cÅ©ng Ä‘Æ¡n giáº£n hÆ¡n. Äáº§u tiÃªn hÃ£y viáº¿t trong docker-compose.yml vá» dagster nhÆ° sau: de_dagster:build:context:./dagster/container_name:de_dagsterimage:de_dagster Äá»‘i vá»›i Dagster, ta sáº½ tá»± config báº±ng Dockerfile, hÃ£y táº¡o 1 folder ./dagster/: mkdir dagster cd dagster touch Dockerfile requirements.txt Sau Ä‘Ã³ táº¡o Dockerfile cÃ³ ná»™i dung sau: # Dagster libraries to run both dagit and the dagster-daemon. Does not# need to have access to any pipeline code.FROMpython:3.10-slim# Set $DAGSTER_HOME and copy dagster instance and workspace YAML thereENV DAGSTER_HOME=/opt/dagster/dagster_homeRUN mkdir -p $DAGSTER_HOME \u0026\u0026 \\ mkdir -p $DAGSTER_HOME/storage \u0026\u0026 \\ mkdir -p $DAGSTER_HOME/compute_logs \u0026\u0026 \\ mkdir -p $DAGSTER_HOME/local_artifact_storageWORKDIR$DAGSTER_HOMECOPY requirements.txt $DAGSTER_HOMERUN pip install --upgrade pip \u0026\u0026 pip install -r requirements.txt vÃ  requirement.txt: dagster==1.1.20 dagit==1.1.20 dagster-postgres==0.17.20 dagster-dbt==0.17.20 DagitDagit lÃ  giao diá»‡n UI cá»§a Dagster, vÃ  ta sáº½ thao tÃ¡c trÃªn Dagit Ä‘á»ƒ quáº£n lÃ½ cÃ¡c assets, jobs,â€¦ de_dagster_dagit:image:de_dagster:latestentrypoint:- dagit- -h- \"0.0.0.0\"- -p- \"3001\"- -w- workspace.yamlcontainer_name:de_dagster_dagitexpose:- \"3001\"ports:- \"3001:3001\"volumes:# Make docker client accessible so we can terminate containers from dagit- /var/run/docker.sock:/var/run/docker.sock- ./dagster_home:/opt/dagster/dagster_homeenv_file:- ./.envnetworks:- de_network Sau Ä‘Ã³ hÃ£y táº¡o 1 folder ./dagster_home, trong Ä‘Ã³ táº¡o 2 file config cho workspace cá»§a dagster: dagster.yaml run_coordinator:module:dagster.core.run_coordinatorclass:QueuedRunCoordinatorconfig:max_concurrent_runs:3scheduler:module:dagster.core.schedulerclass:DagsterDaemonSchedulerconfig:max_catchup_runs:5storage:postgres:postgres_db:username:env:DAGSTER_PG_USERNAMEpassword:env:DAGSTER_PG_PASSWORDhostname:env:DAGSTER_PG_HOSTNAMEdb_name:env:DAGSTER_PG_DBport:5432run_launcher:module:dagster.core.launcherclass:DefaultRunLaunchercompute_logs:module:dagster.core.storage.local_compute_log_managerclass:LocalComputeLogManagerconfig:base_dir:/opt/dagster/dagster_home/compute_logslocal_artifact_storage:module:dagster.core.storage.rootclass:LocalArtifactStorageconfig:base_dir:/opt/dagster/dagster_home/local_artifact_storage vÃ  workspace.yaml load_from:- grpc_server:host:etl_pipelineport:4000location_name:\"etl_pipeline\" Dagster DeamonÄá»ƒ quáº£n lÃ½ cÃ¡c Schedules, sensors,â€¦ ta cáº§n pháº£i cÃ³ dagster-deamon de_dagster_daemon:image:de_dagster:latestentrypoint:- dagster-daemon- runcontainer_name:de_dagster_daemonvolumes:# Make docker client accessible so we can launch containers using host docker- /var/run/docker.sock:/var/run/docker.sock- ./dagster_home:/opt/dagster/dagster_homeenv_file:- ./.envnetworks:- de_network ","date":"31 Jul 2023","objectID":"/football_etl/:2:4","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#dagster"},{"categories":["projects"],"content":"DagsterDagster lÃ  má»™t cÃ´ng cá»¥ mÃ£ nguá»“n má»Ÿ há»— trá»£ Orchestrate Task (quáº£n lÃ½, tá»• chá»©c, Ä‘iá»u phá»‘i cÃ¡c tÃ¡c vá»¥ vÃ  cÃ´ng viá»‡c), há»— trá»£ giÃºp xÃ¢y dá»±ng data pipeline khÃ¡ tá»‘t. MÃ¬nh tháº¥y cÃ´ng cá»¥ nÃ y gá»n nháº¹ hÆ¡n Apache Airflow vÃ  cÅ©ng Ä‘Æ¡n giáº£n hÆ¡n. Äáº§u tiÃªn hÃ£y viáº¿t trong docker-compose.yml vá» dagster nhÆ° sau: de_dagster:build:context:./dagster/container_name:de_dagsterimage:de_dagster Äá»‘i vá»›i Dagster, ta sáº½ tá»± config báº±ng Dockerfile, hÃ£y táº¡o 1 folder ./dagster/: mkdir dagster cd dagster touch Dockerfile requirements.txt Sau Ä‘Ã³ táº¡o Dockerfile cÃ³ ná»™i dung sau: # Dagster libraries to run both dagit and the dagster-daemon. Does not# need to have access to any pipeline code.FROMpython:3.10-slim# Set $DAGSTER_HOME and copy dagster instance and workspace YAML thereENV DAGSTER_HOME=/opt/dagster/dagster_homeRUN mkdir -p $DAGSTER_HOME \u0026\u0026 \\ mkdir -p $DAGSTER_HOME/storage \u0026\u0026 \\ mkdir -p $DAGSTER_HOME/compute_logs \u0026\u0026 \\ mkdir -p $DAGSTER_HOME/local_artifact_storageWORKDIR$DAGSTER_HOMECOPY requirements.txt $DAGSTER_HOMERUN pip install --upgrade pip \u0026\u0026 pip install -r requirements.txt vÃ  requirement.txt: dagster==1.1.20 dagit==1.1.20 dagster-postgres==0.17.20 dagster-dbt==0.17.20 DagitDagit lÃ  giao diá»‡n UI cá»§a Dagster, vÃ  ta sáº½ thao tÃ¡c trÃªn Dagit Ä‘á»ƒ quáº£n lÃ½ cÃ¡c assets, jobs,â€¦ de_dagster_dagit:image:de_dagster:latestentrypoint:- dagit- -h- \"0.0.0.0\"- -p- \"3001\"- -w- workspace.yamlcontainer_name:de_dagster_dagitexpose:- \"3001\"ports:- \"3001:3001\"volumes:# Make docker client accessible so we can terminate containers from dagit- /var/run/docker.sock:/var/run/docker.sock- ./dagster_home:/opt/dagster/dagster_homeenv_file:- ./.envnetworks:- de_network Sau Ä‘Ã³ hÃ£y táº¡o 1 folder ./dagster_home, trong Ä‘Ã³ táº¡o 2 file config cho workspace cá»§a dagster: dagster.yaml run_coordinator:module:dagster.core.run_coordinatorclass:QueuedRunCoordinatorconfig:max_concurrent_runs:3scheduler:module:dagster.core.schedulerclass:DagsterDaemonSchedulerconfig:max_catchup_runs:5storage:postgres:postgres_db:username:env:DAGSTER_PG_USERNAMEpassword:env:DAGSTER_PG_PASSWORDhostname:env:DAGSTER_PG_HOSTNAMEdb_name:env:DAGSTER_PG_DBport:5432run_launcher:module:dagster.core.launcherclass:DefaultRunLaunchercompute_logs:module:dagster.core.storage.local_compute_log_managerclass:LocalComputeLogManagerconfig:base_dir:/opt/dagster/dagster_home/compute_logslocal_artifact_storage:module:dagster.core.storage.rootclass:LocalArtifactStorageconfig:base_dir:/opt/dagster/dagster_home/local_artifact_storage vÃ  workspace.yaml load_from:- grpc_server:host:etl_pipelineport:4000location_name:\"etl_pipeline\" Dagster DeamonÄá»ƒ quáº£n lÃ½ cÃ¡c Schedules, sensors,â€¦ ta cáº§n pháº£i cÃ³ dagster-deamon de_dagster_daemon:image:de_dagster:latestentrypoint:- dagster-daemon- runcontainer_name:de_dagster_daemonvolumes:# Make docker client accessible so we can launch containers using host docker- /var/run/docker.sock:/var/run/docker.sock- ./dagster_home:/opt/dagster/dagster_homeenv_file:- ./.envnetworks:- de_network ","date":"31 Jul 2023","objectID":"/football_etl/:2:4","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#dagit"},{"categories":["projects"],"content":"DagsterDagster lÃ  má»™t cÃ´ng cá»¥ mÃ£ nguá»“n má»Ÿ há»— trá»£ Orchestrate Task (quáº£n lÃ½, tá»• chá»©c, Ä‘iá»u phá»‘i cÃ¡c tÃ¡c vá»¥ vÃ  cÃ´ng viá»‡c), há»— trá»£ giÃºp xÃ¢y dá»±ng data pipeline khÃ¡ tá»‘t. MÃ¬nh tháº¥y cÃ´ng cá»¥ nÃ y gá»n nháº¹ hÆ¡n Apache Airflow vÃ  cÅ©ng Ä‘Æ¡n giáº£n hÆ¡n. Äáº§u tiÃªn hÃ£y viáº¿t trong docker-compose.yml vá» dagster nhÆ° sau: de_dagster:build:context:./dagster/container_name:de_dagsterimage:de_dagster Äá»‘i vá»›i Dagster, ta sáº½ tá»± config báº±ng Dockerfile, hÃ£y táº¡o 1 folder ./dagster/: mkdir dagster cd dagster touch Dockerfile requirements.txt Sau Ä‘Ã³ táº¡o Dockerfile cÃ³ ná»™i dung sau: # Dagster libraries to run both dagit and the dagster-daemon. Does not# need to have access to any pipeline code.FROMpython:3.10-slim# Set $DAGSTER_HOME and copy dagster instance and workspace YAML thereENV DAGSTER_HOME=/opt/dagster/dagster_homeRUN mkdir -p $DAGSTER_HOME \u0026\u0026 \\ mkdir -p $DAGSTER_HOME/storage \u0026\u0026 \\ mkdir -p $DAGSTER_HOME/compute_logs \u0026\u0026 \\ mkdir -p $DAGSTER_HOME/local_artifact_storageWORKDIR$DAGSTER_HOMECOPY requirements.txt $DAGSTER_HOMERUN pip install --upgrade pip \u0026\u0026 pip install -r requirements.txt vÃ  requirement.txt: dagster==1.1.20 dagit==1.1.20 dagster-postgres==0.17.20 dagster-dbt==0.17.20 DagitDagit lÃ  giao diá»‡n UI cá»§a Dagster, vÃ  ta sáº½ thao tÃ¡c trÃªn Dagit Ä‘á»ƒ quáº£n lÃ½ cÃ¡c assets, jobs,â€¦ de_dagster_dagit:image:de_dagster:latestentrypoint:- dagit- -h- \"0.0.0.0\"- -p- \"3001\"- -w- workspace.yamlcontainer_name:de_dagster_dagitexpose:- \"3001\"ports:- \"3001:3001\"volumes:# Make docker client accessible so we can terminate containers from dagit- /var/run/docker.sock:/var/run/docker.sock- ./dagster_home:/opt/dagster/dagster_homeenv_file:- ./.envnetworks:- de_network Sau Ä‘Ã³ hÃ£y táº¡o 1 folder ./dagster_home, trong Ä‘Ã³ táº¡o 2 file config cho workspace cá»§a dagster: dagster.yaml run_coordinator:module:dagster.core.run_coordinatorclass:QueuedRunCoordinatorconfig:max_concurrent_runs:3scheduler:module:dagster.core.schedulerclass:DagsterDaemonSchedulerconfig:max_catchup_runs:5storage:postgres:postgres_db:username:env:DAGSTER_PG_USERNAMEpassword:env:DAGSTER_PG_PASSWORDhostname:env:DAGSTER_PG_HOSTNAMEdb_name:env:DAGSTER_PG_DBport:5432run_launcher:module:dagster.core.launcherclass:DefaultRunLaunchercompute_logs:module:dagster.core.storage.local_compute_log_managerclass:LocalComputeLogManagerconfig:base_dir:/opt/dagster/dagster_home/compute_logslocal_artifact_storage:module:dagster.core.storage.rootclass:LocalArtifactStorageconfig:base_dir:/opt/dagster/dagster_home/local_artifact_storage vÃ  workspace.yaml load_from:- grpc_server:host:etl_pipelineport:4000location_name:\"etl_pipeline\" Dagster DeamonÄá»ƒ quáº£n lÃ½ cÃ¡c Schedules, sensors,â€¦ ta cáº§n pháº£i cÃ³ dagster-deamon de_dagster_daemon:image:de_dagster:latestentrypoint:- dagster-daemon- runcontainer_name:de_dagster_daemonvolumes:# Make docker client accessible so we can launch containers using host docker- /var/run/docker.sock:/var/run/docker.sock- ./dagster_home:/opt/dagster/dagster_homeenv_file:- ./.envnetworks:- de_network ","date":"31 Jul 2023","objectID":"/football_etl/:2:4","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#dagster-deamon"},{"categories":["projects"],"content":"PipelineTáº¥t cáº£ má»i viá»‡c xÃ¢y dá»±ng pipeline ta sáº½ hoáº¡t Ä‘á»™ng á»Ÿ Ä‘Ã¢y Äáº§u tiÃªn ta cáº§n init má»™t dagster project dagster project scaffold --name etl_pipeline vÃ  thÆ° má»¥c má»›i táº¡o sáº½ trÃ´ng nhÆ° tháº¿ nÃ y: Tip Äá»ƒ cháº¡y Ä‘Æ°á»£c lá»‡nh dagster á»Ÿ bÆ°á»›c táº¡o dagster project, ta cáº§n pháº£i cÃ³ dagster package, náº¿u chÆ°a cÃ³ hÃ£y cÃ i Ä‘áº·t báº±ng: pip install dagster â€“\u003e NÃªn cÃ i Ä‘áº·t trong mÃ´i trÆ°á»ng áº£o Sau Ä‘Ã³ vÃ o thÆ° má»¥c vá»«a táº¡o vÃ o viáº¿t Dockerfile thÃ´i: FROMpython:3.10-slim# Add repository codeWORKDIR/opt/dagster/appCOPY requirements.txt /opt/dagster/appRUN pip install --upgrade pip \u0026\u0026 pip install -r requirements.txtWORKDIR/opt/dagster/appCOPY . /opt/dagster/app/etl_pipeline# CMD allows this to be overridden from run launchers or executors that want to run other commands against your repositoryCMD [\"dagster\", \"api\", \"grpc\", \"-h\", \"0.0.0.0\", \"-p\", \"4000\", \"-m\", \"etl_pipeline\"] cÃ¹ng vá»›i requirements.txt: dagster==1.1.20 dagit==1.1.20 dagster-postgres==0.17.20 dagster-aws==0.17.20 dagster-dbt==0.17.20 pandas==1.5.3 SQLAlchemy==1.4.46 pymysql==1.0.2 cryptography==39.0.0 pyarrow==10.0.1 boto3==1.26.57 fsspec==2023.1.0 s3fs==0.4.2 minio==7.1.13 Cuá»‘i cÃ¹ng lÃ  viáº¿t vÃ o docker-compose.yml: etl_pipeline:build:context:./etl_pipelinedockerfile:./Dockerfilecontainer_name:etl_pipelineimage:etl_pipeline:latestvolumes:- ./etl_pipeline:/opt/dagster/appenv_file:- ./.envnetworks:- de_network ","date":"31 Jul 2023","objectID":"/football_etl/:2:5","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#pipeline"},{"categories":["projects"],"content":"StreamlitCuá»‘i cÃ¹ng lÃ  viá»‡c lÃ  Dashboard, Streamlit cháº¯c cháº¯c lÃ  cÃ´ng cá»¥ siÃªu phÃ¹ há»£p lÃ m viá»‡c nÃ y. ÄÃ¢y lÃ  framework há»— trá»£ viá»‡c xÃ¢y dá»±ng giao diá»‡n Æ°u nhÃ¬n chá»‰ báº±ng Python, quÃ¡ Ä‘Ã£ pháº£i khÃ´ng nÃ o :)) HÃ£y táº¡o folder ./streamlit/scr/ cÃ¹ng vá»›i ./streamlit/Dockerfile: FROMpython:3.10EXPOSE8501WORKDIR/usr/src/appCOPY requirements.txt ./RUN pip install -r requirements.txtCOPY . . vÃ  streamlit/requirements.txt: pandas plotly matplotlib numpy streamlit psycopg2-binary sqlalchemy python-dotenv Cuá»‘i cÃ¹ng lÃ  ghi trong yml streamlit:build:./streamymlcontainer_name:streamlitimage:streamlit:latestcommand:\"streamlit run src/main.py\"ports:- \"8501:8501\"volumes:- \"./streamlit/src:/usr/src/app/src\"networks:- de_network ","date":"31 Jul 2023","objectID":"/football_etl/:2:6","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#streamlit"},{"categories":["projects"],"content":"HoÃ n chá»‰nh setupCuá»‘i cÃ¹ng, file yaml sáº½ trÃ´ng nhÆ° tháº¿ nÃ y: # version: '3.9'services:minio:hostname:minioimage:minio/miniocontainer_name:miniovolumes:- ./MinIO/storage:/data- ./MinIO/config:/root/.minioports:- \"9000:9000\"- \"9090:9090\"env_file:- ./.envcommand:server /data --console-address \":9090\"networks:- de_networkmc:image:minio/mccontainer_name:mchostname:mcenv_file:- ./.enventrypoint:\u003e/bin/sh -c \" until (/usr/bin/mc config host add minio http://minio:9000 minio minio123) do echo '...waiting...' \u0026\u0026 sleep 1;done; /usr/bin/mc mb minio/warehouse; /usr/bin/mc policy set public minio/warehouse; exit 0; \"depends_on:- minionetworks:- de_networkde_mysql:image:mysql:8.0container_name:de_mysqlports:- \"3306:3306\"volumes:- ./storage/mysql_data:/var/lib/mysql- ./dataset:/tmp/datasetenv_file:- ./.envnetworks:- de_networkde_psql:container_name:de_psqlimage:postgres:15-alpineenv_file:- ./.envports:- '5432:5432'volumes:- ./storage/postgres_data:/var/lib/postgresql/datanetworks:- de_networkstreamlit:build:./streamlitcontainer_name:streamlitimage:streamlit:latestcommand:\"streamlit run src/main.py\"ports:- \"8501:8501\"volumes:- \"./streamlit/src:/usr/src/app/src\"networks:- de_networkde_dagster:build:context:./dagster/container_name:de_dagsterimage:de_dagsterde_dagster_dagit:image:de_dagster:latestentrypoint:- dagit- -h- \"0.0.0.0\"- -p- \"3001\"- -w- workspace.yamlcontainer_name:de_dagster_dagitexpose:- \"3001\"ports:- \"3001:3001\"volumes:# Make docker client accessible so we can terminate containers from dagit- /var/run/docker.sock:/var/run/docker.sock- ./dagster_home:/opt/dagster/dagster_homeenv_file:- ./.envnetworks:- de_networkde_dagster_daemon:image:de_dagster:latestentrypoint:- dagster-daemon- runcontainer_name:de_dagster_daemonvolumes:# Make docker client accessible so we can launch containers using host docker- /var/run/docker.sock:/var/run/docker.sock- ./dagster_home:/opt/dagster/dagster_homeenv_file:- ./.envnetworks:- de_network# Pipelinesetl_pipeline:build:context:./etl_pipelinedockerfile:./Dockerfilecontainer_name:etl_pipelineimage:etl_pipeline:latestvolumes:- ./etl_pipeline:/opt/dagster/appenv_file:- ./.envnetworks:- de_networknetworks:de_network:driver:bridgename:de_network VÃ  .env file: # PostgreSQL POSTGRES_HOST=de_psql POSTGRES_PORT=5432 POSTGRES_DB=football POSTGRES_USER=admin POSTGRES_PASSWORD=admin123 POSTGRES_HOST_AUTH_METHOD=trust # Dagster DAGSTER_PG_HOSTNAME=de_psql DAGSTER_PG_USERNAME=admin DAGSTER_PG_PASSWORD=admin123 DAGSTER_PG_DB=football # MySQL MYSQL_HOST=de_mysql MYSQL_PORT=3306 MYSQL_DATABASE=football MYSQL_ROOT_PASSWORD=admin123 MYSQL_USER=admin MYSQL_PASSWORD=admin123 # MinIO MINIO_ENDPOINT=minio:9000 MINIO_ROOT_USER=minio MINIO_ROOT_PASSWORD=minio123 MINIO_ACCESS_KEY=minio MINIO_SECRET_KEY=minio123 DATALAKE_BUCKET=warehouse AWS_ACCESS_KEY_ID=minio AWS_SECRET_ACCESS_KEY=minio123 AWS_REGION=us-east-1 Warning Náº¿u báº¡n chá»‰ Ä‘á»c pháº§n HoÃ n chá»‰nh setup thÃ¬ cÃ³ thá»ƒ há»‡ thá»‘ng vá»… sáº½ gáº·p lá»—i vÃ¬ cÃ³ thá»ƒ thiáº¿u cÃ¡c configuration cáº§n thiáº¿t cho dagster, dagit hay pipeline. Báº¡n cáº§n Ä‘á»c qua pháº§n Dagster, Dagit, Pipeline Cháº¡y thá»­: sau khi hoÃ n táº¥t toÃ n bá»™ set up dÃ i ngoáº±n, cÅ©ng Ä‘Ã£ Ä‘áº¿n lÃºc cháº¡y chÆ°Æ¡ng trÃ¬nh thÃ´i. Note nho nhá» Náº¿u báº¡n Ä‘Ã£ build láº§n lÆ°á»£t cÃ¡c images rá»“i, thÃ¬ chá»‰ cáº§n compose up thÃ´i, náº¿u khÃ´ng, hÃ£y build báº±ng lá»‡nh docker compose build trÆ°á»›c khi cháº¡y compose up. docker compose --env-file .env up -d Láº¡i lÃ  má»™t tip cÃ³ thá»ƒ há»¯u Ã­ch Äá»ƒ Ä‘Æ¡n giáº£n hÃ³a viá»‡c ghi lá»‡nh dÃ i dÃ²ng, hÃ£y táº¡o má»™t make file tÃªn Makefile vá»›i ná»™i dung sau: include .env build: docker compose build up: docker compose --env-file .env up -d down: docker compose --env-file .env down restart: make down \u0026\u0026 make up to_psql: docker exec -ti de_psql psql postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB} psql_create: docker exec -ti de_psql psql postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB} -f /tmp/psql_schema.sql to_mysql: docker exec -it de_mysql mysql --local-infile=1 -u\"${MYSQL_U","date":"31 Jul 2023","objectID":"/football_etl/:2:7","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#hoÃ n-chá»‰nh-setup"},{"categories":["projects"],"content":"To be ContinueBÃ i Ä‘áº¿n Ä‘Ã¢y cÅ©ng quÃ¡ lÃ  dÃ i rá»“i, mÃ¬nh sáº½ viáº¿t tiáº¿p á»Ÿ pháº§n 2 :))) ChÃºc báº¡n má»™t ngÃ y tá»‘t lÃ nh -Mew- ","date":"31 Jul 2023","objectID":"/football_etl/:3:0","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#to-be-continue"},{"categories":["projects"],"content":"Related Stock Analysis Basic Analyzing VN30 stock using PCA and K-Means Read more... Spotify Analysis Analyze data from Spotify platform utilizing the Spotify API and MongoDB, Apache Hadoop, Pyspark, Dremio and Power BI Read more... ","date":"31 Jul 2023","objectID":"/football_etl/:0:0","series":["Football ETL"],"tags":["data engineer","etl","dagster","docker","Tech","data pipeline","streamlit","MySQL","PostgreSQL","MinIO"],"title":"Football ETL Analysis","uri":"/football_etl/#related"},{"categories":[],"content":"Data Engineering Football ETL Analysis A Data Engineer project building pipeline to analyze football data Read more... Spotify Analysis Analyze data from Spotify platform utilizing the Spotify API and MongoDB, Apache Hadoop, Pyspark, Dremio and Power BI Read more... ","date":"31 Jul 2023","objectID":"/projects/:0:0","series":[],"tags":[],"title":"Projects","uri":"/projects/#data-engineering"},{"categories":[],"content":"Machine learning Basic Stock Analysis Basic Analyzing VN30 stock using PCA and K-Means Read more... ","date":"31 Jul 2023","objectID":"/projects/:0:0","series":[],"tags":[],"title":"Projects","uri":"/projects/#machine-learning-basic"},{"categories":null,"content":"BackgroundHey there! My name is Huynh Luu Vinh Phong, the author of this page. I am currently a final year student at University of Science Ho Chi Minh City, majoring in Data Science. My love for math and solving problems is what first got me interested in data, but over time, I discovered that coding is what truly excites me. Now, my goal is to become a Data Engineer, where I can work with data everyday and turn it into something meaningful. University of Science Ho Chi Minh City\" University of Science Ho Chi Minh City ","date":"30 Jul 2023","objectID":"/about/:0:0","series":null,"tags":null,"title":"About me","uri":"/about/#background"},{"categories":null,"content":"Learning is a journeyThe world of data is huge, indeed. And I am just at the beginning of my journey. I enjoy learning new things and diving deeper into data tools and technologies. Every day is a chance to grow and explore more of this exciting field, and Iâ€™m ready to take on the challenges ahead. There is a quote that motivate me during my journey: The most beautiful thing about learning is that no one can take it away from you This quote is about the power of learning is truly your inside power and your instinct. Therefore, no one can take it away from you. And going along with the ability to learn more, you will have the power to change the world. When Iâ€™m not busy with school or coding, I enjoy playing badminton and getting lost in anime or manga. Iâ€™ve always been fascinated by Japanese culture, and exploring it through anime is one of my favorite ways to unwind. I believe that learning is a lifelong journey, and Iâ€™m always eager to pick up new skills, whether itâ€™s in data science or in my personal hobbies. To me, learning isnâ€™t just about getting better grades or landing a jobâ€”itâ€™s about shaping my future. I truly believe that by continuously learning, I can create the life I want and make an impact in the world of data. And thatâ€™s what keeps me motivated every day. -Mew- Contact me: Mail: phonghuynh9403@gmail.com Linkedin: Huá»³nh LÆ°u VÄ©nh Phong Facebook: Phong Huynh Instagram: phong_huynh Visit my Github PhongHuynh0394 Huá»³nh LÆ°u VÄ©nh Phong ","date":"30 Jul 2023","objectID":"/about/:0:0","series":null,"tags":null,"title":"About me","uri":"/about/#learning-is-a-journey"}]